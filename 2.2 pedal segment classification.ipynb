{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel-last, i.e., (None, n_freq, n_time, n_ch)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from builtins import range\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Flatten, Input, Reshape, Dropout, Permute\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # the number of the GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7 # percentage to be used\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from global_config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(df_subset, ys, is_shuffle, batch_size=20):\n",
    "    \"\"\"Data generator.\n",
    "    df_subset: pandas dataframe, with rows subset\n",
    "    ys: numpy arrays, N-by-8 one-hot-encoded labels\n",
    "    is_shuffle: shuffle every batch if True.\n",
    "    batch_size: integer, size of batch. len(df_subset) % batch_size should be 0.\n",
    "    \"\"\"\n",
    "    n_data = len(df_subset)\n",
    "    n_batch = n_data // batch_size\n",
    "    if n_data % batch_size != 0:\n",
    "        print(\"= WARNING =\")\n",
    "        print(\"  n_data % batch_size != 0 but this code does not assume it\")\n",
    "        print(\"  so the residual {} sample(s) will be ignored.\".format(n_data % batch_size))\n",
    "\n",
    "    while True:\n",
    "        for batch_i in range(n_batch):\n",
    "            if is_shuffle:\n",
    "                batch_idxs = np.random.choice(n_data, batch_size, replace=False)\n",
    "            else:\n",
    "                batch_idxs = range(batch_i * batch_size, (batch_i + 1) * batch_size)\n",
    "\n",
    "            src_batch = np.array([np.load(os.path.join(DIR_PEDAL_SEGMENT_NPY, df_subset.loc[df_subset.index[i]].filepath.split('.')[0]+'.npy')) for i in batch_idxs],\n",
    "                                 dtype=K.floatx())\n",
    "            src_batch = src_batch[:, np.newaxis, :]  # make (batch, N) to (batch, 1, N) for kapre compatible\n",
    "\n",
    "            y_batch = np.array([ys[i] for i in batch_idxs],\n",
    "                               dtype=K.floatx())\n",
    "            \n",
    "            yield src_batch, y_batch\n",
    "        \n",
    "        \n",
    "def get_callbacks(name,patience):\n",
    "    if not os.path.exists(DIR_SAVE_MODEL):\n",
    "        os.makedirs(DIR_SAVE_MODEL)    \n",
    "    early_stopper = keras.callbacks.EarlyStopping(patience=patience)\n",
    "    model_saver = keras.callbacks.ModelCheckpoint(os.path.join(DIR_SAVE_MODEL,\"{}_best_model.h5\".format(name)),\n",
    "                                                  save_best_only=True)\n",
    "    weight_saver = keras.callbacks.ModelCheckpoint(os.path.join(DIR_SAVE_MODEL,\"{}_best_weights.h5\".format(name)),\n",
    "                                                   save_best_only=True,\n",
    "                                                   save_weights_only=True)\n",
    "    csv_logger = keras.callbacks.CSVLogger(os.path.join(DIR_SAVE_MODEL,\"{}.log\".format(name)))\n",
    "    return [early_stopper, model_saver, weight_saver, csv_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Invariant Models for Pedal-Segment Binary Classification\n",
    "\n",
    "use raw-audio input, which is converted to melspectrogram using Kapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_multi_kernel_shape(n_out, input_shape=SEGMENT_INPUT_SHAPE,\n",
    "                             out_activation='softmax'):\n",
    "    \"\"\"\n",
    "\n",
    "    Symbolic summary:\n",
    "    > c2' - p2 - c2 - p2 - c2 - p2 - c2 - p3 - d1\n",
    "    where c2' -> multiple kernel shapes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        n_out: integer, number of output nodes\n",
    "        input_shape: tuple, an input shape, which doesn't include batch-axis.\n",
    "        out_activation: activation function on the output\n",
    "    \"\"\"\n",
    "    audio_input = Input(shape=input_shape)\n",
    "\n",
    "    x = Melspectrogram(n_dft=N_FFT, n_hop=HOP_LENGTH, sr=SR, n_mels=128, power_melgram=2.0, return_decibel_melgram=True)(audio_input)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "    x1 = Conv2D(7, (20, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x2 = Conv2D(7, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x3 = Conv2D(7, (3, 20), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "\n",
    "    x = Concatenate(axis=channel_axis)([x1, x2, x3])\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((4, 4), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    out = Dense(n_out, activation=out_activation, kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "\n",
    "    model = Model(audio_input, out)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_crnn_icassp2017_choi(n_out, input_shape=SEGMENT_INPUT_SHAPE,\n",
    "                               out_activation='softmax'):\n",
    "    \"\"\"A simplified model of \n",
    "    Convolutional Recurrent Neural Networks for Music Classification,\n",
    "    K Choi, G Fazekas, M Sandler, K Choi, ICASSP, 2017, New Orleans, USA\n",
    "\n",
    "    Symbolic summary:\n",
    "    > c2 - p2 - c2 - p2 - c2 - p2 - c2 - p2 - r1 - r2 - d1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        n_out: integer, number of output nodes\n",
    "        input_shape: tuple, an input shape, which doesn't include batch-axis.\n",
    "        out_activation: activation function on the output\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    audio_input = Input(shape=input_shape)\n",
    "\n",
    "    x = Melspectrogram(n_dft=N_FFT, n_hop=HOP_LENGTH, sr=SR, n_mels=128, power_melgram=2.0, return_decibel_melgram=True)(audio_input)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((4, 4), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    if K.image_dim_ordering() == 'channels_first':\n",
    "        x = Permute((3, 1, 2))(x)\n",
    "\n",
    "    x = Reshape((-1, 21))(x)\n",
    "\n",
    "    # GRU block 1, 2, output\n",
    "    x = GRU(41, return_sequences=True, name='gru1')(x)\n",
    "    x = GRU(41, return_sequences=False, name='gru2')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    out = Dense(n_out, activation=out_activation, kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "\n",
    "    model = Model(audio_input, out)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_conv3x3_ismir2016_choi(n_out, input_shape=SEGMENT_INPUT_SHAPE,\n",
    "                                 out_activation='softmax'):\n",
    "    \"\"\" A simplified model of \n",
    "    Automatic Tagging Using Deep Convolutional Neural Networks,\n",
    "    K Choi, G Fazekas, M Sandler, ISMIR, 2016, New York, USA\n",
    "\n",
    "    Symbolic summary:\n",
    "    > c2 - p2 - c2 - p2 - c2 - p2 - c2 - p2 - c2 - p3 - d1\n",
    "\n",
    "    Modifications: \n",
    "        * n_mels (96 -> 32)\n",
    "        * n_channels (many -> [16, 24, 32, 40, 48])\n",
    "        * remove dropout\n",
    "        * maxpooling (irregular to fit the size -> all (2, 2))\n",
    "        * add GlobalAveragePooling2D\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Melspectrogram(n_dft=N_FFT, n_hop=HOP_LENGTH, sr=SR, n_mels=128, power_melgram=2.0, \n",
    "                             return_decibel_melgram=True,\n",
    "                             input_shape=input_shape))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "\n",
    "    model.add(Conv2D(10, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(15, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(15, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(20, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(20, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(n_out, activation=out_activation, kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_conv1d_icassp2014_sander(n_out, input_shape=SEGMENT_INPUT_SHAPE,\n",
    "                                   out_activation='softmax'):\n",
    "    \"\"\"A simplified model of\n",
    "    End-to-end learning for music audio,\n",
    "    Sander Dieleman and Benjamin Schrauwen, ICASSP, 2014\n",
    "\n",
    "    Symbolic summary:\n",
    "    > c1 - p1 - c1 - p1 - c1 - p1 - p3 - d1\n",
    "\n",
    "    Modifications: \n",
    "        * Add BatchNormalization\n",
    "        * n_mels (128 -> 32)\n",
    "        * n_layers (2 -> 3)\n",
    "        * add GlobalAveragePooling2D\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        n_out: integer, number of output nodes\n",
    "        input_shape: tuple, an input shape, which doesn't include batch-axis.\n",
    "        out_activation: activation function on the output\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Melspectrogram(n_dft=N_FFT, n_hop=HOP_LENGTH, sr=SR, n_mels=128, power_melgram=2.0, \n",
    "                             return_decibel_melgram=True,input_shape=input_shape))\n",
    "    model.add(Conv2D(30, (32, 4), padding='valid', kernel_regularizer=keras.regularizers.l2(reg_w)))  # (None, 16, 1, N)\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((1, 4), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(30, (1, 4), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((1, 4), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(30, (1, 4), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((1, 4), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(n_out, activation=out_activation, kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_w = 1e-4\n",
    "batch_size = 250\n",
    "epochs = 50\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the small dataset to see which model returns the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! Lets do something deep with pedal-segment_npydf_small.csv.\n",
      "I'm assuming you finished pre-processing.\n",
      "------------------------------------------------------------\n",
      "We're gonna use cnn3x3 model.\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 1370s 5s/step - loss: 0.4300 - acc: 0.8005 - val_loss: 2.0189 - val_acc: 0.5106\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 529s 2s/step - loss: 0.2771 - acc: 0.8907 - val_loss: 2.2409 - val_acc: 0.5440\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 374s 1s/step - loss: 0.2271 - acc: 0.9116 - val_loss: 1.2020 - val_acc: 0.6880\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 309s 1s/step - loss: 0.1964 - acc: 0.9236 - val_loss: 0.5271 - val_acc: 0.8129\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 282s 1s/step - loss: 0.1841 - acc: 0.9313 - val_loss: 1.1770 - val_acc: 0.6965\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 270s 963ms/step - loss: 0.1678 - acc: 0.9376 - val_loss: 0.7759 - val_acc: 0.7626\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 268s 956ms/step - loss: 0.1558 - acc: 0.9435 - val_loss: 0.7919 - val_acc: 0.7537\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 267s 954ms/step - loss: 0.1489 - acc: 0.9468 - val_loss: 0.2649 - val_acc: 0.8840\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 267s 952ms/step - loss: 0.1394 - acc: 0.9506 - val_loss: 0.3268 - val_acc: 0.8808\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 262s 936ms/step - loss: 0.1346 - acc: 0.9531 - val_loss: 0.1441 - val_acc: 0.9477\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 274s 977ms/step - loss: 0.1275 - acc: 0.9560 - val_loss: 0.2401 - val_acc: 0.9061\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 261s 932ms/step - loss: 0.1193 - acc: 0.9595 - val_loss: 0.0977 - val_acc: 0.9713\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 265s 947ms/step - loss: 0.1197 - acc: 0.9588 - val_loss: 0.1637 - val_acc: 0.9356\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 263s 940ms/step - loss: 0.1144 - acc: 0.9602 - val_loss: 0.1059 - val_acc: 0.9647\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 261s 934ms/step - loss: 0.1154 - acc: 0.9600 - val_loss: 0.3157 - val_acc: 0.8617\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 272s 973ms/step - loss: 0.1116 - acc: 0.9620 - val_loss: 0.1070 - val_acc: 0.9685\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 301s 1s/step - loss: 0.1072 - acc: 0.9639 - val_loss: 0.1008 - val_acc: 0.9657\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 302s 1s/step - loss: 0.1063 - acc: 0.9642 - val_loss: 0.1092 - val_acc: 0.9618\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 294s 1s/step - loss: 0.0991 - acc: 0.9669 - val_loss: 0.0820 - val_acc: 0.9736\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 250s 892ms/step - loss: 0.0989 - acc: 0.9672 - val_loss: 0.0906 - val_acc: 0.9755\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 246s 880ms/step - loss: 0.0999 - acc: 0.9679 - val_loss: 0.1384 - val_acc: 0.9475\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 249s 890ms/step - loss: 0.0953 - acc: 0.9682 - val_loss: 0.1106 - val_acc: 0.9700\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 277s 990ms/step - loss: 0.0966 - acc: 0.9684 - val_loss: 0.2604 - val_acc: 0.9089\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 246s 879ms/step - loss: 0.0978 - acc: 0.9676 - val_loss: 0.1388 - val_acc: 0.9459\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 252s 901ms/step - loss: 0.0938 - acc: 0.9698 - val_loss: 0.1573 - val_acc: 0.9382\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 307s 1s/step - loss: 0.0920 - acc: 0.9694 - val_loss: 0.2687 - val_acc: 0.8771\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 251s 897ms/step - loss: 0.0937 - acc: 0.9693 - val_loss: 0.1123 - val_acc: 0.9618\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 255s 911ms/step - loss: 0.0902 - acc: 0.9703 - val_loss: 0.1700 - val_acc: 0.9355\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 255s 912ms/step - loss: 0.0900 - acc: 0.9700 - val_loss: 0.0801 - val_acc: 0.9736\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 299s 1s/step - loss: 0.0898 - acc: 0.9705 - val_loss: 0.1441 - val_acc: 0.9496\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 254s 908ms/step - loss: 0.0911 - acc: 0.9707 - val_loss: 0.0854 - val_acc: 0.9721\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 254s 907ms/step - loss: 0.0881 - acc: 0.9712 - val_loss: 0.0741 - val_acc: 0.9797\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 256s 915ms/step - loss: 0.0882 - acc: 0.9712 - val_loss: 0.1603 - val_acc: 0.9412\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 301s 1s/step - loss: 0.0869 - acc: 0.9718 - val_loss: 0.1002 - val_acc: 0.9685\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 252s 899ms/step - loss: 0.0857 - acc: 0.9726 - val_loss: 0.8207 - val_acc: 0.6598\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 255s 910ms/step - loss: 0.0870 - acc: 0.9714 - val_loss: 0.0769 - val_acc: 0.9761\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 308s 1s/step - loss: 0.0860 - acc: 0.9728 - val_loss: 0.0893 - val_acc: 0.9719\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 254s 907ms/step - loss: 0.0819 - acc: 0.9742 - val_loss: 0.0913 - val_acc: 0.9681\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 260s 930ms/step - loss: 0.0835 - acc: 0.9730 - val_loss: 0.1272 - val_acc: 0.9551\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - 293s 1s/step - loss: 0.0809 - acc: 0.9749 - val_loss: 0.0856 - val_acc: 0.9741\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - 275s 983ms/step - loss: 0.0830 - acc: 0.9738 - val_loss: 0.0817 - val_acc: 0.9770\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - 253s 905ms/step - loss: 0.0822 - acc: 0.9734 - val_loss: 0.1878 - val_acc: 0.9191\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for cnn3x3!\n",
      "        valid set loss: 0.0778500554385\n",
      "        valid set accuracy: 0.978300068527\n",
      "        valid set auc: 0.99653896\n",
      "------------------------------------------------------------\n",
      "We're gonna use multi_kernel model.\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 318s 1s/step - loss: 0.3553 - acc: 0.8469 - val_loss: 0.3599 - val_acc: 0.8294\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 261s 932ms/step - loss: 0.2230 - acc: 0.9172 - val_loss: 0.1537 - val_acc: 0.9444\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 249s 888ms/step - loss: 0.1967 - acc: 0.9290 - val_loss: 0.1394 - val_acc: 0.9493\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 294s 1s/step - loss: 0.1728 - acc: 0.9375 - val_loss: 0.2872 - val_acc: 0.8701\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 245s 877ms/step - loss: 0.1633 - acc: 0.9420 - val_loss: 0.1836 - val_acc: 0.9306\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 228s 814ms/step - loss: 0.1511 - acc: 0.9473 - val_loss: 0.2932 - val_acc: 0.8940\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 227s 810ms/step - loss: 0.1314 - acc: 0.9551 - val_loss: 0.2218 - val_acc: 0.9174\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 229s 819ms/step - loss: 0.1302 - acc: 0.9543 - val_loss: 0.1161 - val_acc: 0.9594\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 227s 812ms/step - loss: 0.1198 - acc: 0.9588 - val_loss: 0.1454 - val_acc: 0.9477\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 282s 1s/step - loss: 0.1116 - acc: 0.9620 - val_loss: 0.1949 - val_acc: 0.9353\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 236s 844ms/step - loss: 0.1063 - acc: 0.9648 - val_loss: 0.0906 - val_acc: 0.9692\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 234s 834ms/step - loss: 0.1027 - acc: 0.9656 - val_loss: 0.0637 - val_acc: 0.9810\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 241s 861ms/step - loss: 0.0996 - acc: 0.9674 - val_loss: 0.0906 - val_acc: 0.9700\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 289s 1s/step - loss: 0.0940 - acc: 0.9691 - val_loss: 0.0972 - val_acc: 0.9679\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 232s 830ms/step - loss: 0.0905 - acc: 0.9707 - val_loss: 0.0943 - val_acc: 0.9702\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 232s 830ms/step - loss: 0.0899 - acc: 0.9704 - val_loss: 0.1055 - val_acc: 0.9652\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 228s 815ms/step - loss: 0.0908 - acc: 0.9704 - val_loss: 0.1248 - val_acc: 0.9586\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 281s 1s/step - loss: 0.0847 - acc: 0.9730 - val_loss: 0.2504 - val_acc: 0.9200\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 232s 830ms/step - loss: 0.0860 - acc: 0.9722 - val_loss: 0.0913 - val_acc: 0.9679\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 231s 824ms/step - loss: 0.0837 - acc: 0.9726 - val_loss: 0.0908 - val_acc: 0.9699\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 230s 823ms/step - loss: 0.0835 - acc: 0.9729 - val_loss: 0.0799 - val_acc: 0.9761\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 249s 888ms/step - loss: 0.0783 - acc: 0.9750 - val_loss: 0.0849 - val_acc: 0.9715\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for multi_kernel!\n",
      "        valid set loss: 0.0740216823295\n",
      "        valid set accuracy: 0.97630007118\n",
      "        valid set auc: 0.99718576\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'pedal-segment_npydf_small.csv'\n",
    "csv_path = os.path.join(DIR_PEDAL_METADATA, dataset_name)\n",
    "tracks = pd.read_csv(csv_path)\n",
    "training = tracks.loc[tracks['category'] == 'train']\n",
    "validation = tracks.loc[tracks['category'] == 'valid']\n",
    "test = tracks.loc[tracks['category'] == 'test']\n",
    "\n",
    "# make labels as one-hot vector\n",
    "y_train = training.label.values\n",
    "y_valid = validation.label.values\n",
    "y_test = test.label.values\n",
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_valid = keras.utils.to_categorical(y_valid, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)\n",
    "\n",
    "# preparing data generators\n",
    "steps_per_epoch = len(y_train) // batch_size\n",
    "gen_train = data_gen(training, y_train, True, batch_size=batch_size)\n",
    "gen_valid = data_gen(validation, y_valid, False, batch_size=batch_size)\n",
    "gen_test = data_gen(test, y_test, False, batch_size=batch_size)\n",
    "\n",
    "print(\"Welcome! Lets do something deep with {}.\".format(dataset_name))\n",
    "print(\"I'm assuming you finished pre-processing.\")\n",
    "\n",
    "model_names = ['cnn3x3','multi_kernel']\n",
    "for model_name in model_names:\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(\"We're gonna use {} model.\".format(model_name))    \n",
    "    exp_name = 'small-segment_{}'.format(model_name)\n",
    "    \n",
    "    # callbacks\n",
    "    callbacks = get_callbacks(name=exp_name, patience=patience)\n",
    "    early_stopper, model_saver, weight_saver, csv_logger = callbacks\n",
    "\n",
    "    print(\"Getting model...\")\n",
    "    if model_name == 'multi_kernel':\n",
    "        model = model_multi_kernel_shape(n_out=2)\n",
    "    elif model_name == 'crnn':\n",
    "        model = model_crnn_icassp2017_choi(n_out=2)\n",
    "    elif model_name == 'cnn3x3':\n",
    "        model = model_conv3x3_ismir2016_choi(n_out=2)\n",
    "    elif model_name == 'cnn1d':\n",
    "        model = model_conv1d_icassp2014_sander(n_out=2)\n",
    "\n",
    "    model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    print(\"Starting to train...\")\n",
    "    model.fit_generator(gen_train, steps_per_epoch, epochs=epochs,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=gen_valid,\n",
    "                        validation_steps=len(y_valid) // batch_size)\n",
    "\n",
    "    print(\"Training is done. Loading the best weights...\")\n",
    "    model.load_weights(os.path.join(DIR_SAVE_MODEL,\"{}_best_weights.h5\".format(exp_name)))\n",
    "\n",
    "    print(\"Evaluating...\")\n",
    "    scores = model.evaluate_generator(gen_test, len(y_valid) // batch_size)\n",
    "    y_pred = model.predict_generator(gen_test, len(y_valid) // batch_size)\n",
    "    auc = roc_auc_score(y_valid, y_pred)\n",
    "\n",
    "    print(\"Result: Done for {}!\".format(model_name))\n",
    "    print(\"        valid set loss: {}\".format(scores[0]))\n",
    "    print(\"        valid set accuracy: {}\".format(scores[1]))\n",
    "    print(\"        valid set auc: {}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the best model and train it on the large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Beici: Welcome! Lets do something deep with pedal-segment_vd.csv.\n",
      "       I'm assuming you finished pre-processing.\n",
      "       We're gonna use multi_kernel model.\n",
      "Beici: Getting model...\n",
      "Beici: Starting to train...\n",
      "Epoch 1/50= WARNING =\n",
      "  n_data % batch_size != 0 but this code does not assume it\n",
      "\n",
      "  so the residual 194 sample(s) will be ignored.\n",
      "2830/2831 [============================>.] - ETA: 4s - loss: 0.1563 - acc: 0.9442= WARNING =\n",
      "  n_data % batch_size != 0 but this code does not assume it\n",
      "  so the residual 204 sample(s) will be ignored.\n",
      "2831/2831 [==============================] - 17246s 6s/step - loss: 0.1563 - acc: 0.9442 - val_loss: 0.1475 - val_acc: 0.9471\n",
      "Epoch 2/50\n",
      "2831/2831 [==============================] - 16150s 6s/step - loss: 0.0871 - acc: 0.9727 - val_loss: 0.0660 - val_acc: 0.9801\n",
      "Epoch 3/50\n",
      "2831/2831 [==============================] - 15523s 5s/step - loss: 0.0711 - acc: 0.9785 - val_loss: 0.4919 - val_acc: 0.7829\n",
      "Epoch 4/50\n",
      "2831/2831 [==============================] - 14803s 5s/step - loss: 0.0636 - acc: 0.9814 - val_loss: 0.0726 - val_acc: 0.9760\n",
      "Epoch 5/50\n",
      "2831/2831 [==============================] - 12374s 4s/step - loss: 0.0593 - acc: 0.9832 - val_loss: 0.0640 - val_acc: 0.9807\n",
      "Epoch 6/50\n",
      "2831/2831 [==============================] - 9763s 3s/step - loss: 0.0571 - acc: 0.9840 - val_loss: 0.0576 - val_acc: 0.9841\n",
      "Epoch 7/50\n",
      "2831/2831 [==============================] - 9479s 3s/step - loss: 0.0555 - acc: 0.9845 - val_loss: 0.0559 - val_acc: 0.9857\n",
      "Epoch 8/50\n",
      "2831/2831 [==============================] - 9117s 3s/step - loss: 0.0537 - acc: 0.9853 - val_loss: 0.0608 - val_acc: 0.9814\n",
      "Epoch 9/50\n",
      "2831/2831 [==============================] - 9157s 3s/step - loss: 0.0529 - acc: 0.9856 - val_loss: 0.0555 - val_acc: 0.9852\n",
      "Epoch 10/50\n",
      "2831/2831 [==============================] - 8194s 3s/step - loss: 0.0522 - acc: 0.9860 - val_loss: 0.0674 - val_acc: 0.9804\n",
      "Epoch 11/50\n",
      "2831/2831 [==============================] - 8664s 3s/step - loss: 0.0508 - acc: 0.9866 - val_loss: 0.1152 - val_acc: 0.9591\n",
      "Epoch 12/50\n",
      "2831/2831 [==============================] - 8343s 3s/step - loss: 0.0514 - acc: 0.9862 - val_loss: 0.1846 - val_acc: 0.9210\n",
      "Epoch 13/50\n",
      "2831/2831 [==============================] - 8352s 3s/step - loss: 0.0498 - acc: 0.9868 - val_loss: 0.0738 - val_acc: 0.9784\n",
      "Epoch 14/50\n",
      "2831/2831 [==============================] - 8317s 3s/step - loss: 0.0499 - acc: 0.9868 - val_loss: 0.1052 - val_acc: 0.9650\n",
      "Epoch 15/50\n",
      "2831/2831 [==============================] - 8317s 3s/step - loss: 0.0500 - acc: 0.9868 - val_loss: 0.0575 - val_acc: 0.9837\n",
      "Epoch 16/50\n",
      "2831/2831 [==============================] - 8258s 3s/step - loss: 0.0498 - acc: 0.9867 - val_loss: 0.0519 - val_acc: 0.9869\n",
      "Epoch 17/50\n",
      "2831/2831 [==============================] - 8895s 3s/step - loss: 0.0489 - acc: 0.9872 - val_loss: 0.0505 - val_acc: 0.9876\n",
      "Epoch 18/50\n",
      "2831/2831 [==============================] - 12945s 5s/step - loss: 0.0489 - acc: 0.9871 - val_loss: 0.0462 - val_acc: 0.9901\n",
      "Epoch 19/50\n",
      "2831/2831 [==============================] - 8453s 3s/step - loss: 0.0487 - acc: 0.9870 - val_loss: 0.0579 - val_acc: 0.9832\n",
      "Epoch 20/50\n",
      "2831/2831 [==============================] - 7828s 3s/step - loss: 0.0494 - acc: 0.9870 - val_loss: 0.0565 - val_acc: 0.9843\n",
      "Epoch 21/50\n",
      "2831/2831 [==============================] - 8954s 3s/step - loss: 0.0478 - acc: 0.9876 - val_loss: 0.0560 - val_acc: 0.9850\n",
      "Epoch 22/50\n",
      "2831/2831 [==============================] - 7821s 3s/step - loss: 0.0470 - acc: 0.9878 - val_loss: 0.0994 - val_acc: 0.9688\n",
      "Epoch 23/50\n",
      "2831/2831 [==============================] - 7646s 3s/step - loss: 0.0480 - acc: 0.9875 - val_loss: 0.0475 - val_acc: 0.9883\n",
      "Epoch 24/50\n",
      "2831/2831 [==============================] - 7338s 3s/step - loss: 0.0477 - acc: 0.9877 - val_loss: 0.4486 - val_acc: 0.8746\n",
      "Epoch 25/50\n",
      "2831/2831 [==============================] - 7166s 3s/step - loss: 0.0475 - acc: 0.9876 - val_loss: 0.0541 - val_acc: 0.9865\n",
      "Epoch 26/50\n",
      "2831/2831 [==============================] - 7516s 3s/step - loss: 0.0480 - acc: 0.9874 - val_loss: 0.1509 - val_acc: 0.9536\n",
      "Epoch 27/50\n",
      "2831/2831 [==============================] - 7649s 3s/step - loss: 0.0471 - acc: 0.9879 - val_loss: 0.0579 - val_acc: 0.9827\n",
      "Epoch 28/50\n",
      "2831/2831 [==============================] - 7545s 3s/step - loss: 0.0472 - acc: 0.9879 - val_loss: 0.0781 - val_acc: 0.9755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1356d850>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'pedal-segment_vd.csv'\n",
    "model_name = 'multi_kernel'\n",
    "exp_name = 'segment_{}'.format(model_name)\n",
    "reg_w = 1e-4\n",
    "batch_size = 250\n",
    "epochs = 50\n",
    "patience = 10\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"Beici: Welcome! Lets do something deep with {}.\".format(dataset_name))\n",
    "print(\"       I'm assuming you finished pre-processing.\")\n",
    "print(\"       We're gonna use {} model.\".format(model_name))\n",
    "csv_path = os.path.join(DIR_PEDAL_METADATA, dataset_name)\n",
    "\n",
    "tracks = pd.read_csv(csv_path)\n",
    "training = tracks.loc[tracks['category'] == 'train']\n",
    "validation = tracks.loc[tracks['category'] == 'valid']\n",
    "test = tracks.loc[tracks['category'] == 'test']\n",
    "\n",
    "# print(\"Beici: We're loading and modifying label values.\")\n",
    "y_train = training.label.values\n",
    "y_valid = validation.label.values\n",
    "y_test = test.label.values\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_valid = keras.utils.to_categorical(y_valid, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)\n",
    "\n",
    "# callbacks\n",
    "callbacks = get_callbacks(name=exp_name, patience=patience)\n",
    "early_stopper, model_saver, weight_saver, csv_logger = callbacks\n",
    "\n",
    "# print(\"Beici: Preparing data generators for training and validation...\")\n",
    "steps_per_epoch = len(y_train) // batch_size\n",
    "gen_train = data_gen(training, y_train, True, batch_size=batch_size)\n",
    "gen_valid = data_gen(validation, y_valid, False, batch_size=batch_size)\n",
    "gen_test = data_gen(test, y_test, False, batch_size=batch_size)\n",
    "\n",
    "print(\"Beici: Getting model...\")\n",
    "if model_name == 'multi_kernel':\n",
    "    model = model_multi_kernel_shape(n_out=2)\n",
    "elif model_name == 'crnn':\n",
    "    model = model_crnn_icassp2017_choi(n_out=2)\n",
    "elif model_name == 'cnn3x3':\n",
    "    model = model_conv3x3_ismir2016_choi(n_out=2)\n",
    "elif model_name == 'cnn1d':\n",
    "    model = model_conv1d_icassp2014_sander(n_out=2)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "print(\"Beici: Starting to train...\")\n",
    "model.fit_generator(gen_train, steps_per_epoch, epochs=epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=gen_valid,\n",
    "                    validation_steps=len(y_valid) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Beici: Training is done. Loading the best weights...\")\n",
    "model.load_weights(os.path.join(DIR_SAVE_MODEL,\"{}_best_weights.h5\".format(exp_name)))\n",
    "\n",
    "print(\"       Evaluating...\")\n",
    "scores = model.evaluate_generator(gen_test, len(y_test) // batch_size)\n",
    "y_pred = model.predict_generator(gen_test, len(y_test) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beici: Done for multi_kernel!\n",
      "       test set loss: 0.0483642033362\n",
      "       test set accuracy: 0.988722819034\n",
      "       test set auc: 0.998992069409\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test[:len(y_pred)], y_pred)\n",
    "\n",
    "print(\"Beici: Done for {}!\".format(model_name))\n",
    "print(\"       test set loss: {}\".format(scores[0]))\n",
    "print(\"       test set accuracy: {}\".format(scores[1]))\n",
    "print(\"       test set auc: {}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Beici: Plot for {}!\".format(model_name))\n",
    "df_log = pd.read_csv(os.path.join(DIR_SAVE_MODEL,\"{}.log\".format(exp_name)))\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "fig.suptitle(\"Accuracy and Loss Plot of Model: {}\".format(model_name))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "tr_acc, = ax1.plot(range(len(df_log)), df_log.acc.values)\n",
    "val_acc, = ax1.plot(range(len(df_log)), df_log.val_acc.values)\n",
    "ax1.legend([tr_acc, val_acc], ['Train Accuracy', 'Val Accuracy'])\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax2 = plt.subplot(122)\n",
    "tr_loss, = ax2.plot(range(len(df_log)), df_log.loss.values)\n",
    "val_loss, = ax2.plot(range(len(df_log)), df_log.val_loss.values)\n",
    "ax2.legend([tr_loss, val_loss], ['Train Loss', 'Val Loss'])\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
