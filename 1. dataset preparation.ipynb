{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# piano-e-competition dataset\n",
    "\n",
    "- 1567 MIDI files were downloaded from the [official website](http://www.piano-e-competition.com/ecompetition/midiinstructions.asp) and saved into folders named by year, i.e., `piano-e-competition/rendered-dataset/YEAR`.\n",
    "\n",
    "- For each midi file, [Pianoteq 6](https://www.pianoteq.com/pianoteq6) was used to render it into two corresponding audio files, including pedal and non-pedal version (`FILENAME-p.wav` and `FILENAME-np.wav`).\n",
    "\n",
    "- Noted that the non-pedal version does not have any pedal data, while the pedal version only has pedal data on the sustain pedal which was mapped from 0-127 to binary cases (0-63 as pedall off, 64-127 as pedal on).\n",
    "\n",
    "- Statistics info for each folder:\n",
    "    - `2002`: 122 filenames\n",
    "    - `2004`: 294 filenames\n",
    "    - `2006`: 343 filenames\n",
    "    - `2008`: 302 filenames\n",
    "    - `2009`: 331 filenames\n",
    "    - `2011`: 175 filenames\n",
    "\n",
    "- Lists of filenames by year are saved in `piano-e-competition/pedal-metadata/filename-YEAR.txt`\n",
    "\n",
    "- Data for train/valid/test obtains a ratio of 0.7/0.2/0.1, i.e., 1113/279/175. Here files in folder `2011` forms the test set. The rest of files were shuffled to form the train/valid set, which was splitted by the python code below:\n",
    "\n",
    "```\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dir_pedal_metadata = './piano-e-competition/pedal-metadata/'\n",
    "\n",
    "# input for spliting the filename in it as train/valid\n",
    "txt_filename = 'filename-20024689.txt'\n",
    "txt_path = os.path.join(dir_pedal_metadata, txt_filename)\n",
    "filenames = np.genfromtxt(txt_path, dtype=None)\n",
    "\n",
    "x = y = filenames\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# output\n",
    "train_filename = 'train.txt'\n",
    "train_file_path = os.path.join(dir_pedal_metadata, train_filename)\n",
    "\n",
    "with open(train_file_path, 'w') as train_file:\n",
    "    for filename in np.sort(x_train):\n",
    "        train_file.write(filename+'\\n')\n",
    "        \n",
    "valid_filename = 'valid.txt'\n",
    "valid_file_path = os.path.join(dir_pedal_metadata, valid_filename)\n",
    "\n",
    "with open(valid_file_path, 'w') as valid_file:\n",
    "    for filename in np.sort(x_valid):\n",
    "        valid_file.write(filename+'\\n')\n",
    "```\n",
    "\n",
    "- `piano-e-competition/pedal-metadata/{train, valid, test}.txt` lists `YEAR/FILENAME` line by line, e.g.\n",
    "```\n",
    "2002/chan01\n",
    "2002/cho01\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for binary classification task\n",
    "\n",
    "There are two kinds of datasets created for binary classification saved under `./piano-e-competition/pedal-dataset`.\n",
    "\n",
    "1. `pedal-onset-dataset`\n",
    "2. `pedal-segment-dataset`\n",
    "\n",
    "The first one are consisted of 500ms excerpts that are subsegments from tracks with binary labels (**pedal-onset** and **non-pedal-onset**). From midi files, we can get the timing for pedal onset. An excerpt from the pedal-version wav file consists of 500ms of samples with the pedal onset at the 200ms. An excerpt from the corresponding non-pedal-version wav file will also be saved. Neural network can be then trained as a pedal onset detector. \n",
    "\n",
    "Excerpt with/without pedal onset is saved as:\n",
    "\n",
    "`pedal-onset-dataset/CATEGORY/(non-)pedal-onset/FILENAME-(n)p_NUMBER.wav`\n",
    "\n",
    "The second one are consisted of longer excerpts played with pedal effect or not (labelled as **pedal-segment** and **non-pedal-segment**). From midi files, we can get pedal onset and offset times, based on which the pedalled subsegments are obtained from pedal-version tracks. The corresponding subsegments from the non-pedal-version tracks will also be saved. Neural network can be then trained to tell us whether an excerpt is playing with/without pedal effect.\n",
    "\n",
    "Excerpt with/without pedal effect is saved as:\n",
    "\n",
    "`pedal-segment-dataset/CATEGORY/non-pedal-segment/FILENAME-np_NUMBER.wav`\n",
    "\n",
    "The excerpt's filename, filepath, label and category for both dataset are saved in csv files at: \n",
    "- `./piano-e-competition/pedal-metadata/pedal-onset_vd.csv`\n",
    "- `./piano-e-competition/pedal-metadata/pedal-segment_vd.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To decide a length threshold for trimming the excerpt, this can be informed by presenting a distribution of pedalled segment length from all the midi files. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel-last, i.e., (None, n_freq, n_time, n_ch)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from global_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating pedalled segment length...\n",
      "  2002..\n",
      "  2004..\n",
      "  2006..\n",
      "  2008..\n",
      "  2009..\n",
      "  2011..\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Calculating pedalled segment length...')\n",
    "pedal_lengths = []\n",
    "years = ['2002','2004','2006','2008','2009','2011']\n",
    "for year in years:\n",
    "    print('  {}..'.format(year))\n",
    "    txt_path = os.path.join(DIR_PEDAL_METADATA,'filename-{}.txt'.format(year))\n",
    "    filenames = np.genfromtxt(txt_path, dtype=None)\n",
    "\n",
    "    for filename in filenames:\n",
    "        midi_path = os.path.join(DIR_RENDERED, '{}.mid'.format(filename))\n",
    "        \n",
    "        # get ground truth pedal onset time from midi\n",
    "        pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "        pedal_v = []\n",
    "        pedal_t = []\n",
    "        for control_change in pm.instruments[0].control_changes:\n",
    "            if control_change.number == 64:\n",
    "                pedal_v.append(control_change.value)\n",
    "                pedal_t.append(control_change.time)\n",
    "                \n",
    "        pedal_onset = []\n",
    "        pedal_offset = []\n",
    "        for i,v in enumerate(pedal_v):\n",
    "            if i>0 and v>=64 and pedal_v[i-1]<64:\n",
    "                pedal_onset.append(pedal_t[i])   \n",
    "            elif i>0 and v<64 and pedal_v[i-1]>=64:\n",
    "                pedal_offset.append(pedal_t[i])\n",
    "        \n",
    "        pedal_offset = [t for t in pedal_offset if t > pedal_onset[0]]\n",
    "        seg_idxs = np.min([len(pedal_onset), len(pedal_offset)])\n",
    "        pedal_offset = pedal_offset[:seg_idxs]\n",
    "        pedal_onset = pedal_onset[:seg_idxs]\n",
    "        for seg_idx, offset in enumerate(pedal_offset):\n",
    "            if offset != pedal_offset[-1] and offset > pedal_onset[seg_idx] and offset < pedal_onset[seg_idx+1]:\n",
    "                correct_pedal_data = True\n",
    "            elif offset == pedal_offset[-1] and offset > pedal_onset[seg_idx]:\n",
    "                correct_pedal_data = True\n",
    "            else:\n",
    "                correct_pedal_data = False\n",
    "        \n",
    "        if correct_pedal_data:\n",
    "            for seg_idx in np.arange(seg_idxs):\n",
    "                pedal_lengths.append(pedal_offset[seg_idx]-pedal_onset[seg_idx])\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,u'histogram of pedal lengths')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4faa0b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pedal_lengths_mean = np.mean(pedal_lengths)\n",
    "pedal_lengths_meanplusstd = np.mean(pedal_lengths) + np.std(pedal_lengths)\n",
    "sns.distplot(pedal_lengths, bins=int(np.max(pedal_lengths)*100), kde=False)\n",
    "ymin,ymax = plt.ylim()\n",
    "plt.vlines(pedal_lengths_mean, ymin, ymax, linestyle='dashed', lw=2, color='green',label='mean')\n",
    "plt.vlines(pedal_lengths_meanplusstd, ymin, ymax, linestyle='dotted', lw=2, color='green',label='mean+std')\n",
    "plt.xlim(0, 5)\n",
    "plt.legend()\n",
    "plt.title('histogram of pedal lengths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `pedal-segment-dataset` we decide the excerpts in should obtain a length between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum length: 0.30 seconds\n",
      "maximum length: 2.22 seconds\n"
     ]
    }
   ],
   "source": [
    "hist, bin_edges = np.histogram(pedal_lengths, bins=np.arange(0,5,0.1))\n",
    "print('minimum length: {:.2f} seconds'.format(bin_edges[np.argmax(hist)]))\n",
    "print('maximum length: {:.2f} seconds'.format(pedal_lengths_meanplusstd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We therefore set the value of `MIN_SRC` as 0.3 and `MAX_SRC` as 2.3.\n",
    "\n",
    "For `pedal-onset-dataset` we decide to set the beginning of the excerpt 0.2s before the pedal onset and 0.3s after. Therefore `TRIM_SECOND_BEFORE` is 0.2 and `TRIM_SECOND_AFTER` is 0.3.\n",
    "\n",
    "The other global configurations are set in `config.json` and `global_config.py`.\n",
    "\n",
    "## `config.json` :\n",
    "```\n",
    "{\n",
    "  \"dir_rendered\": \"./piano-e-competition/rendered-dataset\",\n",
    "  \"dir_pedal_metadata\" : \"./piano-e-competition/pedal-metadata\",\n",
    "  \"dir_pedal_onset\" : \"./piano-e-competition/pedal-dataset/pedal-onset-dataset\",\n",
    "  \"dir_pedal_segment\": \"./piano-e-competition/pedal-dataset/pedal-segment-dataset\",\n",
    "  \"dir_pedal_onset_npy\" : \"./piano-e-competition/pedal-dataset/pedal-onset-npydataset\",\n",
    "  \"dir_pedal_segment_npy\": \"./piano-e-competition/pedal-dataset/pedal-segment-npydataset\"\n",
    "  \"dir_same_model\": \"./save-model\"\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `global_config.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import json\n",
    "from keras import backend as K\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    print('Channel-first, i.e., (None, n_ch, n_freq, n_time)')\n",
    "    channel_axis = 1\n",
    "    freq_axis = 2\n",
    "    time_axis = 3\n",
    "else:\n",
    "    print('Channel-last, i.e., (None, n_freq, n_time, n_ch)')\n",
    "    channel_axis = 3\n",
    "    freq_axis = 1\n",
    "    time_axis = 2\n",
    "\n",
    "# Constants\n",
    "SR = 44100\n",
    "N_FFT = 1024             # 23 ms\n",
    "HOP_LENGTH = 10/1000*SR  # 10 ms \n",
    "TRIM_SECOND_BEFORE = 0.2\n",
    "TRIM_SECOND_AFTER = 0.3\n",
    "ONSET_INPUT_SHAPE = (1, int(SR * (TRIM_SECOND_BEFORE + TRIM_SECOND_AFTER)))\n",
    "MIN_SRC = 0.3\n",
    "MAX_SRC = 2.3\n",
    "LEN_SRC = 2.0\n",
    "NSP_SRC = int(SR * LEN_SRC)\n",
    "SEGMENT_INPUT_SHAPE = (1, NSP_SRC)\n",
    "FOLDERS = ['train', 'valid', 'test']\n",
    "\n",
    "# Paths\n",
    "with open('config.json') as json_data:\n",
    "    config = json.load(json_data)\n",
    "\n",
    "DIR_RENDERED = config['dir_rendered']\n",
    "DIR_PEDAL_METADATA = config['dir_pedal_metadata']\n",
    "DIR_PEDAL_ONSET = config['dir_pedal_onset']\n",
    "DIR_PEDAL_SEGMENT = config['dir_pedal_segment']\n",
    "DIR_PEDAL_ONSET_NPY = config['dir_pedal_onset_npy']\n",
    "DIR_PEDAL_SEGMENT_NPY = config['dir_pedal_segment_npy']\n",
    "DIR_SAVE_MODEL = config['dir_same_model]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `main_preprocess.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from __future__ import print_function  # (at top of module)\n",
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import librosa\n",
    "\n",
    "from global_config import *\n",
    "\n",
    "def write_to_csv(rows, column_names, csv_fname):\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "    df.to_csv(os.path.join(DIR_PEDAL_METADATA, csv_fname))\n",
    "    \n",
    "def prep_pedal_onset():\n",
    "    \"\"\"\n",
    "    Get 500ms excerpts with/without pedal onset at 200ms    \n",
    "    where pedal onset is obtained from midi file.\n",
    "    \"\"\"\n",
    "    print('Start creating pedal-onset-dataset...')\n",
    "    filename_segs = []\n",
    "    filepaths = []\n",
    "    ys = []\n",
    "    categories = []\n",
    "    for folder in FOLDERS:\n",
    "        print('{}..'.format(folder))\n",
    "        txt_path = os.path.join(DIR_PEDAL_METADATA,'{}.txt'.format(folder))\n",
    "        filenames = np.genfromtxt(txt_path, dtype=None)\n",
    "\n",
    "        pfolder_path = os.path.join(DIR_PEDAL_ONSET, folder, 'pedal-onset/')\n",
    "        npfolder_path = os.path.join(DIR_PEDAL_ONSET, folder, 'non-pedal-onset/')\n",
    "        if not os.path.exists(pfolder_path):\n",
    "            os.makedirs(pfolder_path)\n",
    "        if not os.path.exists(npfolder_path):\n",
    "            os.makedirs(npfolder_path)\n",
    "\n",
    "        for filename in filenames:\n",
    "            print('  {}..'.format(filename))\n",
    "            midi_path = os.path.join(DIR_RENDERED, '{}.mid'.format(filename))\n",
    "            paudio_path = os.path.join(DIR_RENDERED, '{}-p.wav'.format(filename))\n",
    "            npaudio_path = os.path.join(DIR_RENDERED, '{}-np.wav'.format(filename))\n",
    "            paudio, sr = librosa.load(paudio_path, sr=SR)\n",
    "            npaudio, sr = librosa.load(npaudio_path, sr=SR)\n",
    "\n",
    "            # get ground truth pedal onset time from midi\n",
    "            pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "            pedal_v = []\n",
    "            pedal_t = []\n",
    "            for control_change in pm.instruments[0].control_changes:\n",
    "                if control_change.number == 64:\n",
    "                    pedal_v.append(control_change.value)\n",
    "                    pedal_t.append(control_change.time)\n",
    "\n",
    "            pedal_onset = []\n",
    "            for i,v in enumerate(pedal_v):\n",
    "                if i>0 and v>=64 and pedal_v[i-1]<64:\n",
    "                    pedal_onset.append(pedal_t[i])   \n",
    "\n",
    "            pedal_onset_sp = librosa.time_to_samples(pedal_onset, sr=SR)\n",
    "\n",
    "            for seg_idx, sp in enumerate(pedal_onset_sp):\n",
    "                start_sp = int(sp - TRIM_SECOND_BEFORE * SR)\n",
    "                end_sp = int(sp + TRIM_SECOND_AFTER * SR)\n",
    "                newfilename = filename.replace('/','-')\n",
    "\n",
    "                if start_sp > 0 and end_sp < len(npaudio):\n",
    "                    pout_name = '{}-p_{}.wav'.format(newfilename, seg_idx)\n",
    "                    pout_path = os.path.join(pfolder_path, pout_name)            \n",
    "                    librosa.output.write_wav(pout_path, paudio[start_sp:end_sp], SR)\n",
    "                    filename_segs.append(pout_name.rstrip('.wav'))\n",
    "                    filepaths.append(os.path.join(folder, 'pedal-onset/', pout_name))\n",
    "                    ys.append(1)\n",
    "                    categories.append(folder)\n",
    "\n",
    "                    npout_name = '{}-np_{}.wav'.format(newfilename, seg_idx)\n",
    "                    npout_path = os.path.join(npfolder_path, npout_name)\n",
    "                    librosa.output.write_wav(npout_path, npaudio[start_sp:end_sp], SR)\n",
    "                    filename_segs.append(npout_name.rstrip('.wav'))\n",
    "                    filepaths.append(os.path.join(folder, 'non-pedal-onset/', npout_name))\n",
    "                    ys.append(0)\n",
    "                    categories.append(folder)\n",
    "\n",
    "    write_to_csv(zip(*[filename_segs, filepaths, ys, categories]), \n",
    "                 ['filename', 'filepath', 'label', 'category'], \n",
    "                 'pedal-onset_vd.csv')\n",
    "    print('pedal-onset_vd.csv is saved!')\n",
    "    \n",
    "\n",
    "def prep_pedal_segment():\n",
    "    \"\"\"\n",
    "    Get varient length excerpts with/without pedal effect    \n",
    "    where the length is decided by midi file.\n",
    "    \"\"\"\n",
    "    print('Start creating pedal-segment-dataset...')\n",
    "    filename_segs = []\n",
    "    filepaths = []\n",
    "    ys = []\n",
    "    categories = []\n",
    "    min_sp = int(MIN_SRC * SR)\n",
    "    max_sp = int(MAX_SRC * SR)\n",
    "    for folder in FOLDERS:\n",
    "        print('{}..'.format(folder))\n",
    "        txt_path = os.path.join(DIR_PEDAL_METADATA,'{}.txt'.format(folder))\n",
    "        filenames = np.genfromtxt(txt_path, dtype=None)\n",
    "\n",
    "        pfolder_path = os.path.join(DIR_PEDAL_SEGMENT, folder, 'pedal-segment/')\n",
    "        npfolder_path = os.path.join(DIR_PEDAL_SEGMENT, folder, 'non-pedal-segment/')\n",
    "        if not os.path.exists(pfolder_path):\n",
    "            os.makedirs(pfolder_path)\n",
    "        if not os.path.exists(npfolder_path):\n",
    "            os.makedirs(npfolder_path)\n",
    "\n",
    "        for filename in filenames:\n",
    "            print('  {}..'.format(filename))\n",
    "            # get pedal segment from midi\n",
    "            midi_path = os.path.join(PATH_DATASET, '{}.mid'.format(filename))\n",
    "            pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "            pedal_v = []\n",
    "            pedal_t = []\n",
    "            for control_change in pm.instruments[0].control_changes:\n",
    "                if control_change.number == 64:\n",
    "                    pedal_v.append(control_change.value)\n",
    "                    pedal_t.append(control_change.time)\n",
    "\n",
    "            pedal_onset = []\n",
    "            pedal_offset = []\n",
    "            for i,v in enumerate(pedal_v):\n",
    "                if i>0 and v>=64 and pedal_v[i-1]<64:\n",
    "                    pedal_onset.append(pedal_t[i])\n",
    "                elif i>0 and v<64 and pedal_v[i-1]>=64:\n",
    "                    pedal_offset.append(pedal_t[i])\n",
    "\n",
    "            pedal_offset = [t for t in pedal_offset if t > pedal_onset[0]]\n",
    "            seg_idxs = np.min([len(pedal_onset), len(pedal_offset)])\n",
    "            pedal_offset = pedal_offset[:seg_idxs]\n",
    "            pedal_onset = pedal_onset[:seg_idxs]\n",
    "            for seg_idx, offset in enumerate(pedal_offset):\n",
    "                if offset != pedal_offset[-1] and offset > pedal_onset[seg_idx] and offset < pedal_onset[seg_idx+1]:\n",
    "                    correct_pedal_data = True\n",
    "                elif offset == pedal_offset[-1] and offset > pedal_onset[seg_idx]:\n",
    "                    correct_pedal_data = True\n",
    "                else:\n",
    "                    correct_pedal_data = False\n",
    "\n",
    "            if correct_pedal_data:\n",
    "                pedal_onset_sp = librosa.time_to_samples(pedal_onset, sr=SR)\n",
    "                pedal_offset_sp = librosa.time_to_samples(pedal_offset, sr=SR)\n",
    "                paudio_path = os.path.join(DIR_RENDERED, '{}-p.wav'.format(filename))\n",
    "                npaudio_path = os.path.join(DIR_RENDERED, '{}-np.wav'.format(filename))\n",
    "                paudio, sr = librosa.load(paudio_path, sr=SR)\n",
    "                npaudio, sr = librosa.load(npaudio_path, sr=SR)\n",
    "                for seg_idx, start_sp in enumerate(pedal_onset_sp):\n",
    "                    end_sp = pedal_offset_sp[seg_idx]\n",
    "                    len_sp = end_sp - start_sp\n",
    "                    if len_sp > max_sp:\n",
    "                        end_sp = start_sp + max_sp\n",
    "\n",
    "                    if len_sp >= min_sp and end_sp < len(npaudio):\n",
    "                        newfilename = filename.replace('/','-')\n",
    "                        pout_name = '{}-p_{}.wav'.format(newfilename, seg_idx)\n",
    "                        pout_path = os.path.join(pfolder_path, pout_name)            \n",
    "                        librosa.output.write_wav(pout_path, paudio[start_sp:end_sp], SR)\n",
    "                        filename_segs.append(pout_name.rstrip('.wav'))\n",
    "                        filepaths.append(os.path.join(folder, 'pedal-segment/', pout_name))\n",
    "                        ys.append(1)\n",
    "                        categories.append(folder)\n",
    "\n",
    "                        npout_name = '{}-np_{}.wav'.format(newfilename, seg_idx)\n",
    "                        npout_path = os.path.join(npfolder_path, npout_name)\n",
    "                        librosa.output.write_wav(npout_path, npaudio[start_sp:end_sp], SR)\n",
    "                        filename_segs.append(npout_name.rstrip('.wav'))\n",
    "                        filepaths.append(os.path.join(folder, 'non-pedal-segment/', npout_name))\n",
    "                        ys.append(0)\n",
    "                        categories.append(folder)\n",
    "\n",
    "    write_to_csv(zip(*[filename_segs, filepaths, ys, categories]), \n",
    "                 ['filename', 'filepath', 'label', 'category'], \n",
    "                 'pedal-segment_vd.csv')\n",
    "    print('pedal-segment_vd.csv is saved!')    \n",
    "    \n",
    "\n",
    "\n",
    "def print_usage():\n",
    "    print('This script trims excerpts from origninal audio files and saves them as new wav files.')\n",
    "    print('$ python main_preprocess.py $dataset_name$')\n",
    "    print('Example:')\n",
    "    print('$ python main_preprocess.py pedal-onset-dataset')\n",
    "    print('$ python main_preprocess.py pedal-segment-dataset')\n",
    "    print('')\n",
    "    print('Ps. Make sure you have the rendered dataset already and set the dirs/paths in config.json')\n",
    "    \n",
    "    \n",
    "def main(args):\n",
    "    dataset_name = args.dataset_name\n",
    "    if dataset_name == 'pedal-onset-dataset':\n",
    "        prep_pedal_onset()\n",
    "    elif dataset_name == 'pedal-segment-dataset':\n",
    "        prep_pedal_segment()\n",
    "    else:\n",
    "        print_usage()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description = \"Preprocess the rendered audio to trim it into excerpts.\") \n",
    "    parser.add_argument(\"dataset_name\", type=str, help=\"name of the dataset.\")\n",
    "    main(parser.parse_args()) \n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the excerpts are obtained for each datasets.\n",
    "\n",
    "### pedal-onset-dataset\n",
    "\n",
    "1234920 excerpts in total\n",
    "- 893062 @ /train\n",
    "- 241670 @ /valid\n",
    "- 100188 @ /test\n",
    "\n",
    "duration info (hours/minutes/seconds): 87:31:00 in total\n",
    "- 2 x 446531 x 0.5 = 124:02:11 (72.32%)\n",
    "- 2 x 120835 x 0.5 =  33:33:55 (19.57%)\n",
    "- 2 x  50094 x 0.5 =  13:54:54 ( 8.11%)\n",
    "\n",
    "### pedal-segment-dataset\n",
    "\n",
    "983822 excerpts in total\n",
    "- 707944 @ /train\n",
    "- 195454 @ /valid\n",
    "-  80424 @ /test\n",
    "\n",
    "excerpts are varied in duration (between 0.3-2.3s)\n",
    "\n",
    "if set 2s as the fixed length then 546:34:04 in total\n",
    "- 2 x 353972 x 2 = 393:18:08 (71.96%)\n",
    "- 2 x  97727 x 2 = 108:35:08 (19.87%)\n",
    "- 2 x  40212 x 2 =  44:40:48 ( 8.17%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode the wav excerpts into fixed length of npy files.\n",
    "\n",
    "For pedal-onset excerpts, the length are 0.5s.\n",
    "\n",
    "For pedal-segment excerpts, set the length to 2s. For signals that are shorter than 2s, repeat those signals to create 2-second signals.\n",
    "\n",
    "## `main_decode.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function  # (at top of module)\n",
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "from global_config import *\n",
    "\n",
    "def load_save_pedal_onset_npy(track_id):\n",
    "    \"\"\"\n",
    "    Load, decode, and save tracks of pedal onset dataset.\n",
    "    Load/Save paths are set by `config.json`.\n",
    "    track_id : integer. e.g. 2\n",
    "    \"\"\"\n",
    "    audio_path = os.path.join(DIR_PEDAL_ONSET,DF_ONSET.loc[[track_id]].filepath.values[0])\n",
    "    src, _ = librosa.load(audio_path, sr=SR)\n",
    "    src = src.astype(np.float16)    \n",
    "    npy_path = os.path.join(DIR_PEDAL_ONSET_NPY,DF_ONSET.loc[[track_id]].filepath.values[0].split('.')[0]+'.npy')\n",
    "    np.save(npy_path, src)\n",
    "    \n",
    "    print('  {}'.format(DF_ONSET.loc[[track_id]].filename.values[0]))\n",
    "\n",
    "\n",
    "def decode_pedal_onset():\n",
    "    \"\"\"\n",
    "    Decode rendered onset dataset and store them in numpy arrays.\n",
    "    16-bit Float, SR=44100, and 0.5s\n",
    "    \"\"\"\n",
    "    for folder in FOLDERS:\n",
    "        print('{}..'.format(folder))\n",
    "\n",
    "        pfolder_path = os.path.join(DIR_PEDAL_ONSET_NPY, folder, 'pedal-onset/')\n",
    "        npfolder_path = os.path.join(DIR_PEDAL_ONSET_NPY, folder, 'non-pedal-onset/')\n",
    "        if not os.path.exists(pfolder_path):\n",
    "            os.makedirs(pfolder_path)\n",
    "        if not os.path.exists(npfolder_path):\n",
    "            os.makedirs(npfolder_path)\n",
    "            \n",
    "        tracks_folder = DF_ONSET['category'] == folder\n",
    "        indices = DF_ONSET.loc[tracks_folder].index\n",
    "\n",
    "        # decoding\n",
    "        p = multiprocessing.Pool()\n",
    "        p.map(load_save_pedal_onset_npy, indices)\n",
    "        \n",
    "        \n",
    "def load_save_pedal_segment_npy(track_id):\n",
    "    \"\"\"\n",
    "    Load, decode, and save tracks of pedal segment dataset.\n",
    "    Load/Save paths are set by `config.json`.\n",
    "    track_id : integer. e.g. 2\n",
    "    \"\"\"\n",
    "    audio_path = os.path.join(DIR_PEDAL_SEGMENT,DF_SEGMENT.loc[[track_id]].filepath.values[0])\n",
    "    src, _ = librosa.load(audio_path, sr=SR, duration=LEN_SRC)\n",
    "    if len(src) < NSP_SRC:\n",
    "        tile_times = int(np.ceil(NSP_SRC/len(src)))\n",
    "        src = np.tile(src, tile_times)[:NSP_SRC]\n",
    "    else:\n",
    "        src = src[:NSP_SRC]\n",
    "    src = src.astype(np.float16)    \n",
    "    npy_path = os.path.join(DIR_PEDAL_SEGMENT_NPY,DF_SEGMENT.loc[[track_id]].filepath.values[0].split('.')[0]+'.npy')\n",
    "    np.save(npy_path, src)\n",
    "    \n",
    "    print('  {}'.format(DF_SEGMENT.loc[[track_id]].filename.values[0]))\n",
    "\n",
    "\n",
    "def decode_pedal_segment():\n",
    "    \"\"\"\n",
    "    Decode rendered segment dataset and store them in numpy arrays.\n",
    "    16-bit Float, SR=44100, and 2s\n",
    "    \"\"\"    \n",
    "    for folder in FOLDERS:\n",
    "        print('{}..'.format(folder))\n",
    "\n",
    "        pfolder_path = os.path.join(DIR_PEDAL_SEGMENT_NPY, folder, 'pedal-segment/')\n",
    "        npfolder_path = os.path.join(DIR_PEDAL_SEGMENT_NPY, folder, 'non-pedal-segment/')\n",
    "        if not os.path.exists(pfolder_path):\n",
    "            os.makedirs(pfolder_path)\n",
    "        if not os.path.exists(npfolder_path):\n",
    "            os.makedirs(npfolder_path)\n",
    "            \n",
    "        tracks_folder = DF_SEGMENT['category'] == folder\n",
    "        indices = DF_SEGMENT.loc[tracks_folder].index\n",
    "\n",
    "        # decoding\n",
    "        p = multiprocessing.Pool()\n",
    "        p.map(load_save_pedal_segment_npy, indices)\n",
    "        \n",
    "        \n",
    "def print_usage():\n",
    "    print('This script decode audio excerpts and saves them as npy files.')\n",
    "    print('$ python main_decode.py $dataset_name$')\n",
    "    print('Example:')\n",
    "    print('$ python main_decode.py pedal-onset-dataset')\n",
    "    print('$ python main_decode.py pedal-segment-dataset')\n",
    "    print('')\n",
    "    print('Ps. Make sure you have run the preprocess and set the dirs/paths in config.json')\n",
    "    \n",
    "    \n",
    "def main(args):\n",
    "    dataset_name = args.dataset_name\n",
    "    if dataset_name == 'pedal-onset-dataset':\n",
    "        vd_pedal_onset = os.path.join(DIR_PEDAL_METADATA, 'pedal-onset_vd.csv')\n",
    "        global DF_ONSET\n",
    "        DF_ONSET = pd.read_csv(vd_pedal_onset)\n",
    "        decode_pedal_onset()\n",
    "    elif dataset_name == 'pedal-segment-dataset':\n",
    "        vd_pedal_segment = os.path.join(DIR_PEDAL_METADATA, 'pedal-segment_vd.csv')\n",
    "        global DF_SEGMENT\n",
    "        DF_SEGMENT = pd.read_csv(vd_pedal_segment)\n",
    "        decode_pedal_segment()\n",
    "    else:\n",
    "        print_usage()\n",
    " \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description = \"Decode audio excerpts and saves them as npy files.\") \n",
    "    parser.add_argument(\"dataset_name\", type=str, help=\"name of the dataset.\")\n",
    "    main(parser.parse_args()) \n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoded npy files are saved in `./piano-e-competition/pedal-dataset/`\n",
    "- `pedal-onset-npydataset/CATEGORY/(non-)pedal-onset/FILENAME-(n)p_NUMBER.npy` \n",
    "- `pedal-segment-npydataset/CATEGORY/(non-)pedal-segment/FILENAME-(n)p_NUMBER.npy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a small version of the datasets\n",
    "\n",
    "After generating the excerpts and corresponding npy files, we get the first 70000 training tracks, first 20000 validation tracks and first 10000 test tracks from pedal-onset-dataset and pedal-segment-dataset seperately to form the small version dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(rows, column_names, csv_fname):\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "    df.to_csv(os.path.join(DIR_PEDAL_METADATA, csv_fname))\n",
    "    \n",
    "vd_pedal_onset = os.path.join(DIR_PEDAL_METADATA, 'pedal-onset_vd.csv')\n",
    "global DF_ONSET\n",
    "DF_ONSET = pd.read_csv(vd_pedal_onset)\n",
    "small_vd_pedal_onset_filename = 'pedal-onset_npydf_small.csv'\n",
    "\n",
    "vd_pedal_segmnet = os.path.join(DIR_PEDAL_METADATA, 'pedal-segment_vd.csv')\n",
    "global DF_SEGMENT\n",
    "DF_SEGMENT = pd.read_csv(vd_pedal_segmnet)\n",
    "small_vd_pedal_segment_filename = 'pedal-segment_npydf_small.csv'\n",
    "\n",
    "track_categories = ['train', 'valid', 'test']\n",
    "dfs = [DF_ONSET, DF_SEGMENT]\n",
    "small_vd_filenames = [small_vd_pedal_onset_filename, small_vd_pedal_segment_filename]\n",
    "\n",
    "for df,small_vd_filename in zip(dfs, small_vd_filenames):\n",
    "    filename_segs = []\n",
    "    filepaths = []\n",
    "    ys = []\n",
    "    categories = []\n",
    "    \n",
    "    for category in track_categories:\n",
    "        if category == 'train':\n",
    "            tracks_n = 70000\n",
    "        elif category == 'valid':\n",
    "            tracks_n = 20000\n",
    "        elif category == 'test':\n",
    "            tracks_n = 10000\n",
    "        tracks_category = df['category'] == category\n",
    "        df_category = df.loc[tracks_category][:tracks_n]\n",
    "        for row in df_category.itertuples():\n",
    "            filename_segs.append(row.filename)\n",
    "            ys.append(row.label)\n",
    "            categories.append(row.category)\n",
    "            filepath = row.filepath.split('.')[0]+'.npy'\n",
    "            filepaths.append(filepath)        \n",
    "\n",
    "    write_to_csv(zip(*[filename_segs, filepaths, ys, categories]),\n",
    "                 ['filename', 'filepath', 'label', 'category'], small_vd_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
