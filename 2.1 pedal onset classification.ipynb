{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel-last, i.e., (None, n_freq, n_time, n_ch)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from builtins import range\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Flatten, Input, Reshape, Dropout, Permute\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # the number of the GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7 # percentage to be used\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from global_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(df_subset, ys, is_shuffle, batch_size=20):\n",
    "    \"\"\"Data generator.\n",
    "    df_subset: pandas dataframe, with rows subset\n",
    "    ys: numpy arrays, N-by-8 one-hot-encoded labels\n",
    "    is_shuffle: shuffle every batch if True.\n",
    "    batch_size: integer, size of batch. len(df_subset) % batch_size should be 0.\n",
    "    \"\"\"\n",
    "    n_data = len(df_subset)\n",
    "    n_batch = n_data // batch_size\n",
    "    if n_data % batch_size != 0:\n",
    "        print(\"= WARNING =\")\n",
    "        print(\"  n_data % batch_size != 0 but this code does not assume it\")\n",
    "        print(\"  so the residual {} sample(s) will be ignored.\".format(n_data % batch_size))\n",
    "\n",
    "    while True:\n",
    "        for batch_i in range(n_batch):\n",
    "            if is_shuffle:\n",
    "                batch_idxs = np.random.choice(n_data, batch_size, replace=False)\n",
    "            else:\n",
    "                batch_idxs = range(batch_i * batch_size, (batch_i + 1) * batch_size)\n",
    "\n",
    "            src_batch = np.array([np.load(os.path.join(DIR_PEDAL_ONSET_NPY, df_subset.loc[df_subset.index[i]].filepath.split('.')[0]+'.npy')) for i in batch_idxs],\n",
    "                                 dtype=K.floatx())\n",
    "            src_batch = src_batch[:, np.newaxis, :]  # make (batch, N) to (batch, 1, N) for kapre compatible\n",
    "\n",
    "            y_batch = np.array([ys[i] for i in batch_idxs],\n",
    "                               dtype=K.floatx())\n",
    "            \n",
    "            yield src_batch, y_batch\n",
    "        \n",
    "        \n",
    "def get_callbacks(name,patience):\n",
    "    if not os.path.exists(DIR_SAVE_MODEL):\n",
    "        os.makedirs(DIR_SAVE_MODEL)    \n",
    "    early_stopper = keras.callbacks.EarlyStopping(patience=patience)\n",
    "    model_saver = keras.callbacks.ModelCheckpoint(os.path.join(DIR_SAVE_MODEL,\"{}_best_model.h5\".format(name)),\n",
    "                                                  save_best_only=True)\n",
    "    weight_saver = keras.callbacks.ModelCheckpoint(os.path.join(DIR_SAVE_MODEL,\"{}_best_weights.h5\".format(name)),\n",
    "                                                   save_best_only=True,\n",
    "                                                   save_weights_only=True)\n",
    "    csv_logger = keras.callbacks.CSVLogger(os.path.join(DIR_SAVE_MODEL,\"{}.log\".format(name)))\n",
    "    return [early_stopper, model_saver, weight_saver, csv_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Invariant Models for Pedal-Onset Binary Classification\n",
    "\n",
    "use raw-audio input, which is converted to melspectrogram using Kapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_multi_kernel_shape(n_out, input_shape=ONSET_INPUT_SHAPE,\n",
    "                             out_activation='softmax'):\n",
    "    \"\"\"\n",
    "\n",
    "    Symbolic summary:\n",
    "    > c2' - p2 - c2 - p2 - c2 - p2 - c2 - p3 - d1\n",
    "    where c2' -> multiple kernel shapes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        n_out: integer, number of output nodes\n",
    "        input_shape: tuple, an input shape, which doesn't include batch-axis.\n",
    "        out_activation: activation function on the output\n",
    "    \"\"\"\n",
    "    audio_input = Input(shape=input_shape)\n",
    "\n",
    "    x = Melspectrogram(n_dft=N_FFT, n_hop=HOP_LENGTH, sr=SR, n_mels=128, power_melgram=2.0, return_decibel_melgram=True)(audio_input)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "    x1 = Conv2D(7, (20, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x2 = Conv2D(7, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x3 = Conv2D(7, (3, 20), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "\n",
    "    x = Concatenate(axis=channel_axis)([x1, x2, x3])\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((4, 4), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    out = Dense(n_out, activation=out_activation, kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "\n",
    "    model = Model(audio_input, out)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_crnn_icassp2017_choi(n_out, input_shape=ONSET_INPUT_SHAPE,\n",
    "                               out_activation='softmax'):\n",
    "    \"\"\"A simplified model of \n",
    "    Convolutional Recurrent Neural Networks for Music Classification,\n",
    "    K Choi, G Fazekas, M Sandler, K Choi, ICASSP, 2017, New Orleans, USA\n",
    "\n",
    "    Symbolic summary:\n",
    "    > c2 - p2 - c2 - p2 - c2 - p2 - c2 - p2 - r1 - r2 - d1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        n_out: integer, number of output nodes\n",
    "        input_shape: tuple, an input shape, which doesn't include batch-axis.\n",
    "        out_activation: activation function on the output\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    audio_input = Input(shape=input_shape)\n",
    "\n",
    "    x = Melspectrogram(n_dft=N_FFT, n_hop=HOP_LENGTH, sr=SR, n_mels=128, power_melgram=2.0, return_decibel_melgram=True)(audio_input)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(21, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((4, 4), padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    if K.image_dim_ordering() == 'channels_first':\n",
    "        x = Permute((3, 1, 2))(x)\n",
    "\n",
    "    x = Reshape((-1, 21))(x)\n",
    "\n",
    "    # GRU block 1, 2, output\n",
    "    x = GRU(41, return_sequences=True, name='gru1')(x)\n",
    "    x = GRU(41, return_sequences=False, name='gru2')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    out = Dense(n_out, activation=out_activation, kernel_regularizer=keras.regularizers.l2(reg_w))(x)\n",
    "\n",
    "    model = Model(audio_input, out)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_conv3x3_ismir2016_choi(n_out, input_shape=ONSET_INPUT_SHAPE,\n",
    "                                 out_activation='softmax'):\n",
    "    \"\"\" A simplified model of \n",
    "    Automatic Tagging Using Deep Convolutional Neural Networks,\n",
    "    K Choi, G Fazekas, M Sandler, ISMIR, 2016, New York, USA\n",
    "\n",
    "    Symbolic summary:\n",
    "    > c2 - p2 - c2 - p2 - c2 - p2 - c2 - p2 - c2 - p3 - d1\n",
    "\n",
    "    Modifications: \n",
    "        * n_mels (96 -> 32)\n",
    "        * n_channels (many -> [16, 24, 32, 40, 48])\n",
    "        * remove dropout\n",
    "        * maxpooling (irregular to fit the size -> all (2, 2))\n",
    "        * add GlobalAveragePooling2D\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Melspectrogram(n_dft=N_FFT, n_hop=HOP_LENGTH, sr=SR, n_mels=128, power_melgram=2.0, \n",
    "                             return_decibel_melgram=True,\n",
    "                             input_shape=input_shape))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "\n",
    "    model.add(Conv2D(10, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(15, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(15, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(20, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(20, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(n_out, activation=out_activation, kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_conv1d_icassp2014_sander(n_out, input_shape=ONSET_INPUT_SHAPE,\n",
    "                                   out_activation='softmax'):\n",
    "    \"\"\"A simplified model of\n",
    "    End-to-end learning for music audio,\n",
    "    Sander Dieleman and Benjamin Schrauwen, ICASSP, 2014\n",
    "\n",
    "    Symbolic summary:\n",
    "    > c1 - p1 - c1 - p1 - c1 - p1 - p3 - d1\n",
    "\n",
    "    Modifications: \n",
    "        * Add BatchNormalization\n",
    "        * n_mels (128 -> 32)\n",
    "        * n_layers (2 -> 3)\n",
    "        * add GlobalAveragePooling2D\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        n_out: integer, number of output nodes\n",
    "        input_shape: tuple, an input shape, which doesn't include batch-axis.\n",
    "        out_activation: activation function on the output\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Melspectrogram(n_dft=N_FFT, n_hop=HOP_LENGTH, sr=SR, n_mels=128, power_melgram=2.0, \n",
    "                             return_decibel_melgram=True,input_shape=input_shape))\n",
    "    model.add(Conv2D(30, (32, 4), padding='valid', kernel_regularizer=keras.regularizers.l2(reg_w)))  # (None, 16, 1, N)\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((1, 4), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(30, (1, 4), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((1, 4), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(30, (1, 4), padding='same', kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((1, 4), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(n_out, activation=out_activation, kernel_regularizer=keras.regularizers.l2(reg_w)))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_w = 1e-4\n",
    "batch_size = 250\n",
    "epochs = 50\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the small dataset to see which model returns the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! Lets do something deep with pedal-onset_npydf_small.csv.\n",
      "I'm assuming you finished pre-processing.\n",
      "------------------------------------------------------------\n",
      "We're gonna use cnn3x3 model.\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 545s 2s/step - loss: 0.6059 - acc: 0.6690 - val_loss: 1.1014 - val_acc: 0.5237\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 234s 836ms/step - loss: 0.4855 - acc: 0.7730 - val_loss: 1.0581 - val_acc: 0.5935\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 190s 680ms/step - loss: 0.4364 - acc: 0.8043 - val_loss: 0.5581 - val_acc: 0.7404\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 170s 607ms/step - loss: 0.4025 - acc: 0.8246 - val_loss: 1.6448 - val_acc: 0.5305\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 167s 595ms/step - loss: 0.3777 - acc: 0.8392 - val_loss: 0.5180 - val_acc: 0.7587\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 168s 601ms/step - loss: 0.3590 - acc: 0.8494 - val_loss: 0.4732 - val_acc: 0.7824\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 156s 558ms/step - loss: 0.3454 - acc: 0.8543 - val_loss: 0.5798 - val_acc: 0.7493\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 153s 547ms/step - loss: 0.3267 - acc: 0.8668 - val_loss: 1.2700 - val_acc: 0.5662\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 163s 582ms/step - loss: 0.3180 - acc: 0.8703 - val_loss: 0.9607 - val_acc: 0.6456\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 160s 572ms/step - loss: 0.3124 - acc: 0.8734 - val_loss: 1.2884 - val_acc: 0.5839\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 161s 575ms/step - loss: 0.3031 - acc: 0.8773 - val_loss: 0.4072 - val_acc: 0.8240\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 162s 579ms/step - loss: 0.2988 - acc: 0.8792 - val_loss: 0.3415 - val_acc: 0.8534\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 159s 569ms/step - loss: 0.2920 - acc: 0.8820 - val_loss: 0.6445 - val_acc: 0.7473\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 160s 573ms/step - loss: 0.2885 - acc: 0.8839 - val_loss: 0.6179 - val_acc: 0.7540\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 161s 573ms/step - loss: 0.2833 - acc: 0.8868 - val_loss: 0.4146 - val_acc: 0.8216\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 158s 565ms/step - loss: 0.2815 - acc: 0.8858 - val_loss: 0.6494 - val_acc: 0.7475\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 159s 569ms/step - loss: 0.2732 - acc: 0.8916 - val_loss: 0.7617 - val_acc: 0.7301\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 162s 577ms/step - loss: 0.2726 - acc: 0.8925 - val_loss: 0.3026 - val_acc: 0.8730\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 157s 562ms/step - loss: 0.2731 - acc: 0.8903 - val_loss: 0.3449 - val_acc: 0.8542\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 158s 565ms/step - loss: 0.2705 - acc: 0.8916 - val_loss: 0.4213 - val_acc: 0.8226\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 156s 559ms/step - loss: 0.2648 - acc: 0.8949 - val_loss: 0.6758 - val_acc: 0.7514\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 153s 545ms/step - loss: 0.2652 - acc: 0.8958 - val_loss: 0.3472 - val_acc: 0.8527\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 160s 570ms/step - loss: 0.2612 - acc: 0.8966 - val_loss: 0.2436 - val_acc: 0.9050\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 154s 548ms/step - loss: 0.2642 - acc: 0.8949 - val_loss: 0.3546 - val_acc: 0.8482\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 158s 564ms/step - loss: 0.2586 - acc: 0.8982 - val_loss: 0.3388 - val_acc: 0.8560\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 159s 568ms/step - loss: 0.2592 - acc: 0.8980 - val_loss: 0.5617 - val_acc: 0.7803\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 161s 574ms/step - loss: 0.2570 - acc: 0.8979 - val_loss: 0.5303 - val_acc: 0.7887\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 157s 561ms/step - loss: 0.2588 - acc: 0.8968 - val_loss: 0.6417 - val_acc: 0.7608\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 166s 592ms/step - loss: 0.2565 - acc: 0.8985 - val_loss: 0.6319 - val_acc: 0.7459\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 160s 573ms/step - loss: 0.2518 - acc: 0.9017 - val_loss: 0.5576 - val_acc: 0.7830\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 158s 565ms/step - loss: 0.2533 - acc: 0.8986 - val_loss: 0.2811 - val_acc: 0.8856\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 154s 551ms/step - loss: 0.2486 - acc: 0.9025 - val_loss: 0.3101 - val_acc: 0.8719\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 153s 547ms/step - loss: 0.2470 - acc: 0.9036 - val_loss: 0.8616 - val_acc: 0.6844\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for cnn3x3!\n",
      "        valid set loss: 0.28283693213\n",
      "        valid set accuracy: 0.885200031847\n",
      "        valid set auc: 0.97913378\n",
      "------------------------------------------------------------\n",
      "We're gonna use multi_kernel model.\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 169s 602ms/step - loss: 0.6630 - acc: 0.6084 - val_loss: 0.8288 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 159s 567ms/step - loss: 0.4764 - acc: 0.7789 - val_loss: 1.0595 - val_acc: 0.5007\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 159s 566ms/step - loss: 0.4146 - acc: 0.8166 - val_loss: 0.4011 - val_acc: 0.8210\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 161s 576ms/step - loss: 0.3840 - acc: 0.8331 - val_loss: 0.8558 - val_acc: 0.5566\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 161s 574ms/step - loss: 0.3593 - acc: 0.8453 - val_loss: 0.3073 - val_acc: 0.8862\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 159s 569ms/step - loss: 0.3455 - acc: 0.8536 - val_loss: 0.2928 - val_acc: 0.8945\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 158s 566ms/step - loss: 0.3242 - acc: 0.8665 - val_loss: 0.6682 - val_acc: 0.6463\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 160s 571ms/step - loss: 0.2992 - acc: 0.8792 - val_loss: 0.2620 - val_acc: 0.9086\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 158s 565ms/step - loss: 0.2779 - acc: 0.8895 - val_loss: 0.2950 - val_acc: 0.8839\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 160s 571ms/step - loss: 0.2647 - acc: 0.8960 - val_loss: 0.2986 - val_acc: 0.8731\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 164s 586ms/step - loss: 0.2563 - acc: 0.9002 - val_loss: 0.2575 - val_acc: 0.9014\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 160s 572ms/step - loss: 0.2475 - acc: 0.9037 - val_loss: 0.2262 - val_acc: 0.9248\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 161s 574ms/step - loss: 0.2380 - acc: 0.9083 - val_loss: 0.2238 - val_acc: 0.9187\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 161s 575ms/step - loss: 0.2317 - acc: 0.9112 - val_loss: 0.2084 - val_acc: 0.9218\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 158s 564ms/step - loss: 0.2291 - acc: 0.9128 - val_loss: 0.2045 - val_acc: 0.9311\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 161s 577ms/step - loss: 0.2266 - acc: 0.9129 - val_loss: 0.1871 - val_acc: 0.9380\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 161s 574ms/step - loss: 0.2216 - acc: 0.9163 - val_loss: 0.2056 - val_acc: 0.9325\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 159s 567ms/step - loss: 0.2199 - acc: 0.9164 - val_loss: 0.2012 - val_acc: 0.9320\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 162s 577ms/step - loss: 0.2165 - acc: 0.9178 - val_loss: 0.4824 - val_acc: 0.7413\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 161s 574ms/step - loss: 0.2140 - acc: 0.9186 - val_loss: 0.1878 - val_acc: 0.9350\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 154s 551ms/step - loss: 0.2105 - acc: 0.9206 - val_loss: 0.2107 - val_acc: 0.9248\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 158s 564ms/step - loss: 0.2130 - acc: 0.9193 - val_loss: 0.2098 - val_acc: 0.9255\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 151s 541ms/step - loss: 0.2095 - acc: 0.9212 - val_loss: 0.2391 - val_acc: 0.9084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "280/280 [==============================] - 155s 554ms/step - loss: 0.2088 - acc: 0.9222 - val_loss: 0.1857 - val_acc: 0.9381\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 159s 570ms/step - loss: 0.2064 - acc: 0.9223 - val_loss: 0.1827 - val_acc: 0.9373\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 157s 562ms/step - loss: 0.2014 - acc: 0.9256 - val_loss: 0.1784 - val_acc: 0.9416\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 163s 580ms/step - loss: 0.2020 - acc: 0.9241 - val_loss: 0.1852 - val_acc: 0.9387\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 159s 567ms/step - loss: 0.2025 - acc: 0.9254 - val_loss: 0.1696 - val_acc: 0.9449\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 159s 570ms/step - loss: 0.1998 - acc: 0.9261 - val_loss: 0.1714 - val_acc: 0.9452\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 177s 633ms/step - loss: 0.2008 - acc: 0.9247 - val_loss: 0.2359 - val_acc: 0.9087\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 161s 576ms/step - loss: 0.2008 - acc: 0.9249 - val_loss: 0.1843 - val_acc: 0.9342\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 179s 638ms/step - loss: 0.2003 - acc: 0.9248 - val_loss: 0.1772 - val_acc: 0.9388\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 164s 585ms/step - loss: 0.2001 - acc: 0.9252 - val_loss: 0.2361 - val_acc: 0.9164\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 181s 645ms/step - loss: 0.1994 - acc: 0.9263 - val_loss: 0.2267 - val_acc: 0.9135\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 206s 735ms/step - loss: 0.1963 - acc: 0.9269 - val_loss: 0.2159 - val_acc: 0.9258\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 197s 704ms/step - loss: 0.1970 - acc: 0.9263 - val_loss: 0.1913 - val_acc: 0.9307\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 215s 766ms/step - loss: 0.1944 - acc: 0.9282 - val_loss: 0.2191 - val_acc: 0.9173\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 197s 705ms/step - loss: 0.1949 - acc: 0.9272 - val_loss: 0.1633 - val_acc: 0.9454\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 210s 751ms/step - loss: 0.1915 - acc: 0.9288 - val_loss: 0.1756 - val_acc: 0.9392\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - 202s 720ms/step - loss: 0.1939 - acc: 0.9281 - val_loss: 0.2323 - val_acc: 0.9123\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - 207s 739ms/step - loss: 0.1903 - acc: 0.9299 - val_loss: 0.1735 - val_acc: 0.9399\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - 199s 711ms/step - loss: 0.1904 - acc: 0.9288 - val_loss: 0.1923 - val_acc: 0.9303\n",
      "Epoch 43/50\n",
      "280/280 [==============================] - 198s 706ms/step - loss: 0.1905 - acc: 0.9290 - val_loss: 0.1700 - val_acc: 0.9432\n",
      "Epoch 44/50\n",
      "280/280 [==============================] - 190s 678ms/step - loss: 0.1925 - acc: 0.9296 - val_loss: 0.1940 - val_acc: 0.9362\n",
      "Epoch 45/50\n",
      "280/280 [==============================] - 203s 726ms/step - loss: 0.1931 - acc: 0.9288 - val_loss: 0.2708 - val_acc: 0.8859\n",
      "Epoch 46/50\n",
      "280/280 [==============================] - 195s 698ms/step - loss: 0.1895 - acc: 0.9314 - val_loss: 0.1774 - val_acc: 0.9385\n",
      "Epoch 47/50\n",
      "280/280 [==============================] - 194s 694ms/step - loss: 0.1903 - acc: 0.9286 - val_loss: 0.1941 - val_acc: 0.9342\n",
      "Epoch 48/50\n",
      "280/280 [==============================] - 194s 695ms/step - loss: 0.1899 - acc: 0.9298 - val_loss: 0.1628 - val_acc: 0.9478\n",
      "Epoch 49/50\n",
      "280/280 [==============================] - 192s 686ms/step - loss: 0.1872 - acc: 0.9312 - val_loss: 0.2433 - val_acc: 0.9054\n",
      "Epoch 50/50\n",
      "280/280 [==============================] - 198s 708ms/step - loss: 0.1882 - acc: 0.9304 - val_loss: 0.1625 - val_acc: 0.9453\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for multi_kernel!\n",
      "        valid set loss: 0.173930586688\n",
      "        valid set accuracy: 0.939100044221\n",
      "        valid set auc: 0.9852458\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'pedal-onset_npydf_small.csv'\n",
    "csv_path = os.path.join(DIR_PEDAL_METADATA, dataset_name)\n",
    "tracks = pd.read_csv(csv_path)\n",
    "training = tracks.loc[tracks['category'] == 'train']\n",
    "validation = tracks.loc[tracks['category'] == 'valid']\n",
    "test = tracks.loc[tracks['category'] == 'test']\n",
    "\n",
    "# make labels as one-hot vector\n",
    "y_train = training.label.values\n",
    "y_valid = validation.label.values\n",
    "y_test = test.label.values\n",
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_valid = keras.utils.to_categorical(y_valid, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)\n",
    "\n",
    "# preparing data generators\n",
    "steps_per_epoch = len(y_train) // batch_size\n",
    "gen_train = data_gen(training, y_train, True, batch_size=batch_size)\n",
    "gen_valid = data_gen(validation, y_valid, False, batch_size=batch_size)\n",
    "gen_test = data_gen(test, y_test, False, batch_size=batch_size)\n",
    "\n",
    "print(\"Welcome! Lets do something deep with {}.\".format(dataset_name))\n",
    "print(\"I'm assuming you finished pre-processing.\")\n",
    "\n",
    "model_names = ['cnn3x3','multi_kernel']\n",
    "for model_name in model_names:\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(\"We're gonna use {} model.\".format(model_name))\n",
    "    exp_name = 'small-onset_{}'.format(model_name)\n",
    "\n",
    "    # callbacks\n",
    "    callbacks = get_callbacks(name=exp_name, patience=patience)\n",
    "    early_stopper, model_saver, weight_saver, csv_logger = callbacks\n",
    "\n",
    "    print(\"Getting model...\")\n",
    "    if model_name == 'multi_kernel':\n",
    "        model = model_multi_kernel_shape(n_out=2)\n",
    "    elif model_name == 'crnn':\n",
    "        model = model_crnn_icassp2017_choi(n_out=2)\n",
    "    elif model_name == 'cnn3x3':\n",
    "        model = model_conv3x3_ismir2016_choi(n_out=2)\n",
    "    elif model_name == 'cnn1d':\n",
    "        model = model_conv1d_icassp2014_sander(n_out=2)\n",
    "\n",
    "    # model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "    # model.summary()\n",
    "\n",
    "    print(\"Starting to train...\")\n",
    "    model.fit_generator(gen_train, steps_per_epoch, epochs=epochs,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=gen_valid,\n",
    "                        validation_steps=len(y_valid) // batch_size)\n",
    "\n",
    "    print(\"Training is done. Loading the best weights...\")\n",
    "    model.load_weights(os.path.join(DIR_SAVE_MODEL,\"{}_best_weights.h5\".format(exp_name)))\n",
    "\n",
    "    print(\"Evaluating...\")\n",
    "    scores = model.evaluate_generator(gen_test, len(y_valid) // batch_size)\n",
    "    y_pred = model.predict_generator(gen_test, len(y_valid) // batch_size)\n",
    "    auc = roc_auc_score(y_valid, y_pred)\n",
    "\n",
    "    print(\"Result: Done for {}!\".format(model_name))\n",
    "    print(\"        valid set loss: {}\".format(scores[0]))\n",
    "    print(\"        valid set accuracy: {}\".format(scores[1]))\n",
    "    print(\"        valid set auc: {}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the best model and train it on the large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Beici: Welcome! Lets do something deep with pedal-onset_vd.csv.\n",
      "       I'm assuming you finished pre-processing.\n",
      "       We're gonna use multi_kernel model.\n",
      "Beici: Getting model...\n",
      "Beici: Starting to train...\n",
      "= WARNING =\n",
      "  n_data % batch_size != 0 but this code does not assume itEpoch 1/50\n",
      "\n",
      "  so the residual 46 sample(s) will be ignored.\n",
      "3571/3572 [============================>.] - ETA: 2s - loss: 0.3197 - acc: 0.8658= WARNING =\n",
      "  n_data % batch_size != 0 but this code does not assume it\n",
      "  so the residual 170 sample(s) will be ignored.\n",
      "3572/3572 [==============================] - 12667s 4s/step - loss: 0.3197 - acc: 0.8659 - val_loss: 0.2132 - val_acc: 0.9237\n",
      "Epoch 2/50\n",
      "3572/3572 [==============================] - 8093s 2s/step - loss: 0.2147 - acc: 0.9197 - val_loss: 0.2178 - val_acc: 0.9189\n",
      "Epoch 3/50\n",
      "3572/3572 [==============================] - 4603s 1s/step - loss: 0.1978 - acc: 0.9270 - val_loss: 0.3236 - val_acc: 0.8569\n",
      "Epoch 4/50\n",
      "3572/3572 [==============================] - 4626s 1s/step - loss: 0.1897 - acc: 0.9305 - val_loss: 0.1854 - val_acc: 0.9315\n",
      "Epoch 5/50\n",
      "3572/3572 [==============================] - 3762s 1s/step - loss: 0.1868 - acc: 0.9320 - val_loss: 0.1799 - val_acc: 0.9346\n",
      "Epoch 6/50\n",
      "3572/3572 [==============================] - 3370s 943ms/step - loss: 0.1842 - acc: 0.9333 - val_loss: 0.1704 - val_acc: 0.9401\n",
      "Epoch 7/50\n",
      "3572/3572 [==============================] - 3433s 961ms/step - loss: 0.1818 - acc: 0.9345 - val_loss: 0.2080 - val_acc: 0.9229\n",
      "Epoch 8/50\n",
      "3572/3572 [==============================] - 3269s 915ms/step - loss: 0.1813 - acc: 0.9347 - val_loss: 0.1941 - val_acc: 0.9275\n",
      "Epoch 9/50\n",
      "3572/3572 [==============================] - 3033s 849ms/step - loss: 0.1791 - acc: 0.9353 - val_loss: 0.1618 - val_acc: 0.9460\n",
      "Epoch 10/50\n",
      "3572/3572 [==============================] - 2868s 803ms/step - loss: 0.1782 - acc: 0.9360 - val_loss: 0.1873 - val_acc: 0.9310\n",
      "Epoch 11/50\n",
      "3572/3572 [==============================] - 4876s 1s/step - loss: 0.1774 - acc: 0.9361 - val_loss: 0.1630 - val_acc: 0.9432\n",
      "Epoch 12/50\n",
      "3572/3572 [==============================] - 6187s 2s/step - loss: 0.1769 - acc: 0.9370 - val_loss: 0.1721 - val_acc: 0.9379\n",
      "Epoch 13/50\n",
      "3572/3572 [==============================] - 5427s 2s/step - loss: 0.1760 - acc: 0.9373 - val_loss: 0.1717 - val_acc: 0.9408\n",
      "Epoch 14/50\n",
      "3572/3572 [==============================] - 5095s 1s/step - loss: 0.1751 - acc: 0.9378 - val_loss: 0.1818 - val_acc: 0.9371\n",
      "Epoch 15/50\n",
      "3572/3572 [==============================] - 4667s 1s/step - loss: 0.1748 - acc: 0.9380 - val_loss: 0.1595 - val_acc: 0.9444\n",
      "Epoch 16/50\n",
      "3572/3572 [==============================] - 4845s 1s/step - loss: 0.1741 - acc: 0.9381 - val_loss: 0.1652 - val_acc: 0.9422\n",
      "Epoch 17/50\n",
      "3572/3572 [==============================] - 5030s 1s/step - loss: 0.1717 - acc: 0.9393 - val_loss: 0.1552 - val_acc: 0.9454\n",
      "Epoch 18/50\n",
      "3572/3572 [==============================] - 4673s 1s/step - loss: 0.1725 - acc: 0.9392 - val_loss: 0.1594 - val_acc: 0.9458\n",
      "Epoch 19/50\n",
      "3572/3572 [==============================] - 4521s 1s/step - loss: 0.1723 - acc: 0.9393 - val_loss: 0.1728 - val_acc: 0.9400\n",
      "Epoch 20/50\n",
      "3572/3572 [==============================] - 3874s 1s/step - loss: 0.1717 - acc: 0.9390 - val_loss: 0.1558 - val_acc: 0.9453\n",
      "Epoch 21/50\n",
      "3572/3572 [==============================] - 3033s 849ms/step - loss: 0.1710 - acc: 0.9398 - val_loss: 0.1839 - val_acc: 0.9376\n",
      "Epoch 22/50\n",
      "3572/3572 [==============================] - 2980s 834ms/step - loss: 0.1717 - acc: 0.9395 - val_loss: 0.3065 - val_acc: 0.8806\n",
      "Epoch 23/50\n",
      "3572/3572 [==============================] - 3099s 867ms/step - loss: 0.1713 - acc: 0.9395 - val_loss: 0.1712 - val_acc: 0.9409\n",
      "Epoch 24/50\n",
      "3572/3572 [==============================] - 2946s 825ms/step - loss: 0.1713 - acc: 0.9399 - val_loss: 0.1631 - val_acc: 0.9470\n",
      "Epoch 25/50\n",
      "3572/3572 [==============================] - 2853s 799ms/step - loss: 0.1703 - acc: 0.9401 - val_loss: 0.1832 - val_acc: 0.9345\n",
      "Epoch 26/50\n",
      "3572/3572 [==============================] - 2810s 787ms/step - loss: 0.1703 - acc: 0.9401 - val_loss: 0.1773 - val_acc: 0.9394\n",
      "Epoch 27/50\n",
      "3572/3572 [==============================] - 2664s 746ms/step - loss: 0.1695 - acc: 0.9404 - val_loss: 0.2254 - val_acc: 0.9162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13c44ed0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'pedal-onset_vd.csv'\n",
    "model_name = 'multi_kernel'\n",
    "exp_name = 'onset_{}'.format(model_name)\n",
    "reg_w = 1e-4\n",
    "batch_size = 250\n",
    "epochs = 50\n",
    "patience = 10\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"Beici: Welcome! Lets do something deep with {}.\".format(dataset_name))\n",
    "print(\"       I'm assuming you finished pre-processing.\")\n",
    "print(\"       We're gonna use {} model.\".format(model_name))\n",
    "csv_path = os.path.join(DIR_PEDAL_METADATA, dataset_name)\n",
    "\n",
    "tracks = pd.read_csv(csv_path)\n",
    "training = tracks.loc[tracks['category'] == 'train']\n",
    "validation = tracks.loc[tracks['category'] == 'valid']\n",
    "test = tracks.loc[tracks['category'] == 'test']\n",
    "\n",
    "# print(\"Beici: We're loading and modifying label values.\")\n",
    "y_train = training.label.values\n",
    "y_valid = validation.label.values\n",
    "y_test = test.label.values\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_valid = keras.utils.to_categorical(y_valid, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)\n",
    "\n",
    "# callbacks\n",
    "callbacks = get_callbacks(name=exp_name, patience=patience)\n",
    "early_stopper, model_saver, weight_saver, csv_logger = callbacks\n",
    "\n",
    "# print(\"Beici: Preparing data generators for training and validation...\")\n",
    "steps_per_epoch = len(y_train) // batch_size\n",
    "gen_train = data_gen(training, y_train, True, batch_size=batch_size)\n",
    "gen_valid = data_gen(validation, y_valid, False, batch_size=batch_size)\n",
    "gen_test = data_gen(test, y_test, False, batch_size=batch_size)\n",
    "\n",
    "print(\"Beici: Getting model...\")\n",
    "if model_name == 'multi_kernel':\n",
    "    model = model_multi_kernel_shape(n_out=2)\n",
    "elif model_name == 'crnn':\n",
    "    model = model_crnn_icassp2017_choi(n_out=2)\n",
    "elif model_name == 'cnn3x3':\n",
    "    model = model_conv3x3_ismir2016_choi(n_out=2)\n",
    "elif model_name == 'cnn1d':\n",
    "    model = model_conv1d_icassp2014_sander(n_out=2)\n",
    "\n",
    "# model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "print(\"Beici: Starting to train...\")\n",
    "model.fit_generator(gen_train, steps_per_epoch, epochs=epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=gen_valid,\n",
    "                    validation_steps=len(y_valid) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Beici: Training is done. Loading the best weights...\")\n",
    "model.load_weights(os.path.join(DIR_SAVE_MODEL,\"{}_best_weights.h5\".format(exp_name)))\n",
    "\n",
    "print(\"       Evaluating...\")\n",
    "scores = model.evaluate_generator(gen_test, len(y_test) // batch_size)\n",
    "y_pred = model.predict_generator(gen_test, len(y_test) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beici: Done for multi_kernel!\n",
      "       test set loss: 0.160557327438\n",
      "       test set accuracy: 0.943290049285\n",
      "       test set auc: 0.9903246165\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test[:len(y_pred)], y_pred)\n",
    "\n",
    "print(\"Beici: Done for {}!\".format(model_name))\n",
    "print(\"       test set loss: {}\".format(scores[0]))\n",
    "print(\"       test set accuracy: {}\".format(scores[1]))\n",
    "print(\"       test set auc: {}\".format(auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
