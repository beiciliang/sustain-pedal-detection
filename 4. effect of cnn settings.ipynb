{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel-last, i.e., (None, n_freq, n_time, n_ch)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from builtins import range\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Flatten, Input, Reshape, Dropout, Permute\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # the number of the GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1 # percentage to be used\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "from kapre.time_frequency import Melspectrogram, Spectrogram\n",
    "from global_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(dataset_type, df_subset, ys, is_shuffle, batch_size=20):\n",
    "    \"\"\"Data generator.\n",
    "    dataset_type: onset or segment\n",
    "    df_subset: pandas dataframe, with rows subset\n",
    "    ys: numpy arrays, N-by-8 one-hot-encoded labels\n",
    "    is_shuffle: shuffle every batch if True.\n",
    "    batch_size: integer, size of batch. len(df_subset) % batch_size should be 0.\n",
    "    \"\"\"\n",
    "    if dataset_type == \"onset\":\n",
    "        dir_pedal_npy = DIR_PEDAL_ONSET_NPY\n",
    "    elif dataset_type == \"segment\":\n",
    "        dir_pedal_npy = DIR_PEDAL_SEGMENT_NPY\n",
    "    else:\n",
    "        print(\"ERROR: dataset type must be either onset or segment!\")\n",
    "        \n",
    "    n_data = len(df_subset)\n",
    "    n_batch = n_data // batch_size\n",
    "#     if n_data % batch_size != 0:\n",
    "#         print(\"= WARNING =\")\n",
    "#         print(\"  n_data % batch_size != 0 but this code does not assume it\")\n",
    "#         print(\"  so the residual {} sample(s) will be ignored.\".format(n_data % batch_size))\n",
    "\n",
    "    while True:\n",
    "        for batch_i in range(n_batch):\n",
    "            if is_shuffle:\n",
    "                batch_idxs = np.random.choice(n_data, batch_size, replace=False)\n",
    "            else:\n",
    "                batch_idxs = range(batch_i * batch_size, (batch_i + 1) * batch_size)\n",
    "\n",
    "            src_batch = np.array([np.load(os.path.join(dir_pedal_npy, df_subset.loc[df_subset.index[i]].filepath.split('.')[0]+'.npy')) for i in batch_idxs],\n",
    "                                 dtype=K.floatx())\n",
    "            src_batch = src_batch[:, np.newaxis, :]  # make (batch, N) to (batch, 1, N) for kapre compatible\n",
    "\n",
    "            y_batch = np.array([ys[i] for i in batch_idxs],\n",
    "                               dtype=K.floatx())\n",
    "            \n",
    "            yield src_batch, y_batch\n",
    "        \n",
    "        \n",
    "def get_callbacks(name,patience):\n",
    "    if not os.path.exists(DIR_SAVE_MODEL):\n",
    "        os.makedirs(DIR_SAVE_MODEL)    \n",
    "    early_stopper = keras.callbacks.EarlyStopping(patience=patience)\n",
    "    model_saver = keras.callbacks.ModelCheckpoint(os.path.join(DIR_SAVE_MODEL,\"{}_best_model.h5\".format(name)),\n",
    "                                                  save_best_only=True)\n",
    "    weight_saver = keras.callbacks.ModelCheckpoint(os.path.join(DIR_SAVE_MODEL,\"{}_best_weights.h5\".format(name)),\n",
    "                                                   save_best_only=True,\n",
    "                                                   save_weights_only=True)\n",
    "    csv_logger = keras.callbacks.CSVLogger(os.path.join(DIR_SAVE_MODEL,\"{}.log\".format(name)))\n",
    "    return [early_stopper, model_saver, weight_saver, csv_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram vs Mel-Spectrogram using a simple conv3x3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_conv3x3_spectrogram(n_out, inputshape, out_activation='softmax'):\n",
    "    \"\"\"\n",
    "    A simple conv3x3 model using spectrogram as input.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Spectrogram(n_dft=N_FFT, n_hop=HOP_LENGTH, power_spectrogram=2.0, \n",
    "                          return_decibel_spectrogram=True, input_shape=inputshape))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "\n",
    "    model.add(Conv2D(21, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    \n",
    "    model.add(Conv2D(21, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv2D(21, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv2D(21, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((4, 4), padding='same'))\n",
    "    \n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(n_out, activation=out_activation))\n",
    "\n",
    "    return model\n",
    "\n",
    "def model_conv3x3_melspectrogram(n_out, inputshape, out_activation='softmax'):\n",
    "    \"\"\"\n",
    "    A simple conv3x3 model using mel spectrogram as input.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Melspectrogram(n_dft=N_FFT, n_hop=HOP_LENGTH, sr=SR, n_mels=128, power_melgram=2.0, \n",
    "                             return_decibel_melgram=True,\n",
    "                             input_shape=inputshape))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "\n",
    "    model.add(Conv2D(21, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    \n",
    "    model.add(Conv2D(21, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv2D(21, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv2D(21, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((4, 4), padding='same'))\n",
    "    \n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(n_out, activation=out_activation))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_w = 1e-4\n",
    "epochs = 50\n",
    "patience = 10\n",
    "confidence_interval_times = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test on sub excerpts of segment.\n",
      "----------------------------------------\n",
      "We're gonna use cnn3x3-spectrogram model.\n",
      "--- experiment index of 0 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 963s 2s/step - loss: 0.3304 - acc: 0.8637 - val_loss: 2.7852 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 374s 962ms/step - loss: 0.1904 - acc: 0.9307 - val_loss: 4.5724 - val_acc: 0.5112\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 237s 609ms/step - loss: 0.1476 - acc: 0.9483 - val_loss: 1.1592 - val_acc: 0.7050\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 199s 513ms/step - loss: 0.1272 - acc: 0.9555 - val_loss: 0.3425 - val_acc: 0.8573\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 199s 512ms/step - loss: 0.1156 - acc: 0.9598 - val_loss: 7.9133 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 201s 516ms/step - loss: 0.1005 - acc: 0.9646 - val_loss: 0.7063 - val_acc: 0.7571\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 200s 514ms/step - loss: 0.0981 - acc: 0.9646 - val_loss: 1.0941 - val_acc: 0.7426\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 201s 518ms/step - loss: 0.0871 - acc: 0.9698 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 201s 518ms/step - loss: 0.0830 - acc: 0.9704 - val_loss: 0.0891 - val_acc: 0.9717\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 202s 520ms/step - loss: 0.0785 - acc: 0.9720 - val_loss: 1.3484 - val_acc: 0.7205\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.0741 - acc: 0.9754 - val_loss: 0.6766 - val_acc: 0.8203\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 203s 522ms/step - loss: 0.0738 - acc: 0.9739 - val_loss: 5.3090 - val_acc: 0.5519\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 203s 522ms/step - loss: 0.0716 - acc: 0.9749 - val_loss: 7.8820 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0663 - acc: 0.9762 - val_loss: 3.0900 - val_acc: 0.6571\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 203s 521ms/step - loss: 0.0733 - acc: 0.9745 - val_loss: 1.7055 - val_acc: 0.6994\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 204s 523ms/step - loss: 0.0634 - acc: 0.9780 - val_loss: 1.7404 - val_acc: 0.7279\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 199s 511ms/step - loss: 0.0600 - acc: 0.9795 - val_loss: 3.1540 - val_acc: 0.5029\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 204s 524ms/step - loss: 0.0618 - acc: 0.9782 - val_loss: 0.1944 - val_acc: 0.9369\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 204s 525ms/step - loss: 0.0574 - acc: 0.9797 - val_loss: 0.0695 - val_acc: 0.9778\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 203s 522ms/step - loss: 0.0546 - acc: 0.9809 - val_loss: 0.8506 - val_acc: 0.6953\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0553 - acc: 0.9808 - val_loss: 2.2459 - val_acc: 0.6649\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 201s 516ms/step - loss: 0.0554 - acc: 0.9808 - val_loss: 0.4448 - val_acc: 0.8731\n",
      "Epoch 23/50\n",
      "389/389 [==============================] - 202s 520ms/step - loss: 0.0511 - acc: 0.9823 - val_loss: 0.1213 - val_acc: 0.9592\n",
      "Epoch 24/50\n",
      "389/389 [==============================] - 203s 523ms/step - loss: 0.0512 - acc: 0.9823 - val_loss: 0.3330 - val_acc: 0.8952\n",
      "Epoch 25/50\n",
      "389/389 [==============================] - 201s 518ms/step - loss: 0.0508 - acc: 0.9823 - val_loss: 2.0349 - val_acc: 0.5573\n",
      "Epoch 26/50\n",
      "389/389 [==============================] - 201s 516ms/step - loss: 0.0491 - acc: 0.9827 - val_loss: 3.1104 - val_acc: 0.6860\n",
      "Epoch 27/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0491 - acc: 0.9837 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "389/389 [==============================] - 201s 518ms/step - loss: 0.0495 - acc: 0.9827 - val_loss: 5.0399 - val_acc: 0.5373\n",
      "Epoch 29/50\n",
      "389/389 [==============================] - 203s 521ms/step - loss: 0.0461 - acc: 0.9839 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-spectrogram_0!\n",
      "        valid set loss: 0.0694584766614\n",
      "        valid set accuracy: 0.977770618557\n",
      "        valid set auc: 0.997017775171\n",
      "--- experiment index of 1 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 667s 2s/step - loss: 0.3730 - acc: 0.8452 - val_loss: 0.3801 - val_acc: 0.8091\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 280s 721ms/step - loss: 0.1960 - acc: 0.9317 - val_loss: 1.2425 - val_acc: 0.6509\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 200s 514ms/step - loss: 0.1497 - acc: 0.9485 - val_loss: 0.2349 - val_acc: 0.9058\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 202s 520ms/step - loss: 0.1311 - acc: 0.9538 - val_loss: 0.7353 - val_acc: 0.7887\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 201s 516ms/step - loss: 0.1149 - acc: 0.9590 - val_loss: 3.6170 - val_acc: 0.5005\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 202s 520ms/step - loss: 0.1052 - acc: 0.9631 - val_loss: 4.0538 - val_acc: 0.5045\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.1017 - acc: 0.9644 - val_loss: 1.5413 - val_acc: 0.6774\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 204s 524ms/step - loss: 0.0949 - acc: 0.9669 - val_loss: 0.2500 - val_acc: 0.9050\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 202s 520ms/step - loss: 0.0868 - acc: 0.9697 - val_loss: 2.3034 - val_acc: 0.5559\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0867 - acc: 0.9697 - val_loss: 0.2028 - val_acc: 0.9239\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 203s 522ms/step - loss: 0.0810 - acc: 0.9710 - val_loss: 6.6940 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.0760 - acc: 0.9737 - val_loss: 2.3988 - val_acc: 0.6244\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0763 - acc: 0.9730 - val_loss: 0.1951 - val_acc: 0.9186\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 199s 512ms/step - loss: 0.0717 - acc: 0.9752 - val_loss: 0.3229 - val_acc: 0.8586\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 201s 516ms/step - loss: 0.0699 - acc: 0.9760 - val_loss: 1.2359 - val_acc: 0.7486\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.0677 - acc: 0.9763 - val_loss: 0.1269 - val_acc: 0.9508\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 203s 523ms/step - loss: 0.0687 - acc: 0.9750 - val_loss: 0.0845 - val_acc: 0.9733\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 203s 523ms/step - loss: 0.0649 - acc: 0.9770 - val_loss: 1.1575 - val_acc: 0.7530\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 209s 536ms/step - loss: 0.0627 - acc: 0.9776 - val_loss: 1.1564 - val_acc: 0.7897\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 206s 531ms/step - loss: 0.0611 - acc: 0.9789 - val_loss: 6.8431 - val_acc: 0.5036\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 208s 535ms/step - loss: 0.0602 - acc: 0.9788 - val_loss: 1.7710 - val_acc: 0.5970\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0576 - acc: 0.9801 - val_loss: 0.3289 - val_acc: 0.8596\n",
      "Epoch 23/50\n",
      "389/389 [==============================] - 208s 534ms/step - loss: 0.0578 - acc: 0.9794 - val_loss: 3.8676 - val_acc: 0.5044\n",
      "Epoch 24/50\n",
      "389/389 [==============================] - 208s 536ms/step - loss: 0.0539 - acc: 0.9814 - val_loss: 0.1029 - val_acc: 0.9644\n",
      "Epoch 25/50\n",
      "389/389 [==============================] - 205s 526ms/step - loss: 0.0538 - acc: 0.9811 - val_loss: 0.0952 - val_acc: 0.9646\n",
      "Epoch 26/50\n",
      "389/389 [==============================] - 206s 528ms/step - loss: 0.0503 - acc: 0.9824 - val_loss: 2.6922 - val_acc: 0.5343\n",
      "Epoch 27/50\n",
      "389/389 [==============================] - 206s 528ms/step - loss: 0.0517 - acc: 0.9816 - val_loss: 0.0833 - val_acc: 0.9705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "389/389 [==============================] - 209s 538ms/step - loss: 0.0472 - acc: 0.9833 - val_loss: 8.0112 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "389/389 [==============================] - 208s 534ms/step - loss: 0.0487 - acc: 0.9824 - val_loss: 0.4189 - val_acc: 0.8919\n",
      "Epoch 30/50\n",
      "389/389 [==============================] - 212s 545ms/step - loss: 0.0475 - acc: 0.9839 - val_loss: 0.0956 - val_acc: 0.9667\n",
      "Epoch 31/50\n",
      "389/389 [==============================] - 203s 523ms/step - loss: 0.0470 - acc: 0.9841 - val_loss: 0.5196 - val_acc: 0.8520\n",
      "Epoch 32/50\n",
      "389/389 [==============================] - 205s 526ms/step - loss: 0.0456 - acc: 0.9846 - val_loss: 0.4975 - val_acc: 0.8721\n",
      "Epoch 33/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0435 - acc: 0.9845 - val_loss: 0.3105 - val_acc: 0.9028\n",
      "Epoch 34/50\n",
      "389/389 [==============================] - 207s 533ms/step - loss: 0.0495 - acc: 0.9821 - val_loss: 7.9702 - val_acc: 0.5000\n",
      "Epoch 35/50\n",
      "389/389 [==============================] - 209s 538ms/step - loss: 0.0387 - acc: 0.9863 - val_loss: 0.4597 - val_acc: 0.8358\n",
      "Epoch 36/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0437 - acc: 0.9847 - val_loss: 0.1118 - val_acc: 0.9563\n",
      "Epoch 37/50\n",
      "389/389 [==============================] - 207s 531ms/step - loss: 0.0396 - acc: 0.9859 - val_loss: 0.0720 - val_acc: 0.9747\n",
      "Epoch 38/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0412 - acc: 0.9861 - val_loss: 2.4747 - val_acc: 0.6829\n",
      "Epoch 39/50\n",
      "389/389 [==============================] - 209s 536ms/step - loss: 0.0400 - acc: 0.9859 - val_loss: 4.2084 - val_acc: 0.5060\n",
      "Epoch 40/50\n",
      "389/389 [==============================] - 209s 538ms/step - loss: 0.0382 - acc: 0.9869 - val_loss: 0.5766 - val_acc: 0.8616\n",
      "Epoch 41/50\n",
      "389/389 [==============================] - 205s 528ms/step - loss: 0.0378 - acc: 0.9866 - val_loss: 0.2259 - val_acc: 0.9145\n",
      "Epoch 42/50\n",
      "389/389 [==============================] - 201s 518ms/step - loss: 0.0345 - acc: 0.9883 - val_loss: 0.0751 - val_acc: 0.9741\n",
      "Epoch 43/50\n",
      "389/389 [==============================] - 210s 540ms/step - loss: 0.0353 - acc: 0.9876 - val_loss: 0.2853 - val_acc: 0.8981\n",
      "Epoch 44/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0341 - acc: 0.9883 - val_loss: 5.4357 - val_acc: 0.5066\n",
      "Epoch 45/50\n",
      "389/389 [==============================] - 205s 528ms/step - loss: 0.0356 - acc: 0.9875 - val_loss: 7.9726 - val_acc: 0.5000\n",
      "Epoch 46/50\n",
      "389/389 [==============================] - 206s 529ms/step - loss: 0.0302 - acc: 0.9898 - val_loss: 0.1214 - val_acc: 0.9655\n",
      "Epoch 47/50\n",
      "389/389 [==============================] - 207s 532ms/step - loss: 0.0307 - acc: 0.9894 - val_loss: 0.2730 - val_acc: 0.8959\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-spectrogram_1!\n",
      "        valid set loss: 0.0719752481169\n",
      "        valid set accuracy: 0.974710051546\n",
      "        valid set auc: 0.99620551913\n",
      "--- experiment index of 2 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 592s 2s/step - loss: 0.3342 - acc: 0.8650 - val_loss: 2.3187 - val_acc: 0.5034\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 284s 729ms/step - loss: 0.1855 - acc: 0.9322 - val_loss: 0.3083 - val_acc: 0.8715\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 212s 544ms/step - loss: 0.1568 - acc: 0.9435 - val_loss: 0.2862 - val_acc: 0.8847\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 199s 511ms/step - loss: 0.1360 - acc: 0.9508 - val_loss: 3.0592 - val_acc: 0.5005\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 201s 516ms/step - loss: 0.1165 - acc: 0.9588 - val_loss: 0.1184 - val_acc: 0.9574\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 197s 506ms/step - loss: 0.1079 - acc: 0.9625 - val_loss: 2.2124 - val_acc: 0.6374\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 201s 516ms/step - loss: 0.0990 - acc: 0.9649 - val_loss: 0.1311 - val_acc: 0.9522\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 208s 535ms/step - loss: 0.0952 - acc: 0.9665 - val_loss: 0.3291 - val_acc: 0.8441\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 207s 532ms/step - loss: 0.0861 - acc: 0.9692 - val_loss: 7.8426 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 205s 527ms/step - loss: 0.0849 - acc: 0.9693 - val_loss: 6.7338 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0816 - acc: 0.9714 - val_loss: 0.3001 - val_acc: 0.8658\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0798 - acc: 0.9724 - val_loss: 0.1129 - val_acc: 0.9565\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 210s 539ms/step - loss: 0.0716 - acc: 0.9744 - val_loss: 2.2632 - val_acc: 0.5235\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 209s 537ms/step - loss: 0.0752 - acc: 0.9739 - val_loss: 0.5097 - val_acc: 0.8236\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 208s 534ms/step - loss: 0.0678 - acc: 0.9757 - val_loss: 6.8417 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 209s 537ms/step - loss: 0.0659 - acc: 0.9772 - val_loss: 7.6212 - val_acc: 0.5001\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 219s 562ms/step - loss: 0.0640 - acc: 0.9780 - val_loss: 1.1439 - val_acc: 0.6459\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 204s 524ms/step - loss: 0.0628 - acc: 0.9778 - val_loss: 0.4791 - val_acc: 0.8433\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0645 - acc: 0.9768 - val_loss: 0.3845 - val_acc: 0.8953\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 201s 518ms/step - loss: 0.0664 - acc: 0.9766 - val_loss: 5.9575 - val_acc: 0.5457\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 195s 501ms/step - loss: 0.0659 - acc: 0.9764 - val_loss: 1.4000 - val_acc: 0.7181\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 197s 506ms/step - loss: 0.0547 - acc: 0.9808 - val_loss: 4.1651 - val_acc: 0.5061\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-spectrogram_2!\n",
      "        valid set loss: 0.112893043297\n",
      "        valid set accuracy: 0.956507731959\n",
      "        valid set auc: 0.99608517433\n",
      "--- experiment index of 3 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 516s 1s/step - loss: 0.3372 - acc: 0.8605 - val_loss: 2.9963 - val_acc: 0.5210\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 237s 609ms/step - loss: 0.1931 - acc: 0.9297 - val_loss: 2.2216 - val_acc: 0.5892\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 210s 540ms/step - loss: 0.1506 - acc: 0.9452 - val_loss: 3.5874 - val_acc: 0.5647\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 209s 538ms/step - loss: 0.1355 - acc: 0.9508 - val_loss: 5.5467 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 210s 541ms/step - loss: 0.1153 - acc: 0.9602 - val_loss: 2.0679 - val_acc: 0.5035\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 206s 529ms/step - loss: 0.1072 - acc: 0.9627 - val_loss: 0.6697 - val_acc: 0.6878\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 205s 528ms/step - loss: 0.1009 - acc: 0.9647 - val_loss: 2.4316 - val_acc: 0.5139\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 211s 541ms/step - loss: 0.0934 - acc: 0.9681 - val_loss: 0.1012 - val_acc: 0.9629\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 212s 546ms/step - loss: 0.0947 - acc: 0.9670 - val_loss: 6.1584 - val_acc: 0.5004\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 207s 533ms/step - loss: 0.0863 - acc: 0.9707 - val_loss: 1.5515 - val_acc: 0.5609\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0767 - acc: 0.9733 - val_loss: 1.0228 - val_acc: 0.6094\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 204s 525ms/step - loss: 0.0787 - acc: 0.9729 - val_loss: 1.1109 - val_acc: 0.7465\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 210s 539ms/step - loss: 0.0723 - acc: 0.9745 - val_loss: 1.0506 - val_acc: 0.7664\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 214s 549ms/step - loss: 0.0709 - acc: 0.9747 - val_loss: 0.5469 - val_acc: 0.7889\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 205s 526ms/step - loss: 0.0709 - acc: 0.9746 - val_loss: 0.5209 - val_acc: 0.7744\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 204s 525ms/step - loss: 0.0662 - acc: 0.9773 - val_loss: 0.0743 - val_acc: 0.9762\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 204s 524ms/step - loss: 0.0630 - acc: 0.9782 - val_loss: 3.3691 - val_acc: 0.5744\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 203s 522ms/step - loss: 0.0625 - acc: 0.9780 - val_loss: 7.8589 - val_acc: 0.5002\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 194s 499ms/step - loss: 0.0602 - acc: 0.9786 - val_loss: 0.0894 - val_acc: 0.9683\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 201s 516ms/step - loss: 0.0614 - acc: 0.9783 - val_loss: 2.2868 - val_acc: 0.5413\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.0564 - acc: 0.9803 - val_loss: 0.5170 - val_acc: 0.8143\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 207s 533ms/step - loss: 0.0569 - acc: 0.9806 - val_loss: 0.9052 - val_acc: 0.8020\n",
      "Epoch 23/50\n",
      "389/389 [==============================] - 206s 531ms/step - loss: 0.0537 - acc: 0.9818 - val_loss: 1.4327 - val_acc: 0.7337\n",
      "Epoch 24/50\n",
      "389/389 [==============================] - 207s 532ms/step - loss: 0.0549 - acc: 0.9806 - val_loss: 4.6666 - val_acc: 0.5212\n",
      "Epoch 25/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0563 - acc: 0.9805 - val_loss: 6.5401 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "389/389 [==============================] - 214s 550ms/step - loss: 0.0504 - acc: 0.9826 - val_loss: 0.3355 - val_acc: 0.8746\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-spectrogram_3!\n",
      "        valid set loss: 0.0742634291252\n",
      "        valid set accuracy: 0.976240335052\n",
      "        valid set auc: 0.996754530652\n",
      "--- experiment index of 4 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 472s 1s/step - loss: 0.3165 - acc: 0.8712 - val_loss: 0.3645 - val_acc: 0.8417\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 224s 575ms/step - loss: 0.1631 - acc: 0.9432 - val_loss: 0.5167 - val_acc: 0.7599\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 200s 514ms/step - loss: 0.1316 - acc: 0.9531 - val_loss: 1.5812 - val_acc: 0.6438\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 200s 515ms/step - loss: 0.1134 - acc: 0.9601 - val_loss: 4.3325 - val_acc: 0.5065\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 201s 518ms/step - loss: 0.1016 - acc: 0.9642 - val_loss: 0.7695 - val_acc: 0.6398\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 203s 521ms/step - loss: 0.0956 - acc: 0.9664 - val_loss: 0.5184 - val_acc: 0.8514\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 202s 520ms/step - loss: 0.0882 - acc: 0.9691 - val_loss: 0.2215 - val_acc: 0.9166\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 200s 514ms/step - loss: 0.0831 - acc: 0.9716 - val_loss: 0.1559 - val_acc: 0.9414\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 201s 516ms/step - loss: 0.0853 - acc: 0.9699 - val_loss: 7.8934 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 202s 518ms/step - loss: 0.0786 - acc: 0.9716 - val_loss: 6.6294 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.0740 - acc: 0.9748 - val_loss: 0.7489 - val_acc: 0.8068\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 202s 520ms/step - loss: 0.0726 - acc: 0.9743 - val_loss: 0.2801 - val_acc: 0.9227\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 201s 516ms/step - loss: 0.0679 - acc: 0.9754 - val_loss: 0.8318 - val_acc: 0.7947\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 199s 511ms/step - loss: 0.0645 - acc: 0.9775 - val_loss: 1.1737 - val_acc: 0.6096\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 200s 513ms/step - loss: 0.0688 - acc: 0.9759 - val_loss: 8.0149 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 203s 522ms/step - loss: 0.0644 - acc: 0.9766 - val_loss: 7.0830 - val_acc: 0.5026\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 201s 516ms/step - loss: 0.0606 - acc: 0.9776 - val_loss: 7.4218 - val_acc: 0.5010\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0614 - acc: 0.9792 - val_loss: 1.8192 - val_acc: 0.6822\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-spectrogram_4!\n",
      "        valid set loss: 0.155866512011\n",
      "        valid set accuracy: 0.941365979381\n",
      "        valid set auc: 0.983937861398\n",
      "--- experiment index of 5 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 450s 1s/step - loss: 0.4080 - acc: 0.8324 - val_loss: 0.6494 - val_acc: 0.6690\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 220s 565ms/step - loss: 0.2156 - acc: 0.9235 - val_loss: 0.1830 - val_acc: 0.9334\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 197s 506ms/step - loss: 0.1662 - acc: 0.9400 - val_loss: 3.8189 - val_acc: 0.5051\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 197s 506ms/step - loss: 0.1418 - acc: 0.9490 - val_loss: 0.3904 - val_acc: 0.8388\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 196s 504ms/step - loss: 0.1314 - acc: 0.9531 - val_loss: 3.5033 - val_acc: 0.5295\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.1216 - acc: 0.9559 - val_loss: 0.9307 - val_acc: 0.7523\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 201s 518ms/step - loss: 0.1089 - acc: 0.9622 - val_loss: 0.9375 - val_acc: 0.7833\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 202s 518ms/step - loss: 0.1028 - acc: 0.9634 - val_loss: 7.9835 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0914 - acc: 0.9680 - val_loss: 0.2453 - val_acc: 0.8949\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 200s 515ms/step - loss: 0.0869 - acc: 0.9696 - val_loss: 0.2112 - val_acc: 0.9286\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 199s 511ms/step - loss: 0.0868 - acc: 0.9688 - val_loss: 0.7461 - val_acc: 0.8189\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 200s 513ms/step - loss: 0.0804 - acc: 0.9724 - val_loss: 0.1651 - val_acc: 0.9451\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 197s 508ms/step - loss: 0.0802 - acc: 0.9720 - val_loss: 0.1468 - val_acc: 0.9445\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 200s 515ms/step - loss: 0.0731 - acc: 0.9741 - val_loss: 1.9530 - val_acc: 0.5437\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 203s 521ms/step - loss: 0.0755 - acc: 0.9733 - val_loss: 1.1921 - val_acc: 0.5891\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 212s 546ms/step - loss: 0.0708 - acc: 0.9749 - val_loss: 2.8768 - val_acc: 0.5127\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 207s 532ms/step - loss: 0.0675 - acc: 0.9762 - val_loss: 5.7539 - val_acc: 0.5193\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0681 - acc: 0.9762 - val_loss: 0.2209 - val_acc: 0.9093\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 209s 537ms/step - loss: 0.0636 - acc: 0.9778 - val_loss: 0.2524 - val_acc: 0.9286\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 206s 528ms/step - loss: 0.0630 - acc: 0.9780 - val_loss: 0.0758 - val_acc: 0.9728\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 204s 523ms/step - loss: 0.0602 - acc: 0.9790 - val_loss: 2.1691 - val_acc: 0.6633\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 205s 527ms/step - loss: 0.0641 - acc: 0.9768 - val_loss: 0.4290 - val_acc: 0.8188\n",
      "Epoch 23/50\n",
      "389/389 [==============================] - 205s 528ms/step - loss: 0.0589 - acc: 0.9781 - val_loss: 0.1896 - val_acc: 0.9280\n",
      "Epoch 24/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0588 - acc: 0.9795 - val_loss: 3.5412 - val_acc: 0.5878\n",
      "Epoch 25/50\n",
      "389/389 [==============================] - 209s 538ms/step - loss: 0.0537 - acc: 0.9808 - val_loss: 1.0130 - val_acc: 0.7953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "389/389 [==============================] - 199s 511ms/step - loss: 0.0598 - acc: 0.9794 - val_loss: 0.2348 - val_acc: 0.9074\n",
      "Epoch 27/50\n",
      "389/389 [==============================] - 203s 521ms/step - loss: 0.0553 - acc: 0.9803 - val_loss: 1.0175 - val_acc: 0.7924\n",
      "Epoch 28/50\n",
      "389/389 [==============================] - 205s 526ms/step - loss: 0.0550 - acc: 0.9804 - val_loss: 2.6786 - val_acc: 0.6612\n",
      "Epoch 29/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0527 - acc: 0.9809 - val_loss: 0.1400 - val_acc: 0.9529\n",
      "Epoch 30/50\n",
      "389/389 [==============================] - 203s 521ms/step - loss: 0.0502 - acc: 0.9829 - val_loss: 0.6414 - val_acc: 0.8283\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-spectrogram_5!\n",
      "        valid set loss: 0.0758484510378\n",
      "        valid set accuracy: 0.972777061856\n",
      "        valid set auc: 0.995905967483\n",
      "--- experiment index of 6 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 459s 1s/step - loss: 0.3163 - acc: 0.8737 - val_loss: 0.4917 - val_acc: 0.7899\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 220s 566ms/step - loss: 0.1812 - acc: 0.9331 - val_loss: 0.1817 - val_acc: 0.9332\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 197s 507ms/step - loss: 0.1391 - acc: 0.9505 - val_loss: 0.1530 - val_acc: 0.9435\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 199s 512ms/step - loss: 0.1205 - acc: 0.9575 - val_loss: 1.3566 - val_acc: 0.6778\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 197s 506ms/step - loss: 0.1060 - acc: 0.9636 - val_loss: 0.2471 - val_acc: 0.8969\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 200s 514ms/step - loss: 0.0980 - acc: 0.9655 - val_loss: 0.9534 - val_acc: 0.7457\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.0913 - acc: 0.9682 - val_loss: 0.1505 - val_acc: 0.9438\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 198s 510ms/step - loss: 0.0871 - acc: 0.9697 - val_loss: 1.3228 - val_acc: 0.5824\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 200s 515ms/step - loss: 0.0803 - acc: 0.9724 - val_loss: 5.0331 - val_acc: 0.5014\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 199s 512ms/step - loss: 0.0757 - acc: 0.9737 - val_loss: 0.7769 - val_acc: 0.8057\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 197s 507ms/step - loss: 0.0743 - acc: 0.9743 - val_loss: 0.4849 - val_acc: 0.8684\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 198s 509ms/step - loss: 0.0687 - acc: 0.9763 - val_loss: 0.9052 - val_acc: 0.8007\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 197s 507ms/step - loss: 0.0713 - acc: 0.9746 - val_loss: 1.1523 - val_acc: 0.7692\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 200s 515ms/step - loss: 0.0667 - acc: 0.9766 - val_loss: 1.7095 - val_acc: 0.7152\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 200s 513ms/step - loss: 0.0629 - acc: 0.9783 - val_loss: 0.0786 - val_acc: 0.9733\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 197s 507ms/step - loss: 0.0655 - acc: 0.9765 - val_loss: 1.4909 - val_acc: 0.7205\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 199s 510ms/step - loss: 0.0597 - acc: 0.9788 - val_loss: 7.3188 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 200s 514ms/step - loss: 0.0596 - acc: 0.9804 - val_loss: 0.1504 - val_acc: 0.9458\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 199s 511ms/step - loss: 0.0591 - acc: 0.9792 - val_loss: 0.5587 - val_acc: 0.8681\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 198s 508ms/step - loss: 0.0533 - acc: 0.9809 - val_loss: 0.6245 - val_acc: 0.7660\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 200s 514ms/step - loss: 0.0503 - acc: 0.9821 - val_loss: 0.4646 - val_acc: 0.8764\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 200s 514ms/step - loss: 0.0516 - acc: 0.9826 - val_loss: 0.0690 - val_acc: 0.9787\n",
      "Epoch 23/50\n",
      "389/389 [==============================] - 199s 512ms/step - loss: 0.0485 - acc: 0.9828 - val_loss: 0.0999 - val_acc: 0.9618\n",
      "Epoch 24/50\n",
      "389/389 [==============================] - 200s 514ms/step - loss: 0.0471 - acc: 0.9840 - val_loss: 0.7877 - val_acc: 0.7109\n",
      "Epoch 25/50\n",
      "389/389 [==============================] - 202s 518ms/step - loss: 0.0461 - acc: 0.9837 - val_loss: 0.8520 - val_acc: 0.8224\n",
      "Epoch 26/50\n",
      "389/389 [==============================] - 199s 513ms/step - loss: 0.0436 - acc: 0.9844 - val_loss: 0.2774 - val_acc: 0.9205\n",
      "Epoch 27/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.0436 - acc: 0.9847 - val_loss: 0.0831 - val_acc: 0.9746\n",
      "Epoch 28/50\n",
      "389/389 [==============================] - 198s 508ms/step - loss: 0.0416 - acc: 0.9855 - val_loss: 0.5906 - val_acc: 0.7774\n",
      "Epoch 29/50\n",
      "389/389 [==============================] - 199s 512ms/step - loss: 0.0394 - acc: 0.9869 - val_loss: 7.4335 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "389/389 [==============================] - 202s 518ms/step - loss: 0.0416 - acc: 0.9856 - val_loss: 6.0681 - val_acc: 0.5114\n",
      "Epoch 31/50\n",
      "389/389 [==============================] - 201s 516ms/step - loss: 0.0397 - acc: 0.9862 - val_loss: 0.8689 - val_acc: 0.8255\n",
      "Epoch 32/50\n",
      "389/389 [==============================] - 203s 521ms/step - loss: 0.0347 - acc: 0.9884 - val_loss: 0.9612 - val_acc: 0.8244\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-spectrogram_6!\n",
      "        valid set loss: 0.0690469522336\n",
      "        valid set accuracy: 0.978737113402\n",
      "        valid set auc: 0.996078862585\n",
      "--- experiment index of 7 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 412s 1s/step - loss: 0.3421 - acc: 0.8597 - val_loss: 1.6171 - val_acc: 0.5015\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 216s 554ms/step - loss: 0.1860 - acc: 0.9355 - val_loss: 0.5509 - val_acc: 0.7308\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 201s 518ms/step - loss: 0.1449 - acc: 0.9496 - val_loss: 0.9532 - val_acc: 0.7494\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 200s 514ms/step - loss: 0.1310 - acc: 0.9537 - val_loss: 0.8155 - val_acc: 0.6264\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 209s 537ms/step - loss: 0.1161 - acc: 0.9594 - val_loss: 1.7011 - val_acc: 0.6484\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 209s 536ms/step - loss: 0.1085 - acc: 0.9621 - val_loss: 3.7896 - val_acc: 0.5057\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 207s 533ms/step - loss: 0.0954 - acc: 0.9670 - val_loss: 0.3410 - val_acc: 0.8322\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 205s 527ms/step - loss: 0.0913 - acc: 0.9681 - val_loss: 0.3241 - val_acc: 0.8875\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 209s 538ms/step - loss: 0.0835 - acc: 0.9723 - val_loss: 3.0533 - val_acc: 0.6125\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0838 - acc: 0.9705 - val_loss: 7.3335 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 207s 531ms/step - loss: 0.0766 - acc: 0.9733 - val_loss: 0.8672 - val_acc: 0.7942\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 208s 534ms/step - loss: 0.0804 - acc: 0.9721 - val_loss: 0.2566 - val_acc: 0.9111\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 206s 531ms/step - loss: 0.0736 - acc: 0.9745 - val_loss: 0.2502 - val_acc: 0.9162\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 206s 528ms/step - loss: 0.0714 - acc: 0.9752 - val_loss: 0.1327 - val_acc: 0.9540\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 203s 523ms/step - loss: 0.0681 - acc: 0.9766 - val_loss: 0.7213 - val_acc: 0.8265\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 207s 532ms/step - loss: 0.0656 - acc: 0.9777 - val_loss: 0.7062 - val_acc: 0.8266\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 204s 525ms/step - loss: 0.0653 - acc: 0.9775 - val_loss: 0.1588 - val_acc: 0.9448\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 205s 528ms/step - loss: 0.0629 - acc: 0.9768 - val_loss: 0.9988 - val_acc: 0.7338\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 204s 524ms/step - loss: 0.0578 - acc: 0.9796 - val_loss: 5.9818 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 205s 528ms/step - loss: 0.0598 - acc: 0.9790 - val_loss: 0.2212 - val_acc: 0.9172\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 208s 534ms/step - loss: 0.0615 - acc: 0.9786 - val_loss: 1.6766 - val_acc: 0.5616\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 206s 531ms/step - loss: 0.0553 - acc: 0.9803 - val_loss: 0.8084 - val_acc: 0.8338\n",
      "Epoch 23/50\n",
      "389/389 [==============================] - 204s 524ms/step - loss: 0.0542 - acc: 0.9815 - val_loss: 0.0921 - val_acc: 0.9671\n",
      "Epoch 24/50\n",
      "389/389 [==============================] - 208s 534ms/step - loss: 0.0529 - acc: 0.9814 - val_loss: 0.6357 - val_acc: 0.8468\n",
      "Epoch 25/50\n",
      "389/389 [==============================] - 207s 532ms/step - loss: 0.0530 - acc: 0.9817 - val_loss: 1.1945 - val_acc: 0.7643\n",
      "Epoch 26/50\n",
      "389/389 [==============================] - 203s 521ms/step - loss: 0.0501 - acc: 0.9828 - val_loss: 1.1812 - val_acc: 0.7135\n",
      "Epoch 27/50\n",
      "389/389 [==============================] - 204s 525ms/step - loss: 0.0499 - acc: 0.9825 - val_loss: 7.0648 - val_acc: 0.5046\n",
      "Epoch 28/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0502 - acc: 0.9819 - val_loss: 0.1292 - val_acc: 0.9489\n",
      "Epoch 29/50\n",
      "389/389 [==============================] - 208s 534ms/step - loss: 0.0513 - acc: 0.9822 - val_loss: 1.3826 - val_acc: 0.6776\n",
      "Epoch 30/50\n",
      "389/389 [==============================] - 206s 531ms/step - loss: 0.0462 - acc: 0.9841 - val_loss: 0.2305 - val_acc: 0.9327\n",
      "Epoch 31/50\n",
      "389/389 [==============================] - 207s 533ms/step - loss: 0.0454 - acc: 0.9844 - val_loss: 0.1037 - val_acc: 0.9671\n",
      "Epoch 32/50\n",
      "389/389 [==============================] - 203s 522ms/step - loss: 0.0426 - acc: 0.9855 - val_loss: 6.5478 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0420 - acc: 0.9851 - val_loss: 2.2600 - val_acc: 0.5919\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-spectrogram_7!\n",
      "        valid set loss: 0.0920512368807\n",
      "        valid set accuracy: 0.967139175258\n",
      "        valid set auc: 0.994330184925\n",
      "--- experiment index of 8 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 395s 1s/step - loss: 0.3227 - acc: 0.8712 - val_loss: 1.2531 - val_acc: 0.6657\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 209s 538ms/step - loss: 0.1671 - acc: 0.9424 - val_loss: 2.7915 - val_acc: 0.5702\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.1316 - acc: 0.9545 - val_loss: 0.9330 - val_acc: 0.7353\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.1137 - acc: 0.9595 - val_loss: 2.0894 - val_acc: 0.6436\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 201s 518ms/step - loss: 0.1024 - acc: 0.9645 - val_loss: 5.7162 - val_acc: 0.5230\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 202s 518ms/step - loss: 0.0960 - acc: 0.9656 - val_loss: 6.4566 - val_acc: 0.5149\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 199s 511ms/step - loss: 0.0901 - acc: 0.9690 - val_loss: 1.3714 - val_acc: 0.7159\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 199s 513ms/step - loss: 0.0815 - acc: 0.9707 - val_loss: 5.1688 - val_acc: 0.5001\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 199s 512ms/step - loss: 0.0834 - acc: 0.9716 - val_loss: 0.2762 - val_acc: 0.8781\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 202s 520ms/step - loss: 0.0702 - acc: 0.9759 - val_loss: 4.8212 - val_acc: 0.5007\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 204s 524ms/step - loss: 0.0752 - acc: 0.9729 - val_loss: 2.9480 - val_acc: 0.6197\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 200s 514ms/step - loss: 0.0733 - acc: 0.9748 - val_loss: 7.9769 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.0649 - acc: 0.9773 - val_loss: 0.2632 - val_acc: 0.8902\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0641 - acc: 0.9775 - val_loss: 0.4988 - val_acc: 0.8013\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 202s 518ms/step - loss: 0.0616 - acc: 0.9783 - val_loss: 5.9542 - val_acc: 0.5209\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.0615 - acc: 0.9785 - val_loss: 4.0358 - val_acc: 0.5756\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 201s 517ms/step - loss: 0.0583 - acc: 0.9795 - val_loss: 8.0145 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 202s 520ms/step - loss: 0.0593 - acc: 0.9796 - val_loss: 2.6991 - val_acc: 0.6450\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 204s 524ms/step - loss: 0.0586 - acc: 0.9790 - val_loss: 1.1762 - val_acc: 0.7465\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 201s 518ms/step - loss: 0.0525 - acc: 0.9813 - val_loss: 8.0100 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 200s 513ms/step - loss: 0.0502 - acc: 0.9831 - val_loss: 5.4000 - val_acc: 0.5010\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0450 - acc: 0.9850 - val_loss: 0.2468 - val_acc: 0.8959\n",
      "Epoch 23/50\n",
      "389/389 [==============================] - 200s 515ms/step - loss: 0.0525 - acc: 0.9810 - val_loss: 4.5762 - val_acc: 0.5763\n",
      "Epoch 24/50\n",
      "389/389 [==============================] - 203s 521ms/step - loss: 0.0451 - acc: 0.9843 - val_loss: 0.0884 - val_acc: 0.9712\n",
      "Epoch 25/50\n",
      "389/389 [==============================] - 203s 521ms/step - loss: 0.0458 - acc: 0.9841 - val_loss: 4.0013 - val_acc: 0.5059\n",
      "Epoch 26/50\n",
      "389/389 [==============================] - 203s 521ms/step - loss: 0.0447 - acc: 0.9843 - val_loss: 4.7642 - val_acc: 0.5086\n",
      "Epoch 27/50\n",
      "389/389 [==============================] - 202s 520ms/step - loss: 0.0443 - acc: 0.9842 - val_loss: 8.0143 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "389/389 [==============================] - 201s 516ms/step - loss: 0.0447 - acc: 0.9843 - val_loss: 1.5167 - val_acc: 0.7345\n",
      "Epoch 29/50\n",
      "389/389 [==============================] - 202s 518ms/step - loss: 0.0473 - acc: 0.9831 - val_loss: 7.6800 - val_acc: 0.5013\n",
      "Epoch 30/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0394 - acc: 0.9866 - val_loss: 1.0262 - val_acc: 0.6646\n",
      "Epoch 31/50\n",
      "389/389 [==============================] - 200s 514ms/step - loss: 0.0450 - acc: 0.9842 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 32/50\n",
      "389/389 [==============================] - 202s 519ms/step - loss: 0.0379 - acc: 0.9862 - val_loss: 0.8407 - val_acc: 0.8222\n",
      "Epoch 33/50\n",
      "389/389 [==============================] - 203s 523ms/step - loss: 0.0393 - acc: 0.9863 - val_loss: 1.8501 - val_acc: 0.7130\n",
      "Epoch 34/50\n",
      "389/389 [==============================] - 202s 520ms/step - loss: 0.0389 - acc: 0.9868 - val_loss: 6.8373 - val_acc: 0.5000\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-spectrogram_8!\n",
      "        valid set loss: 0.0884207251539\n",
      "        valid set accuracy: 0.971166237113\n",
      "        valid set auc: 0.997555629241\n",
      "--- experiment index of 9 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 387s 996ms/step - loss: 0.3724 - acc: 0.8385 - val_loss: 0.6452 - val_acc: 0.7092\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.1813 - acc: 0.9374 - val_loss: 5.4081 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 203s 522ms/step - loss: 0.1481 - acc: 0.9467 - val_loss: 1.2214 - val_acc: 0.6924\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 202s 518ms/step - loss: 0.1267 - acc: 0.9552 - val_loss: 0.2141 - val_acc: 0.9142\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 204s 525ms/step - loss: 0.1101 - acc: 0.9608 - val_loss: 3.1836 - val_acc: 0.5627\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 205s 528ms/step - loss: 0.0977 - acc: 0.9655 - val_loss: 1.9152 - val_acc: 0.5525\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0974 - acc: 0.9649 - val_loss: 0.1802 - val_acc: 0.9410\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 206s 529ms/step - loss: 0.0904 - acc: 0.9683 - val_loss: 2.2938 - val_acc: 0.5072\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0871 - acc: 0.9697 - val_loss: 0.9033 - val_acc: 0.6354\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 207s 531ms/step - loss: 0.0769 - acc: 0.9723 - val_loss: 4.9927 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 204s 525ms/step - loss: 0.0755 - acc: 0.9741 - val_loss: 2.3132 - val_acc: 0.6492\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 205s 527ms/step - loss: 0.0786 - acc: 0.9721 - val_loss: 0.1272 - val_acc: 0.9534\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 208s 534ms/step - loss: 0.0717 - acc: 0.9745 - val_loss: 2.6592 - val_acc: 0.5102\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 206s 530ms/step - loss: 0.0653 - acc: 0.9771 - val_loss: 1.6932 - val_acc: 0.7352\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 205s 526ms/step - loss: 0.0654 - acc: 0.9768 - val_loss: 7.9444 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 203s 523ms/step - loss: 0.0646 - acc: 0.9768 - val_loss: 3.6110 - val_acc: 0.5562\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 203s 521ms/step - loss: 0.0608 - acc: 0.9782 - val_loss: 1.5869 - val_acc: 0.7302\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 202s 518ms/step - loss: 0.0580 - acc: 0.9792 - val_loss: 0.3012 - val_acc: 0.9018\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 205s 528ms/step - loss: 0.0535 - acc: 0.9813 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 206s 529ms/step - loss: 0.0520 - acc: 0.9820 - val_loss: 5.9790 - val_acc: 0.5003\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 204s 523ms/step - loss: 0.0532 - acc: 0.9815 - val_loss: 8.0151 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 204s 524ms/step - loss: 0.0524 - acc: 0.9818 - val_loss: 4.2360 - val_acc: 0.5060\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-spectrogram_9!\n",
      "        valid set loss: 0.127175009771\n",
      "        valid set accuracy: 0.953366623711\n",
      "        valid set auc: 0.996207432763\n",
      "----------------------------------------\n",
      "We're gonna use cnn3x3-melspectrogram model.\n",
      "--- experiment index of 0 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 213s 546ms/step - loss: 0.2525 - acc: 0.8976 - val_loss: 0.2346 - val_acc: 0.9142\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 149s 384ms/step - loss: 0.1449 - acc: 0.9470 - val_loss: 0.1436 - val_acc: 0.9436\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 130s 333ms/step - loss: 0.1202 - acc: 0.9576 - val_loss: 0.1873 - val_acc: 0.9242\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 121s 312ms/step - loss: 0.0974 - acc: 0.9666 - val_loss: 0.3251 - val_acc: 0.8489\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 121s 310ms/step - loss: 0.0957 - acc: 0.9673 - val_loss: 0.1089 - val_acc: 0.9627\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 115s 295ms/step - loss: 0.0863 - acc: 0.9694 - val_loss: 0.1565 - val_acc: 0.9470\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0774 - acc: 0.9735 - val_loss: 0.6248 - val_acc: 0.7232\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0731 - acc: 0.9741 - val_loss: 0.1105 - val_acc: 0.9594\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 114s 294ms/step - loss: 0.0732 - acc: 0.9742 - val_loss: 0.1805 - val_acc: 0.9423\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0652 - acc: 0.9772 - val_loss: 0.0874 - val_acc: 0.9686\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0651 - acc: 0.9773 - val_loss: 0.6745 - val_acc: 0.7071\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 115s 295ms/step - loss: 0.0606 - acc: 0.9788 - val_loss: 0.1885 - val_acc: 0.9385\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 113s 291ms/step - loss: 0.0552 - acc: 0.9811 - val_loss: 0.2015 - val_acc: 0.9195\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0564 - acc: 0.9804 - val_loss: 0.0755 - val_acc: 0.9737\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 116s 297ms/step - loss: 0.0551 - acc: 0.9803 - val_loss: 0.1754 - val_acc: 0.9414\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0519 - acc: 0.9819 - val_loss: 0.2162 - val_acc: 0.9403\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0474 - acc: 0.9833 - val_loss: 0.0730 - val_acc: 0.9753\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 115s 295ms/step - loss: 0.0452 - acc: 0.9843 - val_loss: 0.0988 - val_acc: 0.9617\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 116s 297ms/step - loss: 0.0483 - acc: 0.9832 - val_loss: 0.1406 - val_acc: 0.9422\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 114s 292ms/step - loss: 0.0431 - acc: 0.9847 - val_loss: 0.0901 - val_acc: 0.9679\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 116s 297ms/step - loss: 0.0410 - acc: 0.9858 - val_loss: 0.1605 - val_acc: 0.9543\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 115s 295ms/step - loss: 0.0417 - acc: 0.9851 - val_loss: 0.2833 - val_acc: 0.9216\n",
      "Epoch 23/50\n",
      "389/389 [==============================] - 116s 299ms/step - loss: 0.0386 - acc: 0.9869 - val_loss: 0.0610 - val_acc: 0.9791\n",
      "Epoch 24/50\n",
      "389/389 [==============================] - 115s 295ms/step - loss: 0.0393 - acc: 0.9861 - val_loss: 0.5321 - val_acc: 0.8818\n",
      "Epoch 25/50\n",
      "389/389 [==============================] - 115s 296ms/step - loss: 0.0354 - acc: 0.9873 - val_loss: 0.9340 - val_acc: 0.6873\n",
      "Epoch 26/50\n",
      "389/389 [==============================] - 115s 296ms/step - loss: 0.0394 - acc: 0.9864 - val_loss: 0.4518 - val_acc: 0.8236\n",
      "Epoch 27/50\n",
      "389/389 [==============================] - 115s 296ms/step - loss: 0.0349 - acc: 0.9878 - val_loss: 0.2737 - val_acc: 0.8906\n",
      "Epoch 28/50\n",
      "389/389 [==============================] - 116s 297ms/step - loss: 0.0320 - acc: 0.9888 - val_loss: 0.3263 - val_acc: 0.8671\n",
      "Epoch 29/50\n",
      "389/389 [==============================] - 115s 297ms/step - loss: 0.0314 - acc: 0.9890 - val_loss: 0.0954 - val_acc: 0.9723\n",
      "Epoch 30/50\n",
      "389/389 [==============================] - 114s 293ms/step - loss: 0.0294 - acc: 0.9904 - val_loss: 0.1525 - val_acc: 0.9613\n",
      "Epoch 31/50\n",
      "389/389 [==============================] - 116s 297ms/step - loss: 0.0324 - acc: 0.9886 - val_loss: 0.3596 - val_acc: 0.8582\n",
      "Epoch 32/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.0310 - acc: 0.9893 - val_loss: 0.0505 - val_acc: 0.9836\n",
      "Epoch 33/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.0332 - acc: 0.9879 - val_loss: 0.1997 - val_acc: 0.9166\n",
      "Epoch 34/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0273 - acc: 0.9909 - val_loss: 0.0645 - val_acc: 0.9797\n",
      "Epoch 35/50\n",
      "389/389 [==============================] - 116s 299ms/step - loss: 0.0264 - acc: 0.9908 - val_loss: 0.4849 - val_acc: 0.8959\n",
      "Epoch 36/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.0257 - acc: 0.9913 - val_loss: 0.1081 - val_acc: 0.9704\n",
      "Epoch 37/50\n",
      "389/389 [==============================] - 115s 295ms/step - loss: 0.0285 - acc: 0.9907 - val_loss: 0.1393 - val_acc: 0.9473\n",
      "Epoch 38/50\n",
      "389/389 [==============================] - 116s 299ms/step - loss: 0.0260 - acc: 0.9910 - val_loss: 1.1421 - val_acc: 0.6873\n",
      "Epoch 39/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0251 - acc: 0.9916 - val_loss: 0.1615 - val_acc: 0.9373\n",
      "Epoch 40/50\n",
      "389/389 [==============================] - 115s 295ms/step - loss: 0.0253 - acc: 0.9914 - val_loss: 0.1664 - val_acc: 0.9369\n",
      "Epoch 41/50\n",
      "389/389 [==============================] - 115s 296ms/step - loss: 0.0221 - acc: 0.9930 - val_loss: 0.3058 - val_acc: 0.8780\n",
      "Epoch 42/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0240 - acc: 0.9917 - val_loss: 0.2316 - val_acc: 0.9112\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-melspectrogram_0!\n",
      "        valid set loss: 0.0505056151995\n",
      "        valid set accuracy: 0.983569587629\n",
      "        valid set auc: 0.997619272127\n",
      "--- experiment index of 1 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 126s 323ms/step - loss: 0.2908 - acc: 0.8851 - val_loss: 1.0866 - val_acc: 0.5839\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 121s 310ms/step - loss: 0.1538 - acc: 0.9466 - val_loss: 0.1731 - val_acc: 0.9342\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.1230 - acc: 0.9573 - val_loss: 0.6332 - val_acc: 0.8210\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 119s 305ms/step - loss: 0.1080 - acc: 0.9622 - val_loss: 2.6787 - val_acc: 0.5010\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0967 - acc: 0.9672 - val_loss: 1.0798 - val_acc: 0.6020\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0842 - acc: 0.9711 - val_loss: 0.6667 - val_acc: 0.7279\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0833 - acc: 0.9709 - val_loss: 0.2024 - val_acc: 0.9335\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 121s 311ms/step - loss: 0.0755 - acc: 0.9734 - val_loss: 0.1362 - val_acc: 0.9440\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 119s 305ms/step - loss: 0.0754 - acc: 0.9733 - val_loss: 0.0734 - val_acc: 0.9748\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0674 - acc: 0.9758 - val_loss: 0.0786 - val_acc: 0.9707\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0653 - acc: 0.9772 - val_loss: 0.1108 - val_acc: 0.9601\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0631 - acc: 0.9777 - val_loss: 0.4599 - val_acc: 0.7989\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 118s 303ms/step - loss: 0.0630 - acc: 0.9782 - val_loss: 0.5585 - val_acc: 0.7806\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0579 - acc: 0.9796 - val_loss: 0.1142 - val_acc: 0.9584\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0605 - acc: 0.9784 - val_loss: 0.9842 - val_acc: 0.6432\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 119s 305ms/step - loss: 0.0548 - acc: 0.9804 - val_loss: 0.1141 - val_acc: 0.9635\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0540 - acc: 0.9808 - val_loss: 0.3740 - val_acc: 0.8379\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 118s 303ms/step - loss: 0.0522 - acc: 0.9822 - val_loss: 0.0640 - val_acc: 0.9762\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 118s 303ms/step - loss: 0.0482 - acc: 0.9831 - val_loss: 0.0891 - val_acc: 0.9659\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 132s 339ms/step - loss: 0.0457 - acc: 0.9840 - val_loss: 0.0677 - val_acc: 0.9757\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 119s 305ms/step - loss: 0.0465 - acc: 0.9834 - val_loss: 0.0714 - val_acc: 0.9744\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0475 - acc: 0.9831 - val_loss: 0.2344 - val_acc: 0.9368\n",
      "Epoch 23/50\n",
      "389/389 [==============================] - 120s 307ms/step - loss: 0.0442 - acc: 0.9849 - val_loss: 0.1136 - val_acc: 0.9585\n",
      "Epoch 24/50\n",
      "389/389 [==============================] - 119s 305ms/step - loss: 0.0404 - acc: 0.9861 - val_loss: 0.0600 - val_acc: 0.9784\n",
      "Epoch 25/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0406 - acc: 0.9852 - val_loss: 0.2116 - val_acc: 0.9377\n",
      "Epoch 26/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0381 - acc: 0.9869 - val_loss: 0.5744 - val_acc: 0.7697\n",
      "Epoch 27/50\n",
      "389/389 [==============================] - 117s 302ms/step - loss: 0.0381 - acc: 0.9866 - val_loss: 0.6005 - val_acc: 0.8695\n",
      "Epoch 28/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0385 - acc: 0.9861 - val_loss: 0.0582 - val_acc: 0.9799\n",
      "Epoch 29/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.0354 - acc: 0.9877 - val_loss: 0.1511 - val_acc: 0.9387\n",
      "Epoch 30/50\n",
      "389/389 [==============================] - 119s 305ms/step - loss: 0.0338 - acc: 0.9885 - val_loss: 0.1122 - val_acc: 0.9646\n",
      "Epoch 31/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.0341 - acc: 0.9880 - val_loss: 0.2697 - val_acc: 0.8908\n",
      "Epoch 32/50\n",
      "389/389 [==============================] - 118s 302ms/step - loss: 0.0317 - acc: 0.9889 - val_loss: 0.0829 - val_acc: 0.9734\n",
      "Epoch 33/50\n",
      "389/389 [==============================] - 118s 302ms/step - loss: 0.0329 - acc: 0.9885 - val_loss: 0.0968 - val_acc: 0.9639\n",
      "Epoch 34/50\n",
      "389/389 [==============================] - 118s 302ms/step - loss: 0.0301 - acc: 0.9897 - val_loss: 0.0727 - val_acc: 0.9767\n",
      "Epoch 35/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0291 - acc: 0.9900 - val_loss: 1.1438 - val_acc: 0.6848\n",
      "Epoch 36/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0287 - acc: 0.9906 - val_loss: 0.0613 - val_acc: 0.9784\n",
      "Epoch 37/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0280 - acc: 0.9902 - val_loss: 0.0927 - val_acc: 0.9732\n",
      "Epoch 38/50\n",
      "389/389 [==============================] - 118s 303ms/step - loss: 0.0273 - acc: 0.9907 - val_loss: 0.0813 - val_acc: 0.9751\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-melspectrogram_1!\n",
      "        valid set loss: 0.0582197288282\n",
      "        valid set accuracy: 0.979864690722\n",
      "        valid set auc: 0.997068898358\n",
      "--- experiment index of 2 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 124s 319ms/step - loss: 0.2602 - acc: 0.8962 - val_loss: 1.0293 - val_acc: 0.6805\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 122s 314ms/step - loss: 0.1429 - acc: 0.9497 - val_loss: 0.3611 - val_acc: 0.8107\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 121s 310ms/step - loss: 0.1099 - acc: 0.9610 - val_loss: 2.0839 - val_acc: 0.5249\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.1015 - acc: 0.9635 - val_loss: 0.9012 - val_acc: 0.7784\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 118s 302ms/step - loss: 0.0931 - acc: 0.9671 - val_loss: 0.6456 - val_acc: 0.7149\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0826 - acc: 0.9714 - val_loss: 0.1075 - val_acc: 0.9636\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 118s 303ms/step - loss: 0.0804 - acc: 0.9718 - val_loss: 0.1672 - val_acc: 0.9356\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0740 - acc: 0.9731 - val_loss: 0.7933 - val_acc: 0.8076\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0711 - acc: 0.9751 - val_loss: 0.1115 - val_acc: 0.9621\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0683 - acc: 0.9753 - val_loss: 0.1162 - val_acc: 0.9590\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0638 - acc: 0.9773 - val_loss: 0.2201 - val_acc: 0.9012\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 119s 305ms/step - loss: 0.0614 - acc: 0.9787 - val_loss: 0.3726 - val_acc: 0.9005\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.0522 - acc: 0.9817 - val_loss: 0.6207 - val_acc: 0.7528\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 120s 307ms/step - loss: 0.0516 - acc: 0.9822 - val_loss: 0.0682 - val_acc: 0.9762\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0529 - acc: 0.9813 - val_loss: 0.0789 - val_acc: 0.9744\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0487 - acc: 0.9833 - val_loss: 0.1196 - val_acc: 0.9615\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0493 - acc: 0.9831 - val_loss: 0.2428 - val_acc: 0.9270\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0494 - acc: 0.9832 - val_loss: 0.0692 - val_acc: 0.9778\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 121s 311ms/step - loss: 0.0458 - acc: 0.9839 - val_loss: 0.1968 - val_acc: 0.9190\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.0425 - acc: 0.9847 - val_loss: 0.9457 - val_acc: 0.7018\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 122s 313ms/step - loss: 0.0413 - acc: 0.9854 - val_loss: 0.0596 - val_acc: 0.9798\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 121s 312ms/step - loss: 0.0397 - acc: 0.9865 - val_loss: 0.2466 - val_acc: 0.8959\n",
      "Epoch 23/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0377 - acc: 0.9871 - val_loss: 0.1381 - val_acc: 0.9584\n",
      "Epoch 24/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0380 - acc: 0.9865 - val_loss: 0.1901 - val_acc: 0.9245\n",
      "Epoch 25/50\n",
      "389/389 [==============================] - 119s 305ms/step - loss: 0.0371 - acc: 0.9869 - val_loss: 0.1609 - val_acc: 0.9386\n",
      "Epoch 26/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0339 - acc: 0.9882 - val_loss: 0.0731 - val_acc: 0.9762\n",
      "Epoch 27/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0318 - acc: 0.9891 - val_loss: 0.1753 - val_acc: 0.9274\n",
      "Epoch 28/50\n",
      "389/389 [==============================] - 118s 303ms/step - loss: 0.0335 - acc: 0.9885 - val_loss: 0.0960 - val_acc: 0.9648\n",
      "Epoch 29/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0324 - acc: 0.9893 - val_loss: 0.0843 - val_acc: 0.9699\n",
      "Epoch 30/50\n",
      "389/389 [==============================] - 121s 310ms/step - loss: 0.0303 - acc: 0.9900 - val_loss: 0.0829 - val_acc: 0.9741\n",
      "Epoch 31/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.0318 - acc: 0.9888 - val_loss: 0.1049 - val_acc: 0.9572\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-melspectrogram_2!\n",
      "        valid set loss: 0.0595522884846\n",
      "        valid set accuracy: 0.979784149485\n",
      "        valid set auc: 0.997284198266\n",
      "--- experiment index of 3 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 129s 332ms/step - loss: 0.2701 - acc: 0.8876 - val_loss: 0.4658 - val_acc: 0.7208\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 121s 312ms/step - loss: 0.1504 - acc: 0.9464 - val_loss: 0.1435 - val_acc: 0.9460\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 122s 314ms/step - loss: 0.1190 - acc: 0.9573 - val_loss: 1.1101 - val_acc: 0.6196\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 122s 313ms/step - loss: 0.1050 - acc: 0.9632 - val_loss: 2.9882 - val_acc: 0.5014\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0928 - acc: 0.9672 - val_loss: 3.1787 - val_acc: 0.5227\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 120s 307ms/step - loss: 0.0881 - acc: 0.9694 - val_loss: 0.2099 - val_acc: 0.9069\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 122s 314ms/step - loss: 0.0801 - acc: 0.9710 - val_loss: 0.1243 - val_acc: 0.9485\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 121s 311ms/step - loss: 0.0764 - acc: 0.9728 - val_loss: 0.2578 - val_acc: 0.8877\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 121s 311ms/step - loss: 0.0774 - acc: 0.9721 - val_loss: 0.0731 - val_acc: 0.9722\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 121s 312ms/step - loss: 0.0684 - acc: 0.9760 - val_loss: 0.1975 - val_acc: 0.9315\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.0635 - acc: 0.9777 - val_loss: 0.9157 - val_acc: 0.7341\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 121s 310ms/step - loss: 0.0580 - acc: 0.9792 - val_loss: 0.3801 - val_acc: 0.8255\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0577 - acc: 0.9790 - val_loss: 0.1522 - val_acc: 0.9487\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 121s 311ms/step - loss: 0.0574 - acc: 0.9799 - val_loss: 0.0810 - val_acc: 0.9708\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0523 - acc: 0.9821 - val_loss: 0.0668 - val_acc: 0.9762\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 121s 310ms/step - loss: 0.0524 - acc: 0.9826 - val_loss: 0.0682 - val_acc: 0.9750\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 121s 310ms/step - loss: 0.0478 - acc: 0.9834 - val_loss: 0.0671 - val_acc: 0.9762\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 120s 307ms/step - loss: 0.0474 - acc: 0.9836 - val_loss: 0.4134 - val_acc: 0.8951\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0439 - acc: 0.9848 - val_loss: 0.0577 - val_acc: 0.9795\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0425 - acc: 0.9853 - val_loss: 0.3410 - val_acc: 0.8564\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.0407 - acc: 0.9862 - val_loss: 0.1360 - val_acc: 0.9570\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0417 - acc: 0.9849 - val_loss: 0.1808 - val_acc: 0.9486\n",
      "Epoch 23/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0405 - acc: 0.9865 - val_loss: 3.2664 - val_acc: 0.5442\n",
      "Epoch 24/50\n",
      "389/389 [==============================] - 121s 310ms/step - loss: 0.0388 - acc: 0.9865 - val_loss: 0.1636 - val_acc: 0.9533\n",
      "Epoch 25/50\n",
      "389/389 [==============================] - 120s 310ms/step - loss: 0.0363 - acc: 0.9879 - val_loss: 0.0710 - val_acc: 0.9759\n",
      "Epoch 26/50\n",
      "389/389 [==============================] - 121s 310ms/step - loss: 0.0348 - acc: 0.9879 - val_loss: 0.0619 - val_acc: 0.9758\n",
      "Epoch 27/50\n",
      "389/389 [==============================] - 120s 307ms/step - loss: 0.0355 - acc: 0.9881 - val_loss: 0.1347 - val_acc: 0.9451\n",
      "Epoch 28/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0355 - acc: 0.9882 - val_loss: 0.0729 - val_acc: 0.9774\n",
      "Epoch 29/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0318 - acc: 0.9897 - val_loss: 0.4208 - val_acc: 0.8418\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-melspectrogram_3!\n",
      "        valid set loss: 0.0577079967221\n",
      "        valid set accuracy: 0.979461984536\n",
      "        valid set auc: 0.997291320872\n",
      "--- experiment index of 4 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 127s 327ms/step - loss: 0.2557 - acc: 0.8968 - val_loss: 0.5098 - val_acc: 0.7645\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 121s 312ms/step - loss: 0.1472 - acc: 0.9452 - val_loss: 1.7554 - val_acc: 0.6245\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 121s 310ms/step - loss: 0.1208 - acc: 0.9555 - val_loss: 0.2501 - val_acc: 0.9011\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.1043 - acc: 0.9627 - val_loss: 0.1256 - val_acc: 0.9555\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 121s 311ms/step - loss: 0.0916 - acc: 0.9679 - val_loss: 0.7728 - val_acc: 0.6375\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0864 - acc: 0.9695 - val_loss: 0.3144 - val_acc: 0.8996\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 119s 305ms/step - loss: 0.0803 - acc: 0.9714 - val_loss: 0.0792 - val_acc: 0.9738\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 121s 312ms/step - loss: 0.0760 - acc: 0.9733 - val_loss: 0.4165 - val_acc: 0.8748\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.0727 - acc: 0.9737 - val_loss: 0.1205 - val_acc: 0.9538\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.0641 - acc: 0.9770 - val_loss: 0.1456 - val_acc: 0.9447\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0596 - acc: 0.9795 - val_loss: 0.1126 - val_acc: 0.9545\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0588 - acc: 0.9792 - val_loss: 0.0653 - val_acc: 0.9776\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 118s 303ms/step - loss: 0.0608 - acc: 0.9777 - val_loss: 0.6855 - val_acc: 0.7065\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0569 - acc: 0.9796 - val_loss: 0.1696 - val_acc: 0.9419\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 117s 302ms/step - loss: 0.0556 - acc: 0.9804 - val_loss: 0.2473 - val_acc: 0.9257\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0482 - acc: 0.9831 - val_loss: 1.0224 - val_acc: 0.6585\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0498 - acc: 0.9826 - val_loss: 0.1404 - val_acc: 0.9574\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.0468 - acc: 0.9841 - val_loss: 0.1671 - val_acc: 0.9481\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 119s 305ms/step - loss: 0.0467 - acc: 0.9832 - val_loss: 0.4716 - val_acc: 0.8710\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0436 - acc: 0.9841 - val_loss: 0.0743 - val_acc: 0.9726\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0423 - acc: 0.9852 - val_loss: 0.6919 - val_acc: 0.8421\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0415 - acc: 0.9855 - val_loss: 0.0641 - val_acc: 0.9767\n",
      "Epoch 23/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0409 - acc: 0.9854 - val_loss: 0.7909 - val_acc: 0.7142\n",
      "Epoch 24/50\n",
      "389/389 [==============================] - 118s 303ms/step - loss: 0.0368 - acc: 0.9873 - val_loss: 0.1402 - val_acc: 0.9416\n",
      "Epoch 25/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0348 - acc: 0.9881 - val_loss: 0.0535 - val_acc: 0.9808\n",
      "Epoch 26/50\n",
      "389/389 [==============================] - 119s 305ms/step - loss: 0.0384 - acc: 0.9860 - val_loss: 0.4844 - val_acc: 0.8638\n",
      "Epoch 27/50\n",
      "389/389 [==============================] - 118s 305ms/step - loss: 0.0357 - acc: 0.9876 - val_loss: 0.2655 - val_acc: 0.9090\n",
      "Epoch 28/50\n",
      "389/389 [==============================] - 121s 310ms/step - loss: 0.0324 - acc: 0.9885 - val_loss: 0.0698 - val_acc: 0.9758\n",
      "Epoch 29/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0300 - acc: 0.9898 - val_loss: 0.0718 - val_acc: 0.9754\n",
      "Epoch 30/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0304 - acc: 0.9895 - val_loss: 0.2395 - val_acc: 0.9067\n",
      "Epoch 31/50\n",
      "389/389 [==============================] - 125s 322ms/step - loss: 0.0336 - acc: 0.9879 - val_loss: 2.9298 - val_acc: 0.5267\n",
      "Epoch 32/50\n",
      "389/389 [==============================] - 121s 312ms/step - loss: 0.0299 - acc: 0.9896 - val_loss: 0.1983 - val_acc: 0.9167\n",
      "Epoch 33/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0298 - acc: 0.9895 - val_loss: 0.2157 - val_acc: 0.9422\n",
      "Epoch 34/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0290 - acc: 0.9902 - val_loss: 0.2107 - val_acc: 0.9260\n",
      "Epoch 35/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.0258 - acc: 0.9910 - val_loss: 0.0648 - val_acc: 0.9771\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-melspectrogram_4!\n",
      "        valid set loss: 0.0534720819434\n",
      "        valid set accuracy: 0.98075064433\n",
      "        valid set auc: 0.997574927741\n",
      "--- experiment index of 5 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 135s 347ms/step - loss: 0.2517 - acc: 0.8992 - val_loss: 1.1408 - val_acc: 0.6361\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 135s 347ms/step - loss: 0.1371 - acc: 0.9510 - val_loss: 0.8181 - val_acc: 0.7604\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 123s 315ms/step - loss: 0.1153 - acc: 0.9595 - val_loss: 0.1674 - val_acc: 0.9353\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 122s 314ms/step - loss: 0.1004 - acc: 0.9643 - val_loss: 0.2495 - val_acc: 0.9171\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 121s 312ms/step - loss: 0.0904 - acc: 0.9675 - val_loss: 1.2413 - val_acc: 0.6056\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 123s 317ms/step - loss: 0.0765 - acc: 0.9738 - val_loss: 0.0889 - val_acc: 0.9668\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.0791 - acc: 0.9727 - val_loss: 0.1343 - val_acc: 0.9548\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 123s 317ms/step - loss: 0.0703 - acc: 0.9759 - val_loss: 0.3304 - val_acc: 0.8447\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 121s 310ms/step - loss: 0.0750 - acc: 0.9733 - val_loss: 0.7324 - val_acc: 0.7066\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 121s 311ms/step - loss: 0.0647 - acc: 0.9778 - val_loss: 0.0783 - val_acc: 0.9725\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 121s 312ms/step - loss: 0.0566 - acc: 0.9809 - val_loss: 0.3512 - val_acc: 0.9056\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.0568 - acc: 0.9801 - val_loss: 0.0673 - val_acc: 0.9762\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.0553 - acc: 0.9810 - val_loss: 0.2673 - val_acc: 0.9196\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 120s 310ms/step - loss: 0.0524 - acc: 0.9825 - val_loss: 0.0777 - val_acc: 0.9734\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 122s 314ms/step - loss: 0.0500 - acc: 0.9828 - val_loss: 0.1908 - val_acc: 0.9487\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 120s 307ms/step - loss: 0.0489 - acc: 0.9832 - val_loss: 0.0812 - val_acc: 0.9733\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.0477 - acc: 0.9834 - val_loss: 0.2527 - val_acc: 0.9340\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0457 - acc: 0.9841 - val_loss: 0.2166 - val_acc: 0.9126\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 119s 305ms/step - loss: 0.0429 - acc: 0.9855 - val_loss: 0.0741 - val_acc: 0.9716\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0413 - acc: 0.9861 - val_loss: 0.0989 - val_acc: 0.9625\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 116s 299ms/step - loss: 0.0396 - acc: 0.9866 - val_loss: 0.5635 - val_acc: 0.7825\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.0387 - acc: 0.9870 - val_loss: 0.8777 - val_acc: 0.6952\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-melspectrogram_5!\n",
      "        valid set loss: 0.0672698939872\n",
      "        valid set accuracy: 0.976240335052\n",
      "        valid set auc: 0.996247644999\n",
      "--- experiment index of 6 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 123s 316ms/step - loss: 0.2421 - acc: 0.9024 - val_loss: 0.2878 - val_acc: 0.8744\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.1400 - acc: 0.9501 - val_loss: 0.1749 - val_acc: 0.9351\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 116s 297ms/step - loss: 0.1118 - acc: 0.9602 - val_loss: 0.3369 - val_acc: 0.8341\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0964 - acc: 0.9663 - val_loss: 0.2740 - val_acc: 0.8734\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0905 - acc: 0.9684 - val_loss: 0.2972 - val_acc: 0.8608\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 116s 299ms/step - loss: 0.0850 - acc: 0.9697 - val_loss: 1.5440 - val_acc: 0.5498\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 118s 302ms/step - loss: 0.0821 - acc: 0.9715 - val_loss: 0.3220 - val_acc: 0.9095\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 115s 296ms/step - loss: 0.0741 - acc: 0.9733 - val_loss: 0.2296 - val_acc: 0.8980\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0703 - acc: 0.9750 - val_loss: 0.0912 - val_acc: 0.9646\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0673 - acc: 0.9761 - val_loss: 0.6442 - val_acc: 0.7401\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 115s 296ms/step - loss: 0.0607 - acc: 0.9786 - val_loss: 0.2904 - val_acc: 0.8731\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 115s 297ms/step - loss: 0.0619 - acc: 0.9781 - val_loss: 0.2296 - val_acc: 0.8979\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 117s 302ms/step - loss: 0.0586 - acc: 0.9783 - val_loss: 1.0724 - val_acc: 0.6770\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0560 - acc: 0.9807 - val_loss: 1.0475 - val_acc: 0.6522\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 116s 299ms/step - loss: 0.0527 - acc: 0.9820 - val_loss: 0.1961 - val_acc: 0.9350\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 116s 299ms/step - loss: 0.0446 - acc: 0.9851 - val_loss: 4.0633 - val_acc: 0.5028\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 115s 296ms/step - loss: 0.0466 - acc: 0.9836 - val_loss: 0.0992 - val_acc: 0.9601\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0445 - acc: 0.9842 - val_loss: 0.1608 - val_acc: 0.9514\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 116s 297ms/step - loss: 0.0457 - acc: 0.9838 - val_loss: 1.9668 - val_acc: 0.6123\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-melspectrogram_6!\n",
      "        valid set loss: 0.0912334366903\n",
      "        valid set accuracy: 0.964642396907\n",
      "        valid set auc: 0.995171755226\n",
      "--- experiment index of 7 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 124s 319ms/step - loss: 0.2964 - acc: 0.8796 - val_loss: 0.3078 - val_acc: 0.8652\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.1524 - acc: 0.9461 - val_loss: 0.1509 - val_acc: 0.9431\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.1279 - acc: 0.9541 - val_loss: 0.7211 - val_acc: 0.7783\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.1132 - acc: 0.9602 - val_loss: 0.9973 - val_acc: 0.7655\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.0982 - acc: 0.9659 - val_loss: 0.4541 - val_acc: 0.7653\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.0889 - acc: 0.9686 - val_loss: 2.6929 - val_acc: 0.5438\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0824 - acc: 0.9711 - val_loss: 0.1080 - val_acc: 0.9573\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0783 - acc: 0.9733 - val_loss: 1.6211 - val_acc: 0.5540\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 116s 299ms/step - loss: 0.0788 - acc: 0.9713 - val_loss: 1.0880 - val_acc: 0.6152\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0726 - acc: 0.9740 - val_loss: 0.3344 - val_acc: 0.8450\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0700 - acc: 0.9754 - val_loss: 0.2635 - val_acc: 0.8814\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 116s 299ms/step - loss: 0.0672 - acc: 0.9759 - val_loss: 0.0832 - val_acc: 0.9696\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0651 - acc: 0.9768 - val_loss: 0.1937 - val_acc: 0.9156\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.0626 - acc: 0.9785 - val_loss: 1.1261 - val_acc: 0.6057\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.0662 - acc: 0.9762 - val_loss: 0.1463 - val_acc: 0.9433\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 115s 297ms/step - loss: 0.0599 - acc: 0.9796 - val_loss: 1.1838 - val_acc: 0.7668\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 115s 295ms/step - loss: 0.0583 - acc: 0.9795 - val_loss: 0.7273 - val_acc: 0.7452\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 114s 294ms/step - loss: 0.0552 - acc: 0.9800 - val_loss: 0.1064 - val_acc: 0.9577\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.0534 - acc: 0.9813 - val_loss: 1.1122 - val_acc: 0.7763\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0488 - acc: 0.9828 - val_loss: 0.1783 - val_acc: 0.9452\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 118s 303ms/step - loss: 0.0496 - acc: 0.9816 - val_loss: 0.0858 - val_acc: 0.9697\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 118s 302ms/step - loss: 0.0479 - acc: 0.9829 - val_loss: 0.1050 - val_acc: 0.9598\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-melspectrogram_7!\n",
      "        valid set loss: 0.0831669406178\n",
      "        valid set accuracy: 0.969555412371\n",
      "        valid set auc: 0.99537149957\n",
      "--- experiment index of 8 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 126s 324ms/step - loss: 0.2688 - acc: 0.8879 - val_loss: 0.3941 - val_acc: 0.8229\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 119s 307ms/step - loss: 0.1484 - acc: 0.9458 - val_loss: 0.3719 - val_acc: 0.8614\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.1268 - acc: 0.9541 - val_loss: 1.0502 - val_acc: 0.7509\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 120s 310ms/step - loss: 0.1120 - acc: 0.9596 - val_loss: 0.1450 - val_acc: 0.9387\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.1036 - acc: 0.9632 - val_loss: 0.1445 - val_acc: 0.9471\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0977 - acc: 0.9646 - val_loss: 0.4292 - val_acc: 0.8638\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 116s 297ms/step - loss: 0.0888 - acc: 0.9686 - val_loss: 1.5167 - val_acc: 0.5527\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 115s 296ms/step - loss: 0.0841 - acc: 0.9697 - val_loss: 0.5767 - val_acc: 0.7394\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 114s 293ms/step - loss: 0.0776 - acc: 0.9726 - val_loss: 0.0927 - val_acc: 0.9653\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 115s 297ms/step - loss: 0.0725 - acc: 0.9742 - val_loss: 0.5862 - val_acc: 0.7447\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.0703 - acc: 0.9749 - val_loss: 0.0715 - val_acc: 0.9754\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 115s 295ms/step - loss: 0.0632 - acc: 0.9778 - val_loss: 0.2197 - val_acc: 0.9149\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0661 - acc: 0.9763 - val_loss: 0.1933 - val_acc: 0.9265\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 115s 295ms/step - loss: 0.0632 - acc: 0.9768 - val_loss: 0.1057 - val_acc: 0.9625\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 115s 295ms/step - loss: 0.0618 - acc: 0.9780 - val_loss: 0.2115 - val_acc: 0.9100\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 116s 299ms/step - loss: 0.0538 - acc: 0.9811 - val_loss: 0.0694 - val_acc: 0.9752\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 114s 294ms/step - loss: 0.0528 - acc: 0.9810 - val_loss: 0.7619 - val_acc: 0.8228\n",
      "Epoch 18/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0511 - acc: 0.9819 - val_loss: 0.4115 - val_acc: 0.8907\n",
      "Epoch 19/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0508 - acc: 0.9821 - val_loss: 0.0985 - val_acc: 0.9650\n",
      "Epoch 20/50\n",
      "389/389 [==============================] - 115s 296ms/step - loss: 0.0450 - acc: 0.9838 - val_loss: 0.7680 - val_acc: 0.8288\n",
      "Epoch 21/50\n",
      "389/389 [==============================] - 116s 299ms/step - loss: 0.0464 - acc: 0.9833 - val_loss: 0.1140 - val_acc: 0.9600\n",
      "Epoch 22/50\n",
      "389/389 [==============================] - 115s 295ms/step - loss: 0.0446 - acc: 0.9843 - val_loss: 0.3387 - val_acc: 0.9161\n",
      "Epoch 23/50\n",
      "389/389 [==============================] - 116s 297ms/step - loss: 0.0447 - acc: 0.9845 - val_loss: 0.4907 - val_acc: 0.8870\n",
      "Epoch 24/50\n",
      "389/389 [==============================] - 115s 296ms/step - loss: 0.0429 - acc: 0.9848 - val_loss: 0.1669 - val_acc: 0.9356\n",
      "Epoch 25/50\n",
      "389/389 [==============================] - 114s 294ms/step - loss: 0.0398 - acc: 0.9860 - val_loss: 0.3189 - val_acc: 0.9230\n",
      "Epoch 26/50\n",
      "389/389 [==============================] - 115s 297ms/step - loss: 0.0382 - acc: 0.9864 - val_loss: 0.5591 - val_acc: 0.8686\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-melspectrogram_8!\n",
      "        valid set loss: 0.0694007480939\n",
      "        valid set accuracy: 0.975193298969\n",
      "        valid set auc: 0.996432210018\n",
      "--- experiment index of 9 ---\n",
      "Getting model...\n",
      "Starting to train...\n",
      "Epoch 1/50\n",
      "389/389 [==============================] - 126s 323ms/step - loss: 0.2789 - acc: 0.8836 - val_loss: 0.3698 - val_acc: 0.8455\n",
      "Epoch 2/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.1449 - acc: 0.9483 - val_loss: 0.2156 - val_acc: 0.9084\n",
      "Epoch 3/50\n",
      "389/389 [==============================] - 120s 308ms/step - loss: 0.1218 - acc: 0.9565 - val_loss: 1.2672 - val_acc: 0.7034\n",
      "Epoch 4/50\n",
      "389/389 [==============================] - 120s 309ms/step - loss: 0.1040 - acc: 0.9635 - val_loss: 0.3576 - val_acc: 0.8834\n",
      "Epoch 5/50\n",
      "389/389 [==============================] - 119s 306ms/step - loss: 0.0994 - acc: 0.9652 - val_loss: 0.2388 - val_acc: 0.8970\n",
      "Epoch 6/50\n",
      "389/389 [==============================] - 118s 304ms/step - loss: 0.0895 - acc: 0.9689 - val_loss: 0.1395 - val_acc: 0.9457\n",
      "Epoch 7/50\n",
      "389/389 [==============================] - 117s 301ms/step - loss: 0.0818 - acc: 0.9711 - val_loss: 0.0975 - val_acc: 0.9648\n",
      "Epoch 8/50\n",
      "389/389 [==============================] - 117s 302ms/step - loss: 0.0800 - acc: 0.9717 - val_loss: 2.3075 - val_acc: 0.5123\n",
      "Epoch 9/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.0694 - acc: 0.9762 - val_loss: 0.4954 - val_acc: 0.8576\n",
      "Epoch 10/50\n",
      "389/389 [==============================] - 116s 299ms/step - loss: 0.0706 - acc: 0.9754 - val_loss: 0.2211 - val_acc: 0.9258\n",
      "Epoch 11/50\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.0657 - acc: 0.9772 - val_loss: 0.1320 - val_acc: 0.9476\n",
      "Epoch 12/50\n",
      "389/389 [==============================] - 118s 302ms/step - loss: 0.0620 - acc: 0.9780 - val_loss: 0.3861 - val_acc: 0.8965\n",
      "Epoch 13/50\n",
      "389/389 [==============================] - 115s 295ms/step - loss: 0.0611 - acc: 0.9782 - val_loss: 0.6106 - val_acc: 0.8330\n",
      "Epoch 14/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0582 - acc: 0.9794 - val_loss: 4.2713 - val_acc: 0.5035\n",
      "Epoch 15/50\n",
      "389/389 [==============================] - 116s 298ms/step - loss: 0.0581 - acc: 0.9797 - val_loss: 0.2059 - val_acc: 0.9413\n",
      "Epoch 16/50\n",
      "389/389 [==============================] - 114s 293ms/step - loss: 0.0534 - acc: 0.9814 - val_loss: 0.6214 - val_acc: 0.8487\n",
      "Epoch 17/50\n",
      "389/389 [==============================] - 116s 299ms/step - loss: 0.0486 - acc: 0.9841 - val_loss: 0.3001 - val_acc: 0.8708\n",
      "Training is done. Loading the best weights...\n",
      "Evaluating...\n",
      "Result: Done for sub-segment_cnn3x3-melspectrogram_9!\n",
      "        valid set loss: 0.0974746334184\n",
      "        valid set accuracy: 0.964803479381\n",
      "        valid set auc: 0.99282093192\n"
     ]
    }
   ],
   "source": [
    "dataset_types = ['onset', 'segment']\n",
    "model_names = ['cnn3x3-spectrogram','cnn3x3-melspectrogram']\n",
    "subonset_cnn3x3spectrogram_aucs, subonset_cnn3x3melspectrogram_aucs = [], []\n",
    "subsegment_cnn3x3spectrogram_aucs, subsegment_cnn3x3melspectrogram_aucs = [], []\n",
    "\n",
    "for dataset_type in dataset_types:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Test on sub excerpts of {}.\".format(dataset_type))\n",
    "    if dataset_type == 'onset':\n",
    "        typeshape = ONSET_INPUT_SHAPE\n",
    "        batch_size = 256\n",
    "    elif dataset_type == 'segment':\n",
    "        typeshape = SEGMENT_INPUT_SHAPE\n",
    "        batch_size = 128\n",
    "        \n",
    "    csv_path = os.path.join(DIR_PEDAL_METADATA, \"pedal-{}_subdf.csv\".format(dataset_type))\n",
    "    tracks = pd.read_csv(csv_path)\n",
    "    \n",
    "    for model_name in model_names:\n",
    "\n",
    "        print(\"-\" * 40)\n",
    "        print(\"We're gonna use {} model.\".format(model_name))\n",
    "        \n",
    "        for experiment_indx in range(confidence_interval_times):\n",
    "            print(\"--- experiment index of {} ---\".format(experiment_indx))\n",
    "            exp_name = 'sub-{}_{}_{}'.format(dataset_type, model_name, experiment_indx)\n",
    "\n",
    "            training = tracks.loc[(tracks['category'] == 'train') & (tracks['interval_time'] == experiment_indx)]\n",
    "            validation = tracks.loc[(tracks['category'] == 'valid') & (tracks['interval_time'] == experiment_indx)]\n",
    "\n",
    "            # make labels as one-hot vector\n",
    "            y_train = training.label.values\n",
    "            y_valid = validation.label.values\n",
    "            y_train = keras.utils.to_categorical(y_train, 2)\n",
    "            y_valid = keras.utils.to_categorical(y_valid, 2)\n",
    "\n",
    "            # preparing data generators\n",
    "            steps_per_epoch = len(y_train) // batch_size\n",
    "            gen_train = data_gen(dataset_type, training, y_train, True, batch_size=batch_size)\n",
    "            gen_valid = data_gen(dataset_type, validation, y_valid, False, batch_size=batch_size)\n",
    "\n",
    "            # callbacks\n",
    "            callbacks = get_callbacks(name=exp_name, patience=patience)\n",
    "            early_stopper, model_saver, weight_saver, csv_logger = callbacks\n",
    "\n",
    "            print(\"Getting model...\")\n",
    "            if model_name == 'cnn3x3-spectrogram':\n",
    "                model = model_conv3x3_spectrogram(n_out=2, inputshape=typeshape)\n",
    "            elif model_name == 'cnn3x3-melspectrogram':\n",
    "                model = model_conv3x3_melspectrogram(n_out=2, inputshape=typeshape)\n",
    "\n",
    "            # model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "            model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "            # model.summary()\n",
    "\n",
    "            print(\"Starting to train...\")\n",
    "            model.fit_generator(gen_train, steps_per_epoch, epochs=epochs,\n",
    "                                callbacks=callbacks,\n",
    "                                validation_data=gen_valid,\n",
    "                                validation_steps=len(y_valid) // batch_size)\n",
    "\n",
    "            print(\"Training is done. Loading the best weights...\")\n",
    "            model.load_weights(os.path.join(DIR_SAVE_MODEL,\"{}_best_weights.h5\".format(exp_name)))\n",
    "\n",
    "            print(\"Evaluating...\")\n",
    "            scores = model.evaluate_generator(gen_valid, len(y_valid) // batch_size)\n",
    "            y_pred = model.predict_generator(gen_valid, len(y_valid) // batch_size)\n",
    "            auc = roc_auc_score(y_valid[:len(y_pred)], y_pred)\n",
    "\n",
    "            print(\"Result: Done for {}!\".format(exp_name))\n",
    "            print(\"        valid set loss: {}\".format(scores[0]))\n",
    "            print(\"        valid set accuracy: {}\".format(scores[1]))\n",
    "            print(\"        valid set auc: {}\".format(auc))\n",
    "\n",
    "            if dataset_type == 'onset' and model_name == 'cnn3x3-spectrogram':\n",
    "                subonset_cnn3x3spectrogram_aucs.append(auc)\n",
    "            elif dataset_type == 'onset' and model_name == 'cnn3x3-melspectrogram':\n",
    "                subonset_cnn3x3melspectrogram_aucs.append(auc)\n",
    "            elif dataset_type == 'segment' and model_name == 'cnn3x3-spectrogram':\n",
    "                subsegment_cnn3x3spectrogram_aucs.append(auc)\n",
    "            elif dataset_type == 'segment' and model_name == 'cnn3x3-melspectrogram':\n",
    "                subsegment_cnn3x3melspectrogram_aucs.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subonset_cnn3x3input_aucs = np.concatenate((subonset_cnn3x3spectrogram_aucs, subonset_cnn3x3melspectrogram_aucs), axis=0)\n",
    "subsegment_cnn3x3input_aucs = np.concatenate((subsegment_cnn3x3spectrogram_aucs, subsegment_cnn3x3melspectrogram_aucs), axis=0)\n",
    "\n",
    "\n",
    "rows = zip(*[subonset_cnn3x3input_aucs, subsegment_cnn3x3input_aucs,\n",
    "             ['spectrogram']*confidence_interval_times + ['melspectrogram']*confidence_interval_times,\n",
    "             np.concatenate((range(confidence_interval_times),range(confidence_interval_times)))])\n",
    "column_names = ['subonset_cnn3x3input_auc','subsegment_cnn3x3input_auc',\n",
    "                'input_type', 'interval_time']\n",
    "subdf_cnn3x3input_aucs = pd.DataFrame(rows, columns=column_names)\n",
    "subdf_cnn3x3input_aucs.to_csv(os.path.join(DIR_SAVE_MODEL, 'subdf_cnn3x3input_aucs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa88b327750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABakAAAFLCAYAAADceQBQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xl4VOXZx/HvzCQhgSSQhAABVGQR\nEHAXxA0VFawg1g0FrYpiQSruFX0VsCiC2lpRAUWlbt2oC4KA1qWuLKIICgKiIgYDxLCHrDPz/pGa\nNh2URAMD+P1cl9c1M/dzznnOeHNm5pczZwLRaDSKJEmSJEmSJElxEIz3BCRJkiRJkiRJP1+G1JIk\nSZIkSZKkuDGkliRJkiRJkiTFjSG1JEmSJEmSJCluDKklSZIkSZIkSXFjSC1JkiRJkiRJihtDakmS\nJEmSJElS3BhSS5IkSZIkSZLiZoch9dixYznppJNo27Yty5cv3+6YcDjM7bffzsknn8wpp5zClClT\nqlWTJEmSJEmSJP28JexoQPfu3fnVr35F//79v3fMtGnTWLVqFa+88gobN27kzDPPpGvXrjRv3vwH\na5IkSZIkSZKkn7cdnkl9xBFHkJOT84NjZsyYwbnnnkswGCQzM5OTTz6ZWbNm7bAmSZIkSZIkSfp5\nq5VrUufl5dG0adPK+zk5OaxZs2aHNUmSJEmSJEnSz5s/nChJkiRJkiRJipsdXpO6OnJycvjmm284\n6KCDgKpnT/9QrSY2bCgkEonWxnQlSZIkSZIkSbUsGAyQkVGvxsvVSkjds2dPpkyZwqmnnsrGjRt5\n9dVXeeaZZ3ZYq4lIJGpILUmSJEmSJEl7mR2G1HfccQevvPIK3377LZdeeikNGjTgpZdeYuDAgQwd\nOpROnTrRp08fFi5cyKmnngrAkCFD2GeffQB+sCZJkiRJkiRJ+nkLRKPRPeL05IKCrZ5JLUmSJEmS\nJEm7qWAwQFZWas2X2wlzkSRJkiRJkiSpWgypJUmSJEmSJElxY0gtSZIkSZIkSYobQ2pJkiRJkiRJ\nUtwYUkuSJEmSJEmS4saQWpIkSZIkSZIUN4bUkiRJkiRJkqS4MaSWJEmSJEmSJMWNIbUkSZIkSZIk\nKW4MqSVJkiRJkiRJcWNILUmSJEmSJEmKG0NqSZIkSZIkSVLcGFJLkiRJkiRJkuLGkFqSJEmSJEmS\nFDeG1JIkSZIkSZKkuDGkliRJkiRJkiTFjSG1JEmSJEmSJCluDKklSZIkSZIkSXFjSC1JkiRJkiRJ\nihtDakmSJEmSJElS3BhSS5IkSZIkSZLixpBakiRJkiRJkhQ3htSSJEmSJEmSpLgxpJYkSZIkSZIk\nxY0htSRJkiRJkiQpbgypJUmSJEmSJElxY0gtSZIkSZIkSYobQ2pJkiRJkiRJUtwYUkuSJEmSJEmS\n4saQWpIkSZIkSZIUN4bUkiRJkiRJkqS4MaSWJEmSJEmSJMWNIbUkSZIkSZIkKW4MqSVJkiRJkiRJ\ncWNILUmSJEmSJEmKG0NqSZIkSZIkSVLcGFJLkiRJkiRJkuLGkFqSJEmSJEmSFDeG1JIkSZIkSZKk\nuDGkliRJkiRJkiTFjSG1JEmSJEmSJCluDKklSZIkSZIkSXFjSC1JkiRJkiRJihtDakmSJEmSJElS\n3BhSS5IkSZIkSZLixpBakiRJkiRJkhQ3CdUZ9OWXXzJs2DA2btxIgwYNGDt2LC1atKgyJj8/n+HD\nh5Obm0t5eTmDBg2iT58+ABQUFHDzzTeTl5dHeXk5Xbp04dZbbyUhoVqblyRJkiRJkiTtpap1JvWI\nESPo168fL7/8Mv369WP48OExY8aMGUPHjh2ZNm0azzzzDPfddx95eXkATJw4kVatWjFt2jRefPFF\nFi9ezCuvvFK7eyJJkiRJkiRJ2uPs8FTmgoIClixZwuTJkwHo1asXo0aNYv369WRmZlaOW7p0KRdf\nfDEAmZmZtGvXjpkzZzJgwAACgQCFhYVEIhFKS0spKyujcePGO2mXJEmSJO3xIqXU+/wO6uT9nWDp\nt4Tr7s+2FtdS0rTf9sdHoyR//TApuY8TKlpJJDGDkibnUdh6OAQTAcj+Z/p2Fw0n78v64z4hcf3b\nNPjg9O2OKc7px5aOEwFIXXwlSRveIVS0EoDNHSZQ0rT/T9tfSZKkn7EdhtR5eXk0btyYUCgEQCgU\nolGjRuTl5VUJqTt06MCMGTPo1KkTubm5LFiwgObNmwNw5ZVXctVVV3HsscdSVFRE//79Ofzww2s0\n0ays1BqNlyT9ONFomEAgFO9p7DR7+/5J0p6u8jg9/2pYOQ7qtYCm55Pw9bOkLx4EWU2hee/YBT/9\nAyz7LSQ2gP0vIpT/DnW/up+6daJwxP0VY9peXXWZ3KlQuJJQg7ZkZ6dB8gGw9X/GfDYeImUkN+pA\ncnZaxWNb5kFGByhdC+Ei0tOS4btadfdPkiRJlWrtotDDhg1j9OjR9OnTh6ZNm9K1a9fKYHvWrFm0\nbduWJ554gsLCQgYOHMisWbPo2bNntddfULCVSCRaW9OVJH2P7Ow0iopei/c0dpqUlO7k52+J9zQk\nSd8jOzuNoo3PkrxiAgGguMstROu3JJRaj6SPJxBZdAMlWXVjlquz8hGCQFmbsylv25fAxsNJfmMQ\n0RUTKG59HNTJgAP/K9wu2UTyiocJACUtTyJS9FrFp6P/GhNcM486kTKioWSKm7eH714fTx4PQPKM\n9wiEiygtXUK4mq+dvg5JkqS9WTAY+FEnG+/wmtQ5OTmsXbuWcDgMQDgcZt26deTk5FQZl5mZyb33\n3suLL77IxIkTKSwspHXr1gA8/fTTnHHGGQSDQdLS0jjppJOYO3dujScrSZIkae8X3LySQKSMaDCJ\naP2WAEQy2wMQ2PQ5RMMxy0SDSRX1zV9AeTHBjcsr7kfKCG7+KmZ8wpfTCISLiaS3JNL4yO3OI2HF\nFADC+/WEpO1fKkSSJEk/3Q5D6qysLNq3b8/06dMBmD59Ou3bt69yqQ+ADRs2UF5eDsDs2bNZvnw5\nvXr1AqB58+a89dZbAJSWljJ79mzatGlTqzsiSZIkae8QKNlQcSMh5T8P/vt2IBqGks0xy5QfcAHR\nQIiE3DdImdaLpAV/+M/6itdXHRwuJeGLqRXLtTl3+3PYuIJQ/gKigSDlrc/+CXsjSZKkHanW5T5G\njhzJsGHDGD9+POnp6YwdOxaAgQMHMnToUDp16sSiRYu48847CQaDZGRkMHHiRFJSKt5I3nLLLYwY\nMYLevXsTDofp0qUL55133s7bK0mSJEl7rGidjIob5UWVjwXKKm5HAyGoE3tWc6RJZ0pOfpzQN+9A\neSGRrI4kzf0dgXAx0ToNqowNff0qgZINRFKyCTc/cbtzqDyLuunxROvlbHeM4i8zM4VQqNauYrnb\nCYfLWb++aMcDJUnaw1Xr1bxVq1ZMmTIl5vFJkyZV3u7WrRvdunXb7vL77rsvkydP/pFTlCRJkvRz\nEklvQTSYSCBSSmDTF0TrtySwYQlAxeU/AiECW1ZV3E9pBAnJECknmtqM8gP6AhD66uWKgDqhbuWl\nQioWiJKw4h8AhFudBcHtfCQqyieU+yYA5W08uWZ3Fgol7PW/pSFJ0s/B3vsnZ6mG6mekkJSwd/6T\nKC0vZ9MGz8CQJEl7iDoNCLf4BQlfTCVpznAiDQ8itLri8oFlbS8EIPnVAQCUHHsvkexDCH67kMRF\n44lkHkigdBPBvDkV4w+8tMplQ4Jr5xLcsopoYj3KW5y+3c0nrHiOQLSccMNDiGYcEFv/+GECpZug\nrBCA0MoZBL9dSDjnGCJNj6m950Haxfbmz0TRaJhAIBTvaew0nnUvaU8XiEaj0XhPojpK/3UuFK2p\nvF/S+JcU7zMQwtuov+CcmPHFTftT0rQ/gdIC0hddFFtvfhklTc4mWJxL2idXxNSL9ruK0uzTCBV+\nRuqnV8fUt+1/I2VZJxLasojUZcNi6oWtR1DeoAsJG+dSb8XtMfWtbccQTjuIxII3qPvlPbH19vcT\nrteGpPyZpHz1QEx9S8dHiCQ3p86aZ0nOfSymvvmgp4gmZVHnm2dI/uaZmPqmQ/8Bobokfz2JOmuf\nj60fMQOAlJXjSPp2VtViMJlNhz0HQN0vxpK4/s0q5WhiJpsPfhqAep+NJGHTvCr1SJ2mbOn0aEV9\n2U0kbPm4Sj1ctzVbDxwHQOqSoYS2rahSL0/rRGHbikvOpH18OcGSb6rW63emsM1IANIXXkigrOo1\nCMsyu7Gt5U0A1P/wLIgUA5CUGGL1lk18Va8rCzPOB+CM3Nj/95+nnsDiBr8kIVLML765Kaa+LL0n\ny9JPIzm8kVPzRsTUF9fvw+dpJ1GvbB3d194ZU1/Y4Dy+Sj2GBqWrOH7d72PqH2RexOq6R5BV8hnH\n5D8YU5+bNZC1KR1pXPQJXQoqvu3QLK0+pWUVPzBk7+1+vfed0oY9KWoxtKI+/xf8r1113Muu8w3h\nObFnjZW37U+k0eEENq4g8ePxsfUDLyOS1YFgwWISlsT2RlmnK4k2aE1w3QckLIvtjbJDriWatg/B\nvNmVX7GuUj98GNG6jQjlvkHoy2kx9dLOI6BOfUJfvUxo1cux9a6jISGZlK+XUfr5X2Lq9l7Ney8x\nIUggEICWl1T8V/wtvBPbm7QZDPv1hcKvYXZsb9LuemjeGzYvg3m/jq13vBWanAwbPoIPromtHzwa\nso+G/Pdg4S2x9cP/CBmHwJpX4ZM7YuudH4b0tpA7DZb+57gbjUYpK4943NsNe+87vt/bO3svKTFE\neVoWZR0uJ2HJ5IprR0fKIJRENCWbaHImkcwDSVz+14p1ZXWEQLDixxK3rIJwKQQCROu3orz1OYS+\n/ieES/6za5s+J1BWSFmb8yjveAVJb19Xdd8jYYIbPyMQKaWk8wgSvoh97oKbVxIojb0udiSlEdF6\nTQjv35tw8xMJbFtH4gdjqowJBTPY1PRKe4/a6b262z4gHNnwn3pKNmVH3AxA4qLxBDZVPa5FU5tT\ndmjF//PEBX8gsDW3ar1+a8oOurKiPv8uAkX5VeqRzAMp73A5AElzR8L/9EEk+zDK21X8ISXpvZur\n9B5ApMlRlWfnx/QeEG7WjXDLPlBeTNLsWwgFMyrfx8POP+4lHTqCCV8n1eizxn97N/s3FNRpQ7Nt\n8zl8/VMx9bcaXc/GpH3Zb+u7HLzx7zH11xr/H4WJjWi15XU6bJoaU38l53aKQw1ou3kmbTfPiqnP\naDqW8mAyHTY+T6ut/6pSa5ZWn6JjbgMg4bO/E1wzp+rCoTqUHn1XRX3p0wTzP6xaT0qntMvIivri\nRwmuX1KlHO/eC+WcQ36TivdJvubu3cc93+/9T93e2/16L6UJSSfEfqbfkb3zT6SSJGmnCwQChCMb\nCJcuIVz0GpRsIum/goLvhEs/JlzUkEDxOhK3Uy8vXUikqC6B4q+3Xy/5kEhRgEDxiu+pzydSVESw\nZDEJ26mXFc8lWlRAsOTD76nPJpqYS7B0YZV6KJixw+dA0k4USqK8068JlKyPCWsAin75KvBfYU1C\nMpF/n/X830Fh6Ot/VlkuUr9VlaAwRjBEWadfVwaFbCekLuv4a8L79ag47s2L/cAqSZKkmtljzqQu\nKNhKJLJHTFV7qOzsNCa8/1a8p7FTDDriGL/apmrLzk7b66/tmJ+/Jd7T2CvYK5J2Bo8tqgn7pXbt\nzZ+JBh95vL0iSbtAMBggKyu1xst5JvUezF+yVnUFAqG9/g2ZJEmSJEmS9kx7b8L5M+AvWUuSJEmS\nJEna0xlSS5IkSZIkSf/mN9dVXfZK7dl7n0VJkiRJkiSphvzmuqrLXqk9wV22JUmSJEmSJEmS/och\ntSRJkiRJkiQpbgypJUmSJEmSJElxY0gtSZIkSZIkSYobfzhRkiRJO52/fC5JkiTp++y9nxQkSZK0\n2/CXzyVJkiR9H0NqSZJ2ovoZKSQl+HIrSZIkSdL38VOzJEk7UVJCAhPefyve09gpBh95fLynIEmS\nJEnaC/jDiZIkSZIkSZKkuDGkliRJkiRJkiTFjZf7kCRJkiRJkrRT+Ds9qg47RJIkSZIkSdJO4e/0\nqDr26pDav9RIkiRJkiRJ0u5tr05w9+a/1IB/rZEkSZIkSZK059urQ2pJ2hn8loYkSZIkSVLtMWWR\npBryWxqSJEmSJEm1x5BakiRpN+C3NCRJkiT9XPlJSJIkaTfwc/iWRmm4jN+9/Sf+uuQ1vi3aRMsG\nOVzf5Xz6dzx1u8tEo1EmfvgCj340nS835ZGRnMb5B3Zn5HEDSAz9523sgjWf8bt3JjM79xNKI+Xs\nm96YYV0v5PwO3QFoN7E/qzavrbLuUCDIlhtfAeCrTWto//CFMds/cb9DeanvPbX1FEiSJEn6HobU\nkiRJ2iVu+dcjjP/gefar34Rz253AC8vfZuCMu2mQnMbprbvGjH9g/rMMe2MiDeqkcsGBJzN79Sfc\nN+/vlITLuLf7EAA+yFvGqX+5jqLyEk7Y91BaZTTj6y3r+GLjNzHrG3L4WZW3Q4FgTL1pakN+2fY/\nlzxqk9m8NnZbkiRJ0g4YUkuSJGmnyy/M57GPpgMw5azf0TG7JQc3bs1vX5/A6Hef2m5IPeXTNwC4\nrktfbjjqAhauXUHXJwbx6EfT+e1R/WhUL4Nb35xEUXkJtxx9Ebcee/EPzuGe7lf+YL1VRtMdjpEk\nSZJU+wypJUmStNMtzl9MSbiM5IQkOma3BKBz0/YAfJz/OeFImFAwVGWZ5IQkAD7J/4JtZcV8uGY5\nAKXhMj799ivS69Tj3dyPAfhwzXL2eeAsAgTo3uJwxp40mEb1Mqqsr9m4X1IeCXNgwxbcfPSFnNqy\nc5X6+3lLyfrD6aQlpdClWQdGHX85B2TtU/tPhiRJkqQqYr/nKEmSJNWyNVvXAJCamFL5WL1/3y6P\nhPm2aHPMMjccdQEJwRB///QNGt7XiyEv/6GytrZwPeuLNlMeCQMwe/Un9G5zDOl16vG3T1/n0umj\nK8dmJKfRu80xnN2uG20ymzP3myWc89xtzM9bWjlmv/pN6NPmWM4/sDtJoUSmffYuvf7+WzaXFNbu\nEyFJkiQphmdSS5IkaadrktoEgK1lRZWPbS2tuJ0QDNEwJT1mmR4tO7Pgssd5cfk7bCot5OhmHek/\n9XcUlhWTXa8BDevWJxgIEolGuPGoflzXpS/vfL2IU/9yHf/66iM2lxSSXqce7108gUAgAEAkGuHY\nJ4fw0drPmLr8bY7Iace+6Y359NdPV243f9tGWo8/n9wt+cxZvTjmjGtJkiRJtcszqSVJkrTTdcju\nQFIokeLyUj7J/wKAed8sAaBjdktCwRDLClaxrGAV28qKASgLl9MqoxnXdunLyOMGsLZwA4VlxaQl\n1eXInPYkhRJpn7XvdreXEAyRnJBEQdEm1hdXPUs7Go0CUFxeBsCqzWspDZdtdz3F3/O4JEmSpNqz\nx5xJfcUrl1Z+TRTgjNa/ZEDHgWwr20a/l86JGX9+u/5clT2IraUbmfThiJj6cfv24YimJ7G+aB1P\nLLwzpt59//M4qPExrN26ij9/8vuY+mmtL6JdwyP4evNn/GPJgzH1M9oOpFVGRz7f8AkvLpsUUz/n\nwN+wT3obln47n5krnoqp9+t4PY1T92XR2nd57cu/x9QvPvj/APjHp28w6aNpMfVn+oygYd36PPXx\nyzz9ycsx9efPGU3dxGQeXjCV55a+GVN/+YKKr9P+cd7fmfn5nCq15IQ6TD33LgDueu9p/vXVh1Xq\nmSnp/OXMkQAMf/NR5v77A+h3mqVl83ivmwG48bXxLFq3okq9dUZzHup5HQDX/2son2+sWu/YsBN3\nHDsWgMH/vJy8wm+q1I9o3Jlbu1Zs/9JZF7KheH2V+nHNu3H9ETcBcP70sygur/ggnJgY4pstm+jY\nqCuntDwfgPvmXB3z3ByWcwLd9vslpeFiHnr/ppj6Uc170rX5abtV7/1tcX0ikQ0A3H3SlRzcuDWv\nr/yAsbOfiVn+gVOv5YCsfXhpxWzGvT8lpv7Y6cNont5ot+q9YDCDsrIwGcmZTO5ZcSbcHbNHMn/t\nvCrL59RryoRTHgXg1ndu4pNvP65Sb9WgNb8/YRyw496b/NEdbCzOr1Lfv0EHzmx3BQCPfHAbhWVV\nQ5G2WYfxizYVP+r14Ps3UhYurbr+3aT3ln27jIEvXhdTv6lrf05qcTgL167gt6+Pj6nffvxlHNWs\nA3NWL2bEW4/F1HeX3hv//nie+egvMfUXzpwBwEMLxvHPr2ZVqSUnJPPXXs8B8Pv5Y3k7t2rv/lDv\nJSaG2FaWxKWH3ArAlCUPkLu5am81qtec/p1urNiPj+9hXWFulXrz9Nace+BVwO7Ve98dWy7s2IOL\nOvXg222b6D/19pjlBx7Sm3Pan0ju5nVc9tKYmPrQI8/l9NZdWV7wNVe9cl9MPV69992x5aHuj9As\nrTkvfPYsf1ocu/7HejxFVkoWf136DH9dGrv+P5/+D+om1uXxTybx4ornY+rf9d69793LIx9UXT4x\nlMRvjrwHgBmfPcGygqqvufUS07ni8FEV61n6CF9uXFyl3iA5e7fpvV+98CuyUtLJ21rAcU8OoX6d\nVDYWbwFg2NEX0uMv1/H214sA6JTdkgbJqXTI3p83v/qIw3LaMuvzORT8+5Ig2XUbcPaz/8eFHXtw\nU9f+/GranYx46zEenP8sG0u2ApCZksaLy9+hUb0M+ky5mbqJydQJJbK1tIitZUUEqHhPAvDHeVN4\nfOFL1K9Tj4RgiA3FWyiLlJOZks6J+x5ard67/Z1RlJWFq9RHHTuGTg0P4s2v3+C+D+6JWf7ebvfT\nOqMNL6+cyYSPHoip76req+3jHvy019zExBAdG2ZV/ojlgOl3sXpL1d7r0vRAftftcgAueGEk6//n\ncjEn7HcYNx99IQB9ptxMcXlJlfpprY7ims7nAdDjL7GveWe168avD+3DtrJifvmPW2LqP+W4Fwxm\ncHmHK+nR4jRWbPiMG96MPe5ee/iNdNvnRD7+dhG3vTMspn5LlxF0zunCvLy5jJ4bu/2fU+8tXP9B\n5ftcqNlnjSGz/sCKDVWPewc1ar1b9d53r0XfOb9df85v15+CogIue/mimOUv6XAZZ7Y5m9Vbchny\n2hUx9cGHXPWDvXd79xFAUlw/52amNGL+N6/z9qqpMfWBh91OalIDZufOZE7urJj6kCPHkhRK5s2v\nnufDvH9Vqf1tcX1m9r0NiP/n3J3Re6e0OodBB14DVP2cW1nfrydDDh0KwJkv/IL/VZ2MZWf23u52\n3EtMDFU5tuwtGct3vfffx5adlbF855T9ejLy1IoMa2/JWP5b130m07Y+cf+cu7N674ULugM1e7/X\nJLUJz14Qu6874pnUkiRJ2iVaNsihWVpDotEo+ds2Uj85lYmn3cAZbY7Z7vj0OvVICiXywrK32FC8\nhdTEFNpm7kOztIaVY85pfyJjThxEUiiBtYUbIAr7pDWiVYNmFdvMaEbPVl3YVlbM2sINlIRLaZCc\nSqdGrWiT2Ryo+OCfmpTCppLCinUAjepmcM9Jg0mrU3cnPyuSJEmSAtHvvu+4myso2EokUrOpZmen\nMeH9t3bSjOJv8JHHU1T0WrynsdOkpHQnP3/LLtve3twv9krt2pt7BeyX2rY394u9Urv25l4B+0XV\nl52dZq+o2uyX2rU3vxb5OqSa8NhSuzy27Ll+TK8EgwGyslJrvC3PpJYkSZIkSZIkxY0htSRJkiRJ\nkiQpbgypJUmSJEmSJElxY0gtSZIkSZIkSYobQ2pJkiRJkiRJUtwYUkuSJEmSJEmS4saQWpIkSZIk\nSZIUN4bUkiRJkiRJkqS4MaSWJEmSJEmSJMWNIbUkSZIkSZIkKW6qFVJ/+eWX9O3blx49etC3b19W\nrlwZMyY/P5/BgwfTu3dvTjvtNKZOnVqlPmPGDHr37k2vXr3o3bs33377ba3sgCRJkiRJkiRpz5VQ\nnUEjRoygX79+9OnTh6lTpzJ8+HCefPLJKmPGjBlDx44dmTBhAuvXr+ess86ic+fO5OTk8PHHH/Pg\ngw/yxBNPkJ2dzZYtW0hKStopOyRJkiRJkiRJ2nPs8EzqgoIClixZQq9evQDo1asXS5YsYf369VXG\nLV26lOOOOw6AzMxM2rVrx8yZMwH405/+xIABA8jOzgYgLS2NOnXq1OqOSJIkSZIkSZL2PDs8kzov\nL4/GjRsTCoUACIVCNGrUiLy8PDIzMyvHdejQgRkzZtCpUydyc3NZsGABzZs3B+Dzzz+nefPm9O/f\nn23btnHKKacwePBgAoFAtSealZVa033TXiA7Oy3eU9Aewl5RTdgvqi57RTVhv6i67BXVhP2i6rJX\nVBP2i6prV/VKtS73UR3Dhg1j9OjR9OnTh6ZNm9K1a9fKYDscDrNs2TImT55MaWkpl19+OU2bNuXM\nM8+s9voLCrYSiURrNCf/we358vO37LJt2S97NntFNWG/qLrsFdXEruyXvdnP4d+CvVJ77Jfa9XN4\nPvdmHltqz8/h34LHFlVXTXslGAz8qJONdxhS5+TksHbtWsLhMKFQiHA4zLp168jJyakyLjMzk3vv\nvbfy/sCBA2ndujUATZs2pWfPniQlJZGUlET37t1ZtGhRjUJqSZIkSZIkSdLeZ4fXpM7KyqJ9+/ZM\nnz4dgOnTp9O+ffsql/oA2LBhA+Xl5QDMnj2b5cuXV7mO9TvvvEM0GqWsrIw5c+bQrl272t4XSZIk\nSZIkSdIeplqX+xg5ciTDhg1j/PjxpKenM3bsWKDibOmhQ4fSqVMnFi1axJ133kkwGCQjI4OJEyeS\nkpICwOmnn84nn3zCL37xC4LBIMceeyznnHPOztsrSZIkSRL1M1JISqi1qzxKkiTtFNV6t9KqVSum\nTJkS8/ikSZMqb3fr1o1u3bptd/lgMMjNN9/MzTff/COnKUmSJEmqqaSEBCa8/1a8p7HTDD7y+HhP\nQZIk1YIdXu5DkiRJkiRJkqSdxZBakiRJkiRJkhQ3htSSJEmSJEmSpLgxpJYkSZIkSZIkxY0htSRJ\nkiRJkiQpbgypJUmSJEmSJElxY0gtSZIkSZIkSYobQ2pJkiRJkiRJUtwYUkuSJEmSJEmS4saQWpIk\nSZIkSZIUN4bUkiRJkiRJkqTKYyhfAAAgAElEQVS4MaSWJEmSJEmSJMWNIbUkSZIkSZIkKW4MqSVJ\nkiRJkiRJcWNILUmSJEmSJEmKG0NqSZIkSZIkSVLcGFJLkiRJkiRJkuLGkFqSJEmSJEmSFDcJ8Z6A\nJEmSpJqpn5FCUoJv5SVJkrR38J2tJEmStIdJSkhgwvtvxXsaO8XgI4+P9xQkSZK0i3m5D0mSJEmS\nJElS3BhSS5IkSZIkSZLixpBakiRJkiRJkhQ3htSSJEmSJEmSpLgxpJYkSZIkSZIkxY0htSRJkiRJ\nkiQpbgypJUmSJEmSJElxY0gtSZIkSZIkSYobQ2pJkiRJkiRJUtwYUkuSJEmSJEmS4saQWpIkSZIk\nSZIUN4bUkiRJkiRJkqS4MaSWJEmSJEmSJMWNIbUkSZIkSZIkKW4MqSVJkiRJkiRJcWNILUmSJEmS\nJEmKG0NqSZIkSZIkSVLcGFJLkiRJkiRJkuLGkFqSJEmSJEmSFDeG1JIkSZIkSZKkuDGkliRJkiRJ\nkiTFjSG1JEmSJEmSJCluDKklSZIkSZIkSXFjSC1JkiRJkiRJihtDakmSJEmSJElS3FQrpP7yyy/p\n27cvPXr0oG/fvqxcuTJmTH5+PoMHD6Z3796cdtppTJ06NWbMF198wcEHH8zYsWN/8sQlSZIkSZIk\nSXu+aoXUI0aMoF+/frz88sv069eP4cOHx4wZM2YMHTt2ZNq0aTzzzDPcd9995OXlVdbD4TAjRozg\n5JNPrr3ZS5IkSZIkSZL2aDsMqQsKCliyZAm9evUCoFevXixZsoT169dXGbd06VKOO+44ADIzM2nX\nrh0zZ86srD/yyCOccMIJtGjRohanL0mSJEmSJEnak+0wpM7Ly6Nx48aEQiEAQqEQjRo1qnKWNECH\nDh2YMWMG0WiUr7/+mgULFvDNN98AFQH2O++8wyWXXFL7eyBJkiRJkiRJ2mMl1NaKhg0bxujRo+nT\npw9Nmzala9euhEIhysrKuO2227jrrrsqg+4fIysrtbamqj1IdnZavKegPYS9opqwX1Rd9opqwn5R\nddkrqgn7RdVlr6gm7BdV167qlR2G1Dk5Oaxdu5ZwOEwoFCIcDrNu3TpycnKqjMvMzOTee++tvD9w\n4EBat25Nfn4+q1at4oorrgBg8+bNRKNRtm7dyqhRo6o90YKCrUQi0WqPB//B7Q3y87fssm3ZL3s2\ne0U1Yb+ouuwV1YT9ouqyV1QT9ouqa1f2yt7u5/BvwWOLqqumvRIMBn7UycY7DKmzsrJo374906dP\np0+fPkyfPp327duTmZlZZdyGDRtIS0sjISGB2bNns3z5csaNG0dKSgpz586tHPfAAw+wbds2brrp\nphpPVpIkSZIkSZK0d6nW5T5GjhzJsGHDGD9+POnp6YwdOxaoOFt66NChdOrUiUWLFnHnnXcSDAbJ\nyMhg4sSJpKSk7NTJS5IkSZIkSZL2bNUKqVu1asWUKVNiHp80aVLl7W7dutGtW7cdruuqq66qwfQk\nSZIkSZIkSXuzYLwnIEmSJEmSJEn6+arWmdSSJEmSJEkSQP2MFJISjJQk1R6PKJIkSZIkSaq2pIQE\nJrz/VrynsdMMPvL4eE9B+tnxch+SJEmSJEmSpLgxpJYkSZIkSZIkxY0htSRJkiRJkiQpbgypJUmS\nJEmSJElxY0gtSZIkSZIkSYobQ2pJkiRJkiRJUtwYUkuSJEmSJEmS4saQWpIkSZIkSZIUN4bUkiRJ\nkiRJkqS4MaSWJEmSJEmSJMWNIbUkSZIkSZIkKW4MqSVJkiRJkiRJcWNILUmSJEmSJEmKG0NqSZIk\nSZIkSVLcGFJLkiRJkiRJkuLGkFqSJEmSJEmSFDeG1JIkSZIkSZKkuDGkliRJkiRJkiTFjSG1JEmS\nJEmSJCluDKklSZIkSZIkSXFjSC1JkiRJkiRJihtDakmSJEmSJElS3BhSS5IkSZIkSZLixpBakiRJ\nkiRJkhQ3htSSJEmSJEmSpLgxpJYkSZIkSZIkxY0htSRJkiRJkiQpbgypJUmSJEmSJElxY0gtSZIk\nSZIkSYobQ2pJkiRJkiRJUtwkxHsCkiRJkiRJkqoqLw+wZk0qJSUhIFBr6w0ElhCJRGptfTuybl2Q\nQxNSd9n2dqXFi5cQjWbEexo7zQ/1SjAYIiUlldTU+gQCP70/DaklSZIkSZKk3cyaNakkJmaSkVGv\nVkLA7wSDaZSX77qQOiEhyLrCrbtse7tSo3qpRCJb4j2Nneb7eiUajRIOl7Nly0Y2bMgnM7PRT9/W\nT16DJEmSJEmSpFpVUhIiNbV2A2qpNgQCARISEmnQIIvS0uJaWachtSRJkiRJkrTbCRhQa7cWCASB\naK2sy5BakiRJkiRJkhQ3htSSJEmSJEmS4m7tmjxmTX8x3tNQHBhSS5IkSZIkSYq7dWvW8MpL0763\nHg6X18p2IpEI0WjtXKZCtSMh3hOQJEmSJEmS9MPOeO6smMfObHMGAzpdwraybZw/7cKY+gXt+3JB\n+74UFBVw6cyBAAQCIb7LZy/pcBlntjl7h9suLi7mjjtGsHLlF4RCCey7736MGjWGDz+cz/33/57W\nrduwbNlSUlKSueWWkey/f0sAZs6czvPP/4OSslLq1qvH4Guup/k++wIw5c9P89br/yQQCJKcnMyY\n+x9i4rj7WLsmj6uvGEBO02YMGzmKy/udx3EnnsSiBR+y3/4tGXrjMJ79yzO88eorALRp244rrrqa\nlJS6FG7dyrh7x7Bq5UqyGjYkq2E29Rs0YMCgIfz5icdZtXIl2wq3kr9uHfc8MIG/P/MknyxaSHlZ\nGen16zP0xmE0atyEtWvyuG7wFZx6ei8+fH8epSUlXH/LbcyaNpVlny6hTp06/N+o0TSqlxrzXJ11\nVl969DiF+fM/4Ntvv2Xw4CvYsGEjr7zyKps3b+GWW27i0EMPBuC99+bwxBNPUVpaSkJCAldf/Rs6\nduxAQUEBI0b8jsLCbZSWlnL00UcxZMhgAB59dDKrVq2isLCQ1avzaNasKXfeeTvJyck7/P+4OzOk\nliRJkiRJkvS95s6dzbZthTz99BQANm/eXFn7/PPPuOaaG7jttt8xc+Z07rhjBI899hQLFy7g9df/\nycSJj7KxrJQP5s5h3D1juHvceF57eSbz3nuXseMmULduXTZv2kQwGGTQ0GuZ/PB4/jBhUpXtb9u2\njd+PfwSAD+bO4Y1XX+HuceNJqVuXP44dzd+eeoJLrhjMX5/6E6mpaUz409Ns2byZawdfztHHdatc\nz/KlS/jjxEdJr98AgHMu6M+AQUMAeOWl6TzxyERuvG0kAFs2b+LAjgdx8eW/5rm//YXbbriWO/9w\nP7+5/rdMuP8PvPTCc7S96trtPl9lZWVMmjSBJUs+5Te/uYYhQwbx2GMP89prr/Pww5OYOPFBcnNX\nM3nyE/zxj/dSr149vvjiS66//rc8//wUUlNTufvuu6hbty7l5eVcc80NzJkzl6OO6gLA0qXLeOyx\nh0lNTeWaa27g5Zf/SZ8+vWvh/3T8GFJLkiRJkiRJu7kXz3rue2t1E+v+YD0rJauyHgymUV4eqdG2\nW7duw8qVX/L734/l0EMP5+ijj62sNW++D4ceejgAPXr8grvvvpPCwq28++5brFjxGZdd9ivK/315\nja1btwDw/pzZnHZGH+rWrQtAev36P7j9E0/pUXn7ow/nc9yJJ1G3Xr2KbZ7em0kPjQPg448WcMVV\n1wCQlp7OUcccV2U9R3Q+qjKgBvhg3lxemvo8xUVFhMPhKmNTUlI48qiuALRqcwBZ2dm0bN2m8v7C\nD+Z/73y7dz8RgLZtD6C4uPi/7rclN3c1AHPnzmP16m+48sqhlcuFw2HWr19PSkoKDz00gY8/Xkw0\nGqWgYD3Ll6+oDKm7dOlMWloaAB06HMjq1d/84PO3JzCkliRJkiRJkvS9mjVrztNP/535899nzpx3\neeSRh3jiib/+4DLRKJx++hkMGnQl6wq3/qTtp6Sk/KTlv5P8X+tZt3YNj45/kN+Pf5gmOU35dPHH\n/P7OUZX1hMSkytvBYJCkpP/cDwVDMaH2f/tubCgU+p/7wSrLHXVUZ4YP/7+Y5SdPfoLNm7cyadIE\n6tSpw5gx91BaWhqz/u/m9kNz2VP4w4mSJEmSJEmSvte6dWsJBkMcf/wJDB16PRs3bmDLlopLfqxe\nncvChQsA+Oc/Z9GyZWvq1UvlmGOOY9asl1i3bi1QcZbwiuXLADjyqK7MfHEq27ZtA2Dzpk0A1K1b\nl8IdBNqHHHYE7/zrdbZt20Y0GuWVGdM55PAjAOh08KG88cosALZu3cLc99753vVsKywkMTGBjMws\nIpEIs6a9+GOfnh+lc+cjmTNnHl988WXlY0uWfArAli1badgwizp16pCfn8/bb7+7S+cWD55JLUmS\nJEmSJOl7ff75CiZOfBCASCTMhRdeQsOG2axa9RUtW7Zm2rQXuPfeu0hOTubWW28H4JBDDuOKK67k\nhhuupbS8jPLyMo45/kRaH9CWk07tScG333LjbwaRkJBAckoKd933AC1ataJZ8335zWUX03yffRk2\nclTMXA7vchQrv/ic315V8UOCrQ9oy3kX/gqAvr+6mHF3j2HwJReSmZlF6wPaUXc7P24I0KJlK445\n/gSGDLiI9PoNOKLzUSxetHBnPH3btc8+zRkx4lbuuutuSkpKKCsr46CDOnHgge0599yzufXWEfTv\nfwmNGmVzxBGH7bJ5xUu1Quovv/ySYcOGsXHjRho0aMDYsWNp0aJFlTH5+fkMHz6c3NxcysvLGTRo\nEH369AHgoYceYsaMGQSDQRITE7n22ms57rjjtrMlSZIkSZIkSbuTrl2PoWvXY7ZbS0hIqAym/9ep\np57GL35xeszlPgKBAOf1v4jz+l/0P0sEGT56bJVHHv3z32PWe/YF/Tn7gv4xjycnp3DDrcNJSqrD\ntsJCbrp6CD1Or/hBwX4XD4gZP/A3VzPwN1dX3u93ScWYxk1yeOb5aZWPdzrk0Co/5ti952l073na\ndvf5uef+VuX+e++9WXk7JyeHmTP/c8Z2ly5H0qXLkTHryMlpwmOPPbzd9V9++aU/eH9PVa2QesSI\nEfTr148+ffowdepUhg8fzpNPPlllzJgxY+jYsSMTJkxg/fr1nHXWWXTu3JmcnBwOOuggBgwYQEpK\nCkuXLuXCCy/knXfeITk5eafslCRJkiRJkqSfl61btnD7zTcSiUQoLS2l20knV14KRLu3HYbUBQUF\nLFmyhMmTJwPQq1cvRo0axfr168nMzKwct3TpUi6++GIAMjMzadeuHTNnzmTAgAFVzppu27Yt0WiU\njRs30qRJk9reH0mSJEmSJEm7wGGHHcFjjz0V72lUapCRwX0TH433NPQj7DCkzsvLo3HjxpW/RhkK\nhWjUqBF5eXlVQuoOHTowY8YMOnXqRG5uLgsWLKB58+Yx63vhhRfYd999axxQZ2Vt//ox2rtlZ6fF\newraQ9grqgn7RdVlr6gm7BdVl72imrBfVF32imoiISEY7yloD7GjXgkGg7Vy/Km1H04cNmwYo0eP\npk+fPjRt2pSuXbtWBtvfmTdvHvfffz+PP/54jddfULCVSCRao2U8QO/58vO37LJt2S97NntFNWG/\nqLrsFdWE/aLqsldUE/aLqsteUU2Ul0d22bYMxPdsO+qVSCRS5fgTDAZ+1MnGOwypc3JyWLt2LeFw\nmFAoRDgcZt26deTk5FQZl5mZyb333lt5f+DAgbRu3bry/oIFC7jxxhsZP348LVu2rPFEJUmSJEmS\nJEl7nx3+KSMrK4v27dszffp0AKZPn0779u2rXOoDYMOGDZSXlwMwe/Zsli9fTq9evQBYtGgR1157\nLePGjaNDhw61vQ+SJEmSJEmSpD1UtS73MXLkSIYNG8b48eNJT09n7NixQMXZ0kOHDqVTp04sWrSI\nO++8k2AwSEZGBhMnTiQlJQWA22+/neLiYoYPH165zrvvvpu2bdvuhF2SJEmSJEmStLt5bdZM3p/z\nHsNGjorbHD7+aAHl5WUcekTnuM1BsaoVUrdq1YopU6bEPD5p0qTK2926daNbt27bXf7ZZ5/9kdOT\nJEmSJEmSpNrx8cIFFBcVfW9IHQ6XEwr99J/xKy8vJyGh1n4OcK/nMyVJkiRJkiTpBx177BEMHDiY\nt99+k02bNnHTTf/H/PnzmDv3PcrLyxk1aiwtWuwPwMyZ03nuuSmEw2HS0lK57KpraL7Pvj+4/tyv\nV3H/2LsoKSkmEonQvUdPfnneBfz5icf5+quv2LxpI+sLCti3RQuG3jCMeqmplJWV8fTjk/hk4UeU\nlZXRomUrBl9zHSkpdSncupVHJzzIimWfEggEObDTQfTsdQazpr1INBph4YcfcNyJJ3Hcid25bvAV\ndO/Rk0ULPqRHrzM44eRTeOSB+/ls2VIATjylB2ef3w+AVStXMu6euyguLqZ923bk5n7FJZdcxDHH\nHM2QIVfTpk1rFi9eQnp6GmPHjuaGG4axefNmSkpKaN++HTfddAOJiYm89NJMXnnlVdLSUlmx4guy\nsxty3XVX8+CD48nNXU379u0YMeJWAoFAlecpLy+PAQN+zRln9GLOnLmUlJQycuStPP/8VJYs+ZQ6\ndeowduydZGVlAfDUU3/mX/96k3A4THZ2Q4YNu5GsrCzmz/+Ahx9+lNLSUsLhMBdffBGnnNIdgCFD\nrqZ9+3Z88slS8vPzOemkkxk8+Kpa7af/ZUgtSZIkSZIk7ebS550V81hJkzMo2fcSCG8j/YMLY+vN\n+lLSrC+B0gLSPhpY8WAgRDRacbO4+WWUNDm72nNITU3j0Uef5PXXX+Xmm69n5MjRDBr0G5555gme\nfPJxhg8fxcKFC3j99X/y0EOTSEpKYt682Yy7Zwx3jxv/g+ueOfV5Oh99DOf2q9iPrVu2VNaWfLyQ\nPz78OBmZmdx/zxj+9vQTDBg0hOf+9mfq1qvH78c/AsCfHpnAP/78DBddNpBHxz9AckoK9z8ymWAw\nyOZNG0mv34Cevc+guKiIAYOGALB2TR5bNm+iTdt2lY/96ZEJRCIRHnj0TxRt28aNVw2mxf4tObzL\nUdw35g7OOPs8TjzlVApWreKyy35VZT+++eYbJkx4gISEBKLRKLfffhv169cnGo0yatRopk+fwS9/\n2QeApUuX8tRTk2nUqBE33DCMkSNH8eCDfyQlJYVLLx3I/PkfcOSRR8Q8V5s2beKggzoxePAVPPPM\nXxg69DoefPCP3Hzzb7nnnj/wj388z69/fTmzZr3C6tWrmTRpAsFgkOeee4EHHhjPyJG3ccABBzBx\n4oOEQiHWr1/PpZdeQZcunUlPT6t4XtauZeLER9m8eSt9+/ahV68+7LODPzT8FIbUkiRJkiRJknao\ne/dTAWjbth0Q4Jhjjvv3/fa8+eYbALz77lusWPEZV1xxyb+XirJx86YdrrvDQQfzp0cmUlJSTKdD\nDuWgQw6rrB151NFkZGYCcMppp/PIA38EYN5777Jt2zbee+tNAMrKStm/ZWsA3p/zHvdNeJRgMAhA\nev0G37vtpKQkjj3hpMr7Cz/8gIFDhhIIBKhbrx7Hn9Sdjz6cT/uOnfhq5Zd0634yAO3bH0irVi2r\nrOuUU06uvMxHJBLhz3/+G3PmzCUcDrNly1aSk5Mrx3bq1IlGjRoBcMABbcjJaUJaWkVI3Lp1K3Jz\nV283pK5bN4VjjukKQNu2B5Cdnc0BB7QBoF27tsybNx+Ad955l6VLl3HppRV/oCgvD5OaWg+AjRs3\nMnr0GL7+ejUJCSE2b97MqlWr6NixAwAnnngCwWCQ1NRU9ttvf1avzjWk1v+3d+/xOdf/H8ef17Xz\nKUxkIodofHPYbApzyGG2tRAdrINDQuZckSU5poi+iphjEvIt/WKxaMSXpRwW0cHKoZWRzXGzjdl1\n+P2hrr7LORefy3rcbze32/U5vT/Pz+d639x2e+299xsAAAAAAAD/ZLn3fHzxg26+lzxu9yzrOG42\nB8hisf2tDJ6enr+3YZanp4djv9lsltVqPXcvuxQb2149e/aRJLm7m5Wdn3deWzPf+rd2f/+dJGno\ny6PVpPl9Cv5XHX2Ttk3/t2Sx1q76VM8Pf/mSeeyS+gx6VvVDw/7W8/zBy9vnvGk1LuVS5/r6+jg+\np6Ss1a5duzRjxjT5+flqwYKFOnAg03H8j/cp/fFO/9x2c3NzvNO/8vAofp2XV/HtP78Lu7p376IH\nHog9r41Jk/6tpk0j9Nprr8hkMqlz5yd09uxZx/GLtXm9mK9r6wAAAAAAAAD+MSIimmn16mRlZ2dJ\nkqxWq/b+9ON55/UZ9Jzemv2O3pr9jipVvkOHDmaqTGCgWkfHKK7rU9qTvttxbtqWr5Rz8qQk6fPV\nn6pe6LlR1vc0jlDS0g9VWFgoSSooKNCBXzIknRt9/fGHS2T/fW6T3Jxz1/v6+qkgP/+Sz1C/QZjW\nrEqW3W5XQUGBUtevU0hYQ/n6+emOKlW1cd1aSVJ6+m7t3//zRdvJy8tTqVKl5Ofnq7y8PKWkfH7Z\n9+dMTZtG6OOPk5Sbe27qlLNnz2rPnr2ObEFBFWQymbR16zZlZh68odn+ipHUAAAAAAAAAJwiJKSB\nevfuq4SE52S12mSxFKlRsxaqcVfwJa/74r/rteHzNXL38JBJUq9+Ax3H/lW3nia9MlrHjh5V5SpV\nHHNHP/zYE1qyYL6e79tbJpNJJpNJcV27q3KVqnq6b3/NnT5N/Z/uJjc3N9WpH6Le/QepUdNmem3U\nZxrUu4dj4cS/6tylm2ZNfVMDenaXJLVs01Zh99wrSXo24SVNnTRBHy1ZpOCawapevZr8/Pwu+Ewx\nMVFKTd2kuLguKlOmtEJC6qqw8OwFz70eYmKilJOTo36/v0ubza5OnTqoZs0aio/vrcmTp2jevPmq\nVStYNWrcecNyXYjJ/sevE1zcsWN5stmuLmq5cgFK3LbxOiUyXnzD5jp9+sb+BuZG8vFprSNHTl3+\nRCcpyf2FvuJcJbmvSPQXZyvJ/YW+4lwlua9I9BdnK8n9hb7iXCW5r0j0F2cryf2FvuJcJbmvSK7T\nX/btK6OgoIpOb/dapvv4Oy423ceVen/BO8UWOjTa6dMF8v59epD87GzFx/fUf/6zyLHgYElyJX3l\n8OFfVKFClf+5xqSyZf2v+l6MpAYAAAAAAACAK5D+/XeaPytRdrtd7mazEhKGlsgC9Y1GkRoAAAAA\nAACAS3q8Ww+jIxQTGn6PQsPvkSSV9/OXzXbj/oqhJGPhRAAAAAAAAACAYShSAwAAAAAAAAAMQ5Ea\nAAAAAAAAAGAYitQAAAAAAAAAAMOwcCIAAAAAAADg4gJKlZWnu4fT2z1rsSjnxGmntwtcDYrUAAAA\nAAAAgIvzdPdQ4raNTm83vmFzp7f5d2Ud/k070rYp+oH2RkfBDcZ0HwAAAAAAAAAMl334sFKSV1z0\nuNVqccp9bDab7Ha7U9qCczCSGgAAAAAAAMAlnTlzRq+8MkoZGfvl5uauO+6ooo4dH9Zbb72hGjVq\n6scf0+Xj463hw0erWrXqkqRVq1Zq2bKPVFh0Vr5+foof/LwqVb5DkrT0/UXauG6NTCazvL29NeGt\n6Zo5dYqyDv+mQb17KKji7UoYPU49H39UzVq20q4d21WlWnUNHJqg/1uyWOvXpkiSagbXUu8Bg+Tj\n46v8vDxNnTxBv2ZkqOytt6rsreVUqnRp9ejTT+8veEe/ZmSoID9PR7KzNWlaoj5c/J6+27VTlqIi\n3VKqlAYOTVD52yoo6/Bvei6+t9rGPqDt27bqbGGhnh/+slavSNKPu3+Ql5eXXhr3qsr7+Rv2fZQ0\nFKkBAAAAAAAAXNKWLV+poCBfixYtlSTl5uZq796ftG/fHg0ePEQvvzxWq1at1CuvjNK8eQu1c+cO\nrVu3RjNnztXJorP6estmTZ00Qa9PnaHPP1ulrV9u0sSpifL19VVuTo7MZrP6DHxW82fN0L8T5xS7\nd0FBgd6YMVuS9PWWzVq/NkWvT50hH19fvTnxVX2wcIG6947Xfxa+K3//ACW+u0incnP1bHxPNWnW\nwtHOT+k/6M2Zc3VLqdKSpIcfe0I9+vSTJKUkr9SC2TM19OXRkqRTuTn6V5166tbzGX38wRK9PORZ\njf/3W+r//AtKfOvfSl7+sYIHPHu9X/s/BkVqAAAAAAAAAJdUo0ZNZWT8rDfemKjQ0DA1adJUklSp\nUmWFhoZJkqKi7tfrr49Xfn6eNm3aqL179+jpp7vK8vv0Gnl5pyRJ2zZ/pZj2HeTr6ytJuqVUqUve\nu2VklOPzN9vT1KxlK/n6+Z27Z2w7zZk+VZL07Tc71HvAYElSwC23qFFEs2LthN/TyFGglqSvt25R\nctIynTl9Wlartdi5Pj4+atiosSTpzpp3qWy5cqpeo6Zje+fXaVf66nAFKFIDAAAAAAAAuKTbb6+k\nRYs+VFraNm3evEmzZ0/X4MFDL3q+3S7FxrZXnz59lZ2fd0339vHxuabr/+D9P+1kZx3W3Blv640Z\ns1QhqKJ2f/+t3hg/znHc3cPT8dlsNsvT889tN7PbeUVtXBsWTgQAAAAAAABwSdnZWTKb3dS8+X0a\nOPB5nTx5Qrm5uTp4MFM7d+6QJK1Zs1rVq9eQn5+/IiKaafXqZGVnZ0mSrFar9v70oySpYaPGWvVJ\nkgoKCiRJuTk5kiRfX1/lX6agHdIgXF/8d50KCgpkt9uV8ulKhYSFS5Lq1g/V+pTVkqS8vFPa8uUX\nF22nID9fHh7uKhNYVjabTatXfHINbwfXipHUAAAAAAAAgIs7aylSfMPm16FdyxWdt2/fXs2c+bYk\nyWaz6sknu+vWW29V9eo1tGLFck2e/Jq8vb01YsQYSVJISAP17t1XQ4Y8q7OWIlksRYpo3lI17gpW\nq7bROnb0qIb27yN3d3d5+/jotSnTVPXOO3V7pTvU/+luqlT5DiWMHndejrB7Gylj/z69MCBeklTj\nrmA9+mRXSVLnrt009Y437AgAABkwSURBVPUJiu/+pAIDy6rGXbXke5HFDatWv1MRze9Tvx5ddEup\n0gq/p5G+37Xzqt8fnIMiNQAAAAAAAODiTuUcc0o7ZnOALBbbVV/XuHGEGjeOKLZv+/Y0ubu7OwrT\nf9W2bYzuvz/2vOk+TCaTHn2iix59ostf02nkqxOL7Zn7/ofntfvQY0/ooceeOG+/t7ePhowYKU9P\nLxXk52vYoH6Kim0nSXq8W4/zzu/Vf5B69R/k2H68+7lzbqsQpMXLVjj21w0JLbaYY+voGLWOjrng\nM+PvoUgNAAAAAAAA4KaXd+qUxrw4VDabTWfPnlWLVm0cU4HAtVGkBgAAAAAAAHDVGjQI17x5C42O\n4VC6TBlNmTnX6Bj4G1g4EQAAAAAAAABgGIrUAAAAAAAAAADDUKQGAAAAAAAAABiGIjUAAAAAAAAA\nwDAsnAgAAAAAAAC4uNKly8rNzcPp7VqtFh0/ftrp7V7I56tXadvmL5UwetwNuZ8kffvNDlksRQoN\nv+eG3RNXjyI1AAAAAAAA4OLc3Dx0+vTnTm/Xx6e109t0Jd/u3KEzp09ftEhttVrk5nbtJVKLxSJ3\nd0qtfxdvDgAAAAAAAMAlNW0arl694pWaukE5OTkaNuwlpaVt1ZYtX8pisWjcuImqWrWaJGnVqpX6\n+OOlslqtCgjw19MDBqtS5TuKtZd54Fe9NfE1FRaekc1mU+uoaHV89DG9v+AdHfjlF+XmnNTxY8d0\nR9WqGjgkQX7+/ioqKtKid+bou53fqKioSFWr36n4wc/Jx8dX+Xl5mpv4tvb+uFsmk1n/qltP0Q+0\n1+oVn8hut2nn9q/VrGUrNWvZWs/F91brqGjt2rFdUQ+0131tIjV72lva82O6JKllZJQeintckvRr\nRoamTnpNZ86cUbU7a+i3QwfV+Ymuati4ieLje6lmzWr6/vsfdMstAZo48VUNGZKg3NxcFRYWqnbt\nWho2bIg8PDyUnLxKKSlrFRDgr71796tcuVv13HOD9PbbM5SZeVC1a9fSqFEjZDKZbuwX6yIoUgMA\nAAAAAAC4LH//AM2d+57WrVurF198XqNHv6o+ffpr8eIFeu+9dzRy5Djt3LlD69at0fTpc+Tp6amt\nW7/S1EkT9PrUGcXaWpW0TPc0idAjjz8pSco7dcpx7Idvd+rNWe+oTGCg3po0QR8sWqAeffrp4w/e\nl6+fn96YMVuS9O7sRH30/mJ1ebqX5s6YJm8fH701e77MZrNyc07qllKlFd2uvc6cPq0effpJkrIO\n/6ZTuTmqGVzLse/d2Ymy2WyaNvddnS4o0NAB8aparbrC7m2kKRNeUfuHHlXLyLba82O6hvbvU+w5\nDh06pMTEaXJ3d5fdbteYMS+rVKlSstvtGjfuVa1c+ak6duwgSUpPT9fChfNVvnx5DRmSoNGjx+nt\nt9+Uj4+Pnnqql9LSvlbDhuHX58tzcRSpAQAAAAAAAFxW69ZtJUnBwbUkmRQR0ez37drasGG9JGnT\npo3au3ePevfu/vtVdp3MzTmvrbvr1de7s2eqsPCM6oaEql5IA8exho2aqExgoCQpMiZWs6e9KUna\n+uUmFRQU6MuNGyRJRUVnVa16DUnSts1fakriXJnNZknSLaVKX/Q5PD091fS+Vo7tndu/Vq9+A2Uy\nmeTr56fmrVrrm+1pql2nrn7J+FktWreRJNUMrqUq1e8s1lZkZBvHNB82m03vv/+BNm/eIqvVqlOn\n8uTt7e04t27duipfvrwk6a67aiooqIICAgIkSTVq3KnMzIMUqQEAAAAAAADgYjw9PSVJZrNZnp5/\nLuJoNptltVolSXa7FBvbXj17nhtx7O5uVnZ+3nltNWl+n4L/VUffpG3T/y1ZrLWrPtXzw1++5P3t\nkvoMelb1Q8Ou6Tm8vH2ualqNS53r6+vj+JySsla7du3SjBnT5OfnqwULFurAgUzH8T/en/THO/xz\n283NzfEO/4nMRgcAAAAAAAAAUDJERDTT6tXJys7OkiRZrVbt/enH8847dDBTZQID1To6RnFdn9Ke\n9N2OY2lbvlLOyZOSpM9Xf6p6oedGWd/TOEJJSz9UYWGhJKmgoEAHfsmQdG709ccfLpHdbpck5eac\nu97X108F+fmXzFy/QZjWrEqW3W5XQUGBUtevU0hYQ/n6+emOKlW1cd1aSdK+n37UL/v3X7SdvLw8\nlSpVSn5+vsrLy1NKivMXuiypGEkNAAAAAAAAuDirtUg+Pq2vQ7sWp7YXEtJAvXv3VULCc7JabbJY\nitSoWQvVuCu42Hlf/He9Nny+Ru4eHjJJ6tVvoOPYv+rW06RXRuvY0aOqXKWKY+7ohx97QksWzNfz\nfXvLZDLJZDIprmt3Va5SVU/37a+506ep/9Pd5Obmpjr1Q9S7/yA1atpMr436TIN693AsnPhXnbt0\n06ypb2pAz+6SpJZt2irsnnslSc8mvKSpkybooyWLVKXanapSvbp8/fwu+OwxMVFKTd2kuLguKlOm\ntEJC6qqw8Oy1v9R/AIrUAAAAAAAAgIs7efKYU9oxmwNksdiu+rovvkhzfA4Kqqjk5D9HCTdoEK55\n8xY6ttu2jVHbtjGSik/30To6Rq2jz+1/9IkuevSJLhe8163lyuuFl8ect9/d3V1dnu6lLk/3Ou+Y\nv3+ABg8bft7+CkEV9dbsd4rtW7xsRbFtHx/fC14rSeUrVNDk6bNkMpn0a0aGXnp+oKpUqy5JSkyc\nI5vtzwUf/f39NXXqvy/YTmxsjGJjYxzbPXs+Vez4iBEvXvC6fwqK1AAAAAAAAABwAenff6f5sxId\n04j0e26o/H9f7BDOQ5EaAAAAAAAAgEt4vFsPoyMUExp+j0LD7zE6RonHwokAAAAAAAAAAMNQpAYA\nAAAAAABcjt0xxQTgiux2mySTU9qiSA0AAAAAAAC4GC8vq/Ly8ilUw+XY7XZZLEU6efKoPD29ndIm\nc1IDAAAAAAAALqZChTwdPiwdPpwjZ41WlSSTyVs2m81p7V2O2WzWqbNnbtj9biRLjrfs9pL5bNKl\n+4rZ7CYfH3/5+5dyyr0oUgMAAAAAAAAuxt3drkqVTjm9XR+f1jpyxPntXky5cgFK3Lbxht3vRooP\nbaDTpz83OsZ1cyP7yhVN9/Hzzz+rc+fOioqKUufOnZWRkXHeOUeOHFF8fLzatWunmJgYJSUlOY5Z\nrVaNGTNGbdq0UWRkpJYuXeq0BwAAAAAAAAAA3LyuqEg9atQoPf744/rss8/0+OOPa+TIkeedM2HC\nBNWpU0crVqzQ4sWLNWXKFP3222+SpBUrVujXX39VSkqKPvjgA02bNk2ZmZnOfRIAAAAAAAAAwE3n\nstN9HDt2TD/88IPmz58vSXrggQc0btw4HT9+XIGBgY7z0tPT1a1bN0lSYGCgatWqpVWrVqlHjx76\n9NNP9cgjj8hsNiswMFBt2rTR6tWr1bNnzysOajb/vbl3Ajy9/tZ1NwuTyTmTk7uqv/u9/10lub/Q\nV5yrJPcVif7ibCW5v9BXnKsk9xWJ/uJsJbm/0FecqyT3FYn+4mwlub/QV5yrJPcVif7ibCW5v9BX\nru38P5jsl1ki9LvvvtOwYcOUnJzs2Hf//fdr0qRJuvvuux37XnjhBQUGBmrYsGHKzMzUww8/rHbt\n2mnEiBFq166dxo8fr3r16kmS5syZo6ysLI0YMeJvhQYAAAAAAAAAlAxXNN3HlUhISNDRo0fVoUMH\njR8/Xo0bN5abm5uzmgcAAAAAAAAAlECXne4jKChIWVlZslqtcnNzk9VqVXZ2toKCgoqdFxgYqMmT\nJzu2e/XqpRo1ajjaOHTokGMk9W+//aaKFSs68zkAAAAAAAAAADehy46kLlu2rGrXrq2VK1dKklau\nXKnatWsXm49akk6cOCGLxSJJ+uqrr/TTTz/pgQcekCRFR0dr6dKlstlsOn78uNauXauoqChnPwsA\nAAAAAAAA4CZz2TmpJWnfvn1KSEhQbm6ubrnlFk2cOFHVq1dXr169NHDgQNWtW1cbNmzQ+PHjZTab\nVaZMGY0cOVK1a9eWJFmtVo0dO1abNm2SdG6UdefOna/vkwEAAAAAAAAAXN4VFakBAAAAAAAAALge\nnLZwIgAAAAAAAAAAV4siNQAAAAAAAADAMBSpAQAAAAAAAACGoUgNAAAAAAAAADAMRWoAAAAAAAAA\ngGEoUt+ETp48qX79+ikkJEQtW7bUihUrjI4EF7Vo0SJ16tRJderUUUJCgtFx4MLOnj2r4cOHq2XL\nlgoNDVWHDh20YcMGo2PBRQ0ZMkRNmzZVgwYNFBUVpaVLlxodCTeBjIwM1a1bV0OGDDE6ClxUly5d\nVLduXYWGhio0NFRRUVFGR4KLS05OVkxMjEJCQtSmTRulpaUZHQku6I//U/74V7t2bY0bN87oWHBR\nmZmZ6tWrlxo2bKiIiAiNHTtWFovF6FhwQfv27VPXrl0VFhamyMhIrVmzxuhINz13owPg6o0dO1Ye\nHh7atGmTdu/erWeeeUa1atVSzZo1jY4GF1O+fHn17dtXqampKiwsNDoOXJjFYlFQUJAWLlyoihUr\nasOGDRo8eLBWrFihSpUqGR0PLuaZZ57Rq6++Kk9PT8cPZ7Vr11adOnWMjgYXNnbsWNWtW9foGHBx\nI0eO1COPPGJ0DNwENm3apMmTJ2vKlCmqV6+ejhw5YnQkuKgdO3Y4Pufn56tp06aKjo42MBFc2Zgx\nY1S2bFl98cUXys3NVY8ePfT++++ra9euRkeDC7FYLOrbt6/i4uI0f/58bd26VfHx8Vq2bJmqVatm\ndLybFiOpbzIFBQVKSUnRoEGD5Ofnp/DwcLVq1UpJSUlGR4MLatu2rdq0aaPSpUsbHQUuztfXVwMG\nDFClSpVkNpvVsmVLVapUSd9//73R0eCCatasKU9PT0mSyWSSyWTSr7/+anAquLLk5GQFBASocePG\nRkcBUEJMmzZNffv2VUhIiMxms2677TbddtttRseCi0tJSVFgYKDCw8ONjgIXlZmZqZiYGHl5ealc\nuXJq2rSp9u7da3QsuJj9+/crOztb3bt3l5ubmxo3bqwGDRpQm7tGFKlvMhkZGXJzcyv2m5latWrx\nnyYApzp69KgyMjJUo0YNo6PARY0ePVr169dXTEyMypUrpxYtWhgdCS4qLy9PU6dO1Ysvvmh0FNwE\n3njjDd17772Ki4vTli1bjI4DF2W1WvXdd9/pxIkTioyMVPPmzTV27FidOXPG6GhwccuWLdODDz4o\nk8lkdBS4qG7duik5OVmnT59WVlaWUlNT1axZM6Nj4SZgt9u1Z88eo2Pc1ChS32QKCgrk7+9fbF9A\nQIDy8/MNSgSgpCkqKtKQIUPUsWNH3XnnnUbHgYsaPXq0tm/frsWLFysyMtIxshr4qzfffFMPPfSQ\nKlSoYHQUuLghQ4Zo7dq1Sk1NVefOndWnTx/+SgMXdPToURUVFWn16tVavHixli9frh9++EGJiYlG\nR4MLO3jwoLZt26YHH3zQ6ChwYQ0bNtTevXsVFham5s2bq06dOmrTpo3RseBiqlWrpsDAQM2dO1dF\nRUX64osvtG3bNn5Zeo0oUt9kfH19lZeXV2xfXl6e/Pz8DEoEoCSx2Wx64YUX5OHhoZdfftnoOHBx\nbm5uCg8P1+HDh7VkyRKj48AF7d69W1999ZW6d+9udBTcBOrXry9/f395enqqY8eOatCgAYv44oK8\nvb0lnVtss3z58goMDNRTTz1Ff8ElJSUlKSwsTJUrVzY6ClyUzWZTz549FRkZqW+++UabN29WTk6O\nJk2aZHQ0uBgPDw9Nnz5dGzZsUNOmTTV//nxFR0cz7dQ1okh9k6lataqsVqsyMjIc+9LT0/mTfADX\nzG6366WXXtLRo0c1bdo0eXh4GB0JNwmr1cpoR1zQli1bdPDgQbVs2VIRERF65513lJKSoo4dOxod\nDTcBk8kku91udAy4oFKlSqlChQrFpmxg+gZcTlJSEqOocUknT57UoUOH9OSTT8rT01NlypTRQw89\npI0bNxodDS6oVq1aWrRokbZs2aJ58+YpMzNT9erVMzrWTY0i9U3G19dXkZGRmjp1qgoKCvT111/r\n888/V4cOHYyOBhdksVhUWFgom80mq9WqwsJCWSwWo2PBRY0aNUr79u3TzJkzHSOUgL86duyYkpOT\nlZ+fL6vVqtTUVCUnJ7MgHi6oc+fOWrNmjZYvX67ly5crLi5O9913n+bNm2d0NLiY3NxcpaamOn5W\n+eSTT5SWlsY8oLioTp06aeHChTp27JhycnL07rvv6r777jM6FlzU9u3blZWVpejoaKOjwIUFBgaq\nUqVKWrJkiSwWi3Jzc7Vs2TIFBwcbHQ0uKD09XYWFhTp9+rTmzZun7OxsderUyehYNzV3owPg6o0a\nNUrDhw9XkyZNVLp0aY0ePVo1a9Y0OhZcUGJiot5++23H9ieffKL+/ftrwIABBqaCKzp48KA++OAD\neXp6qmnTpo79Y8aMUfv27Q1MBldjMpm0ZMkSjRo1SjabTbfffruGDx+u1q1bGx0NLsjHx0c+Pj6O\nbV9fX3l6eiowMNDAVHBFFotFb775pvbv3y83NzdVr15d06dPL7ZYOPC/+vbtqxMnTigqKkpeXl6K\niYlRfHy80bHgopYvX67IyMjz1ncC/urtt9/Wq6++qjlz5shsNqtRo0Ys/owLSkpK0kcffSSLxaKw\nsDDNnz+fdXqukcnO39ABAAAAAAAAAAzCdB8AAAAAAAAAAMNQpAYAAAAAAAAAGIYiNQAAAAAAAADA\nMBSpAQAAAAAAAACGoUgNAAAAAAAAADAMRWoAAAAAAAAAgGEoUgMAAAAAAAAADEORGgAAACVabGys\ntmzZYnSMS8rMzFRwcLAsFstVXxsaGqoDBw5ch1QAAADAjUGRGgAAACVacnKy7r333sue16pVK335\n5Zc3INHf16VLFy1durTYvh07dqhy5coGJQIAAACuHUVqAAAA4BrZ7XbZbDajYwAAAAA3JYrUAAAA\nKNH+GCE9bdo0DRo0SC+88IJCQ0MVGxurb7/9VpI0dOhQHTp0SH369FFoaKjmzJkjSfrmm28UFxen\n8PBwtW/fvti0IV26dNGUKVMUFxen+vXra+7cuerUqVOxe7/77rvq06ePJOm///2vHnzwQTVo0EAt\nWrTQtGnTruo5pkyZorS0NI0dO1ahoaEaO3asJCk4OFi//PKLJCkhIUGjR49Wz549FRoaqri4OB05\nckTjx49Xw4YNFR0drR9++MHRZlZWlgYMGKBGjRqpVatWeu+9967y7QIAAADXjiI1AAAA/jHWrVun\n2NhYpaWlqVWrVho3bpwkadKkSapYsaJmzpypHTt2qFevXsrKytIzzzyj+Ph4bd26VcOGDdPAgQN1\n/PhxR3tJSUkaN26ctm/frscee0w///yzMjIyHMdXrFihdu3aSZJ8fHw0ceJEpaWladasWVqyZInW\nrl17xdmfffZZhYeHa+TIkdqxY4dGjhx5wfNWrVqlwYMHa/PmzfL09FTnzp119913a/PmzYqKitJr\nr70mSbLZbIqPj1dwcLA2btyoBQsWaMGCBUpNTb3a1woAAABcE4rUAAAA+McICwtTixYt5Obmpg4d\nOig9Pf2i5yYlJal58+Zq0aKFzGazIiIiVKdOHW3YsMFxTseOHVWzZk25u7srICBArVu31sqVKyVJ\nGRkZ2r9/v1q1aiVJuvfeexUcHCyz2axatWopNjZWW7dudfozRkZGqk6dOvLy8lJkZKS8vLz04IMP\nys3NTffff792794tSfr22291/Phx9e/fX56enqpcubIeffRRffrpp07PBAAAAFyKu9EBAAAAgBvl\n1ltvdXz29vZWYWGhLBaL3N3P/7H40KFDWr16tdavX+/YZ7FYii3CGBQUVOyadu3aacKECerfv79W\nrlypNm3ayMfHR5K0c+dOTZ48WXv27FFRUZHOnj2r6OhoZz+iypYt6/js7e193jMXFBRIkg4ePKjs\n7GyFh4c7jlut1mLbAAAAwI1AkRoAAAC4gKCgIHXo0EGvvPLKRc8xmUzFtps0aaLjx49r9+7dWrly\npV588UXHseeff15PPvmk5s6dKy8vL40fP14nTpy4bvkvJygoSJUqVVJKSophGQAAAACJ6T4AAAAA\nSedGWR84cMCx3b59e61fv16pqamyWq0qLCzUli1bdPjw4Yu24eHhoejoaL3++uvKyclRRESE41h+\nfr5KlSolLy8v7dq1yzEtyLVkvBb16tWTn5+fZs+erTNnzshqteqnn37Srl27nNI+AAAAcKUoUgMA\nAACSevfurcTERIWHh2vevHkKCgrSjBkzNGvWLDVu3FgtWrTQvHnzZLPZLtlOu3bt9OWXXyo6OrrY\nNCKjRo3S1KlTFRoaqunTpysmJuaqM3bt2lWfffaZGjZseMkR3lfCzc1NM2fOVHp6ulq3bq1GjRpp\nxIgRysvLu6Z2AQAAgKtlstvtdqNDAAAAAAAAAAD+mRhJDQAAAAAAAAAwDAsnAgAAAC4kNDT0gvvn\nzJmj8PDwG5wGAAAAuP6Y7gMAAAAAAAAAYBim+wAAAAAAAAAAGIYiNQAAAAAAAADAMBSpAQAAAAAA\nAACGoUgNAAAAAAAAADAMRWoAAAAAAAAAgGH+H3DjGhiqhmPDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa88a1d9250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa889dede10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABbcAAAFLCAYAAADlHrELAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIiIiBc7/A5CYtDuLHXlfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa889dedd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.set(palette='Set3')\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(25,5))\n",
    "ax1_sns = sns.barplot(x='interval_time', \n",
    "                      y=subdf_cnn3x3input_aucs.subonset_cnn3x3input_auc.values, \n",
    "                      hue='input_type', data=subdf_cnn3x3input_aucs)\n",
    "xticks_loc, _ = plt.xticks(fontsize=12)\n",
    "subonset_cnn3x3spectrogram_aucs_mean = np.mean(subonset_cnn3x3spectrogram_aucs)\n",
    "plt.axhline(subonset_cnn3x3spectrogram_aucs_mean, linestyle='--', label='spectrogram mean', color='green')\n",
    "ax1_sns.text(xticks_loc[4], subonset_cnn3x3spectrogram_aucs_mean, \n",
    "             '{:.4f}'.format(subonset_cnn3x3spectrogram_aucs_mean),\n",
    "             fontsize=12.5, color='green', weight='bold')\n",
    "subonset_cnn3x3melspectrogram_aucs_mean = np.mean(subonset_cnn3x3melspectrogram_aucs)\n",
    "plt.axhline(subonset_cnn3x3melspectrogram_aucs_mean, linestyle='--', label='mel-spectrogram mean', color='orange')\n",
    "ax1_sns.text(xticks_loc[5], subonset_cnn3x3melspectrogram_aucs_mean, \n",
    "             '{:.4f}'.format(subonset_cnn3x3melspectrogram_aucs_mean),\n",
    "             fontsize=12.5, color='orange', weight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.9,1])\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "fig2, ax2 = plt.subplots(figsize=(25,5))\n",
    "ax2_sns = sns.barplot(x='interval_time', \n",
    "                      y=subdf_cnn3x3input_aucs.subsegment_cnn3x3input_auc.values, \n",
    "                      hue='input_type', data=subdf_cnn3x3input_aucs)\n",
    "xticks_loc, _ = plt.xticks(fontsize=12)\n",
    "subsegment_cnn3x3spectrogram_aucs_mean = np.mean(subsegment_cnn3x3spectrogram_aucs)\n",
    "plt.axhline(subsegment_cnn3x3spectrogram_aucs_mean, linestyle='--', label='spectrogram mean', color='green')\n",
    "ax2_sns.text(xticks_loc[4], subsegment_cnn3x3spectrogram_aucs_mean, \n",
    "             '{:.4f}'.format(subsegment_cnn3x3spectrogram_aucs_mean),\n",
    "             fontsize=12.5, color='green', weight='bold')\n",
    "subsegment_cnn3x3melspectrogram_aucs_mean = np.mean(subsegment_cnn3x3melspectrogram_aucs)\n",
    "plt.axhline(subsegment_cnn3x3melspectrogram_aucs_mean, linestyle='--', label='mel-spectrogram mean', color='orange')\n",
    "ax2_sns.text(xticks_loc[5], subsegment_cnn3x3melspectrogram_aucs_mean, \n",
    "             '{:.4f}'.format(subsegment_cnn3x3melspectrogram_aucs_mean),\n",
    "             fontsize=12.5, color='orange', weight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.98,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== cnn3x3 aucs ========== \n",
      "  spectrogram vs mel-spectrogram  \n",
      "----------------------------------\n",
      "     onset            segment     \n",
      "0.9704 vs 0.9764  0.9970 vs 0.9976\n",
      "0.9777 vs 0.9765  0.9962 vs 0.9971\n",
      "0.9695 vs 0.9800  0.9961 vs 0.9973\n",
      "0.9727 vs 0.9773  0.9968 vs 0.9973\n",
      "0.9687 vs 0.9732  0.9839 vs 0.9976\n",
      "0.9514 vs 0.9800  0.9959 vs 0.9962\n",
      "0.9586 vs 0.9784  0.9961 vs 0.9952\n",
      "0.9776 vs 0.9779  0.9943 vs 0.9954\n",
      "0.9376 vs 0.9755  0.9976 vs 0.9964\n",
      "0.9710 vs 0.9757  0.9962 vs 0.9928\n",
      "----------------------------------\n",
      "      mean              mean      \n",
      "0.9655 vs 0.9771  0.9950 vs 0.9963\n",
      "----------------------------------\n",
      "      onset spec var: 0.000145149\n",
      "  onset mel-spec var: 0.000003974\n",
      "    segment spec var: 0.000014257\n",
      "segment mel-spec var: 0.000002017\n"
     ]
    }
   ],
   "source": [
    "subonset_cnn3x3spectrogram_aucs_var = np.var(subonset_cnn3x3spectrogram_aucs)\n",
    "subonset_cnn3x3melspectrogram_aucs_var = np.var(subonset_cnn3x3melspectrogram_aucs)\n",
    "subsegment_cnn3x3spectrogram_aucs_var = np.var(subsegment_cnn3x3spectrogram_aucs)\n",
    "subsegment_cnn3x3melspectrogram_aucs_var = np.var(subsegment_cnn3x3melspectrogram_aucs)\n",
    "\n",
    "\n",
    "print('{:^34}'.format('========== cnn3x3 aucs =========='))\n",
    "print('{:^34}'.format('spectrogram vs mel-spectrogram'))\n",
    "print('-'*34)\n",
    "print('{:^16}  {:^16}'.format('onset', 'segment'))\n",
    "for i,j,k,l in zip(subonset_cnn3x3spectrogram_aucs, \n",
    "                   subonset_cnn3x3melspectrogram_aucs,\n",
    "                   subsegment_cnn3x3spectrogram_aucs, \n",
    "                   subsegment_cnn3x3melspectrogram_aucs):\n",
    "    print(\"{:.4f} vs {:.4f}  {:.4f} vs {:.4f}\".format(i,j,k,l))\n",
    "print('-'*34)\n",
    "print('{:^16}  {:^16}'.format('mean', 'mean'))\n",
    "print(\"{:.4f} vs {:.4f}  {:.4f} vs {:.4f}\".format(subonset_cnn3x3spectrogram_aucs_mean,\n",
    "                                                  subonset_cnn3x3melspectrogram_aucs_mean,\n",
    "                                                  subsegment_cnn3x3spectrogram_aucs_mean,\n",
    "                                                  subsegment_cnn3x3melspectrogram_aucs_mean))\n",
    "print('-'*34)\n",
    "print(\"      onset spec var: {:.9f}\".format(subonset_cnn3x3spectrogram_aucs_var))\n",
    "print(\"  onset mel-spec var: {:.9f}\".format(subonset_cnn3x3melspectrogram_aucs_var))\n",
    "print(\"    segment spec var: {:.9f}\".format(subsegment_cnn3x3spectrogram_aucs_var))\n",
    "print(\"segment mel-spec var: {:.9f}\".format(subsegment_cnn3x3melspectrogram_aucs_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which split index is most closest to the mean value of aucs:\n",
      "      onset spec: 4\n",
      "  onset mel-spec: 3\n",
      "    segment spec: 7\n",
      "segment mel-spec: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Which split index is most closest to the mean value of aucs:\")\n",
    "subonset_cnn3x3spectrogram_splitindx = np.argmin(np.abs(subonset_cnn3x3spectrogram_aucs-subonset_cnn3x3spectrogram_aucs_mean))\n",
    "subonset_cnn3x3melspectrogram_splitindx = np.argmin(np.abs(subonset_cnn3x3melspectrogram_aucs-subonset_cnn3x3melspectrogram_aucs_mean))\n",
    "subsegment_cnn3x3spectrogram_splitindx = np.argmin(np.abs(subsegment_cnn3x3spectrogram_aucs-subsegment_cnn3x3spectrogram_aucs_mean))\n",
    "subsegment_cnn3x3melspectrogram_splitindx = np.argmin(np.abs(subsegment_cnn3x3melspectrogram_aucs-subsegment_cnn3x3melspectrogram_aucs_mean))\n",
    "print(\"      onset spec: {}\".format(subonset_cnn3x3spectrogram_splitindx))\n",
    "print(\"  onset mel-spec: {}\".format(subonset_cnn3x3melspectrogram_splitindx))\n",
    "print(\"    segment spec: {}\".format(subsegment_cnn3x3spectrogram_splitindx))\n",
    "print(\"segment mel-spec: {}\".format(subsegment_cnn3x3melspectrogram_splitindx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run 10 times for each selected split:\n",
    "```\n",
    "python subdf_cnn3x3input.py onset spectrogram 4\n",
    "python subdf_cnn3x3input.py onset melspectrogram 3\n",
    "python subdf_cnn3x3input.py segment spectrogram 7\n",
    "python subdf_cnn3x3input.py segment melspectrogram 5\n",
    "```\n",
    "\n",
    "This returns performance scores in order to get confidence interval, which indicates how significant an effect is when a parameter is changed in the further experiemnts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_kv = {'onset-spectrogram':4, 'onset-melspectrogram':3, \n",
    "            'segment-spectrogram':7, 'segment-melspectrogram':5}\n",
    "\n",
    "subdf_cnn3x3input_tracks = pd.DataFrame()\n",
    "for dataset_type,input_type in zip(['onset','onset','segment','segment'],\n",
    "                                   ['spectrogram','melspectrogram','spectrogram','melspectrogram']):\n",
    "    split_indx = split_kv['{}-{}'.format(dataset_type,input_type)]\n",
    "    csv_name = 'sub{}_cnn3x3{}_split{}.csv'.format(dataset_type, input_type, split_indx)\n",
    "    csv_path = os.path.join(DIR_SAVE_MODEL, csv_name)\n",
    "    subdf_cnn3x3input_track = pd.read_csv(csv_path)\n",
    "\n",
    "    subdf_cnn3x3input_tracks = pd.concat([subdf_cnn3x3input_tracks, subdf_cnn3x3input_track])\n",
    "\n",
    "onset_input = subdf_cnn3x3input_tracks.loc[subdf_cnn3x3input_tracks['dataset_type']=='onset']\n",
    "onset_spectrogram = onset_input.loc[onset_input['input_type']=='spectrogram']\n",
    "onset_melspectrogram = onset_input.loc[onset_input['input_type']=='melspectrogram']\n",
    "\n",
    "segment_input = subdf_cnn3x3input_tracks.loc[subdf_cnn3x3input_tracks['dataset_type']=='segment']\n",
    "segment_spectrogram = segment_input.loc[onset_input['input_type']=='spectrogram']\n",
    "segment_melspectrogram = segment_input.loc[onset_input['input_type']=='melspectrogram']\n",
    "\n",
    "onsetspec_acc_mean, onsetspec_acc_std = np.mean(onset_spectrogram.subdf_cnn3x3input_acc.values),np.std(onset_spectrogram.subdf_cnn3x3input_acc.values)\n",
    "onsetspec_auc_mean, onsetspec_auc_std = np.mean(onset_spectrogram.subdf_cnn3x3input_auc.values),np.std(onset_spectrogram.subdf_cnn3x3input_auc.values)\n",
    "onsetmel_acc_mean, onsetmel_acc_std = np.mean(onset_melspectrogram.subdf_cnn3x3input_acc.values),np.std(onset_melspectrogram.subdf_cnn3x3input_acc.values)\n",
    "onsetmel_auc_mean, onsetmel_auc_std = np.mean(onset_melspectrogram.subdf_cnn3x3input_auc.values),np.std(onset_melspectrogram.subdf_cnn3x3input_auc.values)\n",
    "\n",
    "segspec_acc_mean, segspec_acc_std = np.mean(segment_spectrogram.subdf_cnn3x3input_acc.values),np.std(segment_spectrogram.subdf_cnn3x3input_acc.values)\n",
    "segspec_auc_mean, segspec_auc_std = np.mean(segment_spectrogram.subdf_cnn3x3input_auc.values),np.std(segment_spectrogram.subdf_cnn3x3input_auc.values)\n",
    "segmel_acc_mean, segmel_acc_std = np.mean(segment_melspectrogram.subdf_cnn3x3input_acc.values),np.std(segment_melspectrogram.subdf_cnn3x3input_acc.values)\n",
    "segmel_auc_mean, segmel_auc_std = np.mean(segment_melspectrogram.subdf_cnn3x3input_auc.values),np.std(segment_melspectrogram.subdf_cnn3x3input_auc.values)\n",
    "\n",
    "onsetspec_acc_max = onsetspec_acc_mean+onsetspec_acc_std\n",
    "onsetspec_auc_max = onsetspec_auc_mean+onsetspec_auc_std\n",
    "onsetmel_acc_max = onsetmel_acc_mean+onsetmel_acc_std\n",
    "onsetmel_auc_max = onsetmel_auc_mean+onsetmel_auc_std\n",
    "\n",
    "segspec_acc_max = segspec_acc_mean+segspec_acc_std\n",
    "segspec_auc_max = segspec_auc_mean+segspec_auc_std\n",
    "segmel_acc_max = segmel_acc_mean+segmel_acc_std\n",
    "segmel_auc_max = segmel_auc_mean+segmel_auc_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input effect on cnn3x3:   mean  ,   std   ,   max   \n",
      "-----------------------------------------------------\n",
      " onset spectrogram acc: 0.897611, 0.019068, 0.916680\n",
      " onset spectrogram auc: 0.967773, 0.007441, 0.975214\n",
      " onset melspecgram acc: 0.919794, 0.010232, 0.930027\n",
      " onset melspecgram auc: 0.976562, 0.003250, 0.979812\n",
      "-----------------------------------------------------\n",
      "   seg spectrogram acc: 0.954462, 0.020886, 0.975348\n",
      "   seg spectrogram auc: 0.992508, 0.005118, 0.997626\n",
      "   seg melspecgram acc: 0.975540, 0.006145, 0.981685\n",
      "   seg melspecgram auc: 0.996258, 0.001816, 0.998074\n"
     ]
    }
   ],
   "source": [
    "print(\"input effect on cnn3x3: {:^8}, {:^8}, {:^8}\".format('mean', 'std', 'max'))\n",
    "print(\"-\"*53)\n",
    "print(\" onset spectrogram acc: {:6f}, {:6f}, {:6f}\".format(onsetspec_acc_mean,onsetspec_acc_std, onsetspec_acc_max))\n",
    "print(\" onset spectrogram auc: {:6f}, {:6f}, {:6f}\".format(onsetspec_auc_mean,onsetspec_auc_std, onsetspec_auc_max))\n",
    "print(\" onset melspecgram acc: {:6f}, {:6f}, {:6f}\".format(onsetmel_acc_mean,onsetmel_acc_std, onsetmel_acc_max))\n",
    "print(\" onset melspecgram auc: {:6f}, {:6f}, {:6f}\".format(onsetmel_auc_mean,onsetmel_auc_std, onsetmel_auc_max))\n",
    "print(\"-\"*53)\n",
    "print(\"   seg spectrogram acc: {:6f}, {:6f}, {:6f}\".format(segspec_acc_mean,segspec_acc_std, segspec_acc_max))\n",
    "print(\"   seg spectrogram auc: {:6f}, {:6f}, {:6f}\".format(segspec_auc_mean,segspec_auc_std, segspec_auc_max))\n",
    "print(\"   seg melspecgram acc: {:6f}, {:6f}, {:6f}\".format(segmel_acc_mean,segmel_acc_std, segmel_acc_max))\n",
    "print(\"   seg melspecgram auc: {:6f}, {:6f}, {:6f}\".format(segmel_auc_mean,segmel_auc_std, segmel_auc_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same split, we test on the effects of different kernel shape:\n",
    "```\n",
    "python subdf_cnnkernel.py onset spectrogram\n",
    "python subdf_cnnkernel.py onset melspectrogram\n",
    "python subdf_cnnkernel.py segment spectrogram\n",
    "python subdf_cnnkernel.py segment melspectrogram\n",
    "```\n",
    "Best results along the frequency or time axis are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf_cnnkernel_tracks = pd.DataFrame()\n",
    "for dataset_type,input_type in zip(['onset','onset','segment','segment'],\n",
    "                                   ['spectrogram','melspectrogram','spectrogram','melspectrogram']):\n",
    "    csv_name = 'sub{}_cnnkernel_{}.csv'.format(dataset_type, input_type)\n",
    "    csv_path = os.path.join(DIR_SAVE_MODEL, csv_name)\n",
    "    subdf_cnnkernel_track = pd.read_csv(csv_path)\n",
    "\n",
    "    subdf_cnnkernel_tracks = pd.concat([subdf_cnnkernel_tracks, subdf_cnnkernel_track])\n",
    "\n",
    "onset_input = subdf_cnnkernel_tracks.loc[subdf_cnnkernel_tracks['dataset_type']=='onset']\n",
    "onset_spectrogram = onset_input.loc[onset_input['input_type']=='spectrogram']\n",
    "onset_melspectrogram = onset_input.loc[onset_input['input_type']=='melspectrogram']\n",
    "\n",
    "segment_input = subdf_cnnkernel_tracks.loc[subdf_cnnkernel_tracks['dataset_type']=='segment']\n",
    "segment_spectrogram = segment_input.loc[onset_input['input_type']=='spectrogram']\n",
    "segment_melspectrogram = segment_input.loc[onset_input['input_type']=='melspectrogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subdf_cnnkernel_acc</th>\n",
       "      <th>subdf_cnnkernel_auc</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>input_type</th>\n",
       "      <th>n_freq</th>\n",
       "      <th>n_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.886268</td>\n",
       "      <td>0.967040</td>\n",
       "      <td>onset</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.914138</td>\n",
       "      <td>0.973482</td>\n",
       "      <td>onset</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.920898</td>\n",
       "      <td>0.977411</td>\n",
       "      <td>onset</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.924805</td>\n",
       "      <td>0.979014</td>\n",
       "      <td>onset</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.930739</td>\n",
       "      <td>0.981743</td>\n",
       "      <td>onset</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.916692</td>\n",
       "      <td>0.974949</td>\n",
       "      <td>onset</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.909255</td>\n",
       "      <td>0.970165</td>\n",
       "      <td>onset</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.923603</td>\n",
       "      <td>0.975790</td>\n",
       "      <td>onset</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.916917</td>\n",
       "      <td>0.974043</td>\n",
       "      <td>onset</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.934570</td>\n",
       "      <td>0.982690</td>\n",
       "      <td>onset</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.926082</td>\n",
       "      <td>0.979889</td>\n",
       "      <td>onset</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.919847</td>\n",
       "      <td>0.974823</td>\n",
       "      <td>onset</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subdf_cnnkernel_acc  subdf_cnnkernel_auc dataset_type  \\\n",
       "0           0             0.886268             0.967040        onset   \n",
       "1           1             0.914138             0.973482        onset   \n",
       "2           2             0.920898             0.977411        onset   \n",
       "3           3             0.924805             0.979014        onset   \n",
       "4           4             0.930739             0.981743        onset   \n",
       "5           5             0.916692             0.974949        onset   \n",
       "0           0             0.909255             0.970165        onset   \n",
       "1           1             0.923603             0.975790        onset   \n",
       "2           2             0.916917             0.974043        onset   \n",
       "3           3             0.934570             0.982690        onset   \n",
       "4           4             0.926082             0.979889        onset   \n",
       "5           5             0.919847             0.974823        onset   \n",
       "\n",
       "       input_type  n_freq  n_time  \n",
       "0     spectrogram       6       3  \n",
       "1     spectrogram      15       3  \n",
       "2     spectrogram      36       3  \n",
       "3     spectrogram       3      10  \n",
       "4     spectrogram       3      20  \n",
       "5     spectrogram       3      30  \n",
       "0  melspectrogram       9       3  \n",
       "1  melspectrogram      20       3  \n",
       "2  melspectrogram      45       3  \n",
       "3  melspectrogram       3      10  \n",
       "4  melspectrogram       3      20  \n",
       "5  melspectrogram       3      30  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onset_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "onsetspec_nfreq = onset_spectrogram.iloc[2].n_freq\n",
    "onsetspec_auc_freqmax = onset_spectrogram.iloc[2].subdf_cnnkernel_auc\n",
    "onsetspec_auc_freqsig = 0\n",
    "if onsetspec_auc_freqmax>onsetspec_auc_max: onsetspec_auc_freqsig = 1\n",
    "\n",
    "onsetspec_ntime = onset_spectrogram.iloc[4].n_time\n",
    "onsetspec_auc_timemax = onset_spectrogram.iloc[4].subdf_cnnkernel_auc\n",
    "onsetspec_auc_timesig = 0\n",
    "if onsetspec_auc_timemax>onsetspec_auc_max: onsetspec_auc_timesig = 1\n",
    "    \n",
    "onsetmel_nfreq = onset_melspectrogram.iloc[1].n_freq\n",
    "onsetmel_auc_freqmax = onset_melspectrogram.iloc[1].subdf_cnnkernel_auc\n",
    "onsetmel_auc_freqsig = 0\n",
    "if onsetmel_auc_freqmax>onsetmel_auc_max: onsetmel_auc_freqsig = 1\n",
    "    \n",
    "onsetmel_ntime = onset_melspectrogram.iloc[3].n_time\n",
    "onsetmel_auc_timemax = onset_melspectrogram.iloc[3].subdf_cnnkernel_auc\n",
    "onsetmel_auc_timesig = 0\n",
    "if onsetmel_auc_timemax>onsetmel_auc_max: onsetmel_auc_timesig = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   kernel effect on onset: n_freq, n_time,   auc   , sig, 3x3mean \n",
      "------------------------------------------------------------------\n",
      "    spectrogram freq axis:   36  ,   3   , 0.977411,  1 , 0.967773\n",
      "    spectrogram time axis:   3   ,   20  , 0.981743,  1 , 0.967773\n",
      "mel spectrogram freq axis:   20  ,   3   , 0.975790,  0 , 0.976562\n",
      "mel spectrogram time axis:   3   ,   10  , 0.982690,  1 , 0.976562\n"
     ]
    }
   ],
   "source": [
    "print(\"   kernel effect on onset: {:^6}, {:^6}, {:^8}, {:^3}, {:^8}\".format('n_freq', 'n_time', 'auc', 'sig', '3x3mean'))\n",
    "print(\"-\"*66)\n",
    "print(\"    spectrogram freq axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format(onsetspec_nfreq, '3', onsetspec_auc_freqmax, onsetspec_auc_freqsig, onsetspec_auc_mean))\n",
    "print(\"    spectrogram time axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('3', onsetspec_ntime, onsetspec_auc_timemax, onsetspec_auc_timesig, onsetspec_auc_mean))\n",
    "print(\"mel spectrogram freq axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format(onsetmel_nfreq, '3', onsetmel_auc_freqmax, onsetmel_auc_freqsig, onsetmel_auc_mean))\n",
    "print(\"mel spectrogram time axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('3', onsetmel_ntime, onsetmel_auc_timemax, onsetmel_auc_timesig, onsetmel_auc_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subdf_cnnkernel_acc</th>\n",
       "      <th>subdf_cnnkernel_auc</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>input_type</th>\n",
       "      <th>n_freq</th>\n",
       "      <th>n_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.958924</td>\n",
       "      <td>0.996912</td>\n",
       "      <td>segment</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.971408</td>\n",
       "      <td>0.995389</td>\n",
       "      <td>segment</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.969716</td>\n",
       "      <td>0.994546</td>\n",
       "      <td>segment</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.980670</td>\n",
       "      <td>0.997830</td>\n",
       "      <td>segment</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.984536</td>\n",
       "      <td>0.998020</td>\n",
       "      <td>segment</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.975274</td>\n",
       "      <td>0.996416</td>\n",
       "      <td>segment</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.963032</td>\n",
       "      <td>0.990533</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.975113</td>\n",
       "      <td>0.995612</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.974710</td>\n",
       "      <td>0.996849</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.981476</td>\n",
       "      <td>0.997321</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.978737</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.981556</td>\n",
       "      <td>0.997111</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subdf_cnnkernel_acc  subdf_cnnkernel_auc dataset_type  \\\n",
       "0           0             0.958924             0.996912      segment   \n",
       "1           1             0.971408             0.995389      segment   \n",
       "2           2             0.969716             0.994546      segment   \n",
       "3           3             0.980670             0.997830      segment   \n",
       "4           4             0.984536             0.998020      segment   \n",
       "5           5             0.975274             0.996416      segment   \n",
       "0           0             0.963032             0.990533      segment   \n",
       "1           1             0.975113             0.995612      segment   \n",
       "2           2             0.974710             0.996849      segment   \n",
       "3           3             0.981476             0.997321      segment   \n",
       "4           4             0.978737             0.997241      segment   \n",
       "5           5             0.981556             0.997111      segment   \n",
       "\n",
       "       input_type  n_freq  n_time  \n",
       "0     spectrogram       6       3  \n",
       "1     spectrogram      15       3  \n",
       "2     spectrogram      36       3  \n",
       "3     spectrogram       3      10  \n",
       "4     spectrogram       3      20  \n",
       "5     spectrogram       3      30  \n",
       "0  melspectrogram       9       3  \n",
       "1  melspectrogram      20       3  \n",
       "2  melspectrogram      45       3  \n",
       "3  melspectrogram       3      10  \n",
       "4  melspectrogram       3      20  \n",
       "5  melspectrogram       3      30  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "segspec_nfreq = segment_spectrogram.iloc[1].n_freq\n",
    "segspec_auc_freqmax = segment_spectrogram.iloc[1].subdf_cnnkernel_auc\n",
    "segspec_auc_freqsig = 0\n",
    "if segspec_auc_freqmax>segspec_auc_max: segspec_auc_freqsig = 1\n",
    "\n",
    "segspec_ntime = segment_spectrogram.iloc[4].n_time\n",
    "segspec_auc_timemax = segment_spectrogram.iloc[4].subdf_cnnkernel_auc\n",
    "segspec_auc_timesig = 0\n",
    "if segspec_auc_timemax>segspec_auc_max: segspec_auc_timesig = 1\n",
    "    \n",
    "segmel_nfreq = segment_melspectrogram.iloc[2].n_freq\n",
    "segmel_auc_freqmax = segment_melspectrogram.iloc[2].subdf_cnnkernel_auc\n",
    "segmel_auc_freqsig = 0\n",
    "if segmel_auc_freqmax>segmel_auc_max: segmel_auc_freqsig = 1\n",
    "    \n",
    "segmel_ntime = segment_melspectrogram.iloc[3].n_time\n",
    "segmel_auc_timemax = segment_melspectrogram.iloc[3].subdf_cnnkernel_auc\n",
    "segmel_auc_timesig = 0\n",
    "if segmel_auc_timemax>segmel_auc_max: segmel_auc_timesig = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " kernel effect on segment: n_freq, n_time,   auc   , sig, 3x3mean \n",
      "------------------------------------------------------------------\n",
      "    spectrogram freq axis:   15  ,   3   , 0.995389,  0 , 0.992508\n",
      "    spectrogram time axis:   3   ,   20  , 0.998020,  1 , 0.992508\n",
      "mel spectrogram freq axis:   45  ,   3   , 0.996849,  0 , 0.996258\n",
      "mel spectrogram time axis:   3   ,   10  , 0.997321,  0 , 0.996258\n"
     ]
    }
   ],
   "source": [
    "print(\" kernel effect on segment: {:^6}, {:^6}, {:^8}, {:^3}, {:^8}\".format('n_freq', 'n_time', 'auc', 'sig', '3x3mean'))\n",
    "print(\"-\"*66)\n",
    "print(\"    spectrogram freq axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format(segspec_nfreq, '3', segspec_auc_freqmax, segspec_auc_freqsig, segspec_auc_mean))\n",
    "print(\"    spectrogram time axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('3', segspec_ntime, segspec_auc_timemax, segspec_auc_timesig, segspec_auc_mean))\n",
    "print(\"mel spectrogram freq axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format(segmel_nfreq, '3', segmel_auc_freqmax, segmel_auc_freqsig, segmel_auc_mean))\n",
    "print(\"mel spectrogram time axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('3', segmel_ntime, segmel_auc_timemax, segmel_auc_timesig, segmel_auc_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the value of `n_freq` and `n_time` which returns the highest auc to run:\n",
    "```\n",
    "python subdf_cnnkernel_multi.py onset spectrogram\n",
    "python subdf_cnnkernel_multi.py onset melspectrogram\n",
    "python subdf_cnnkernel_multi.py segment spectrogram\n",
    "python subdf_cnnkernel_multi.py segment melspectrogram\n",
    "```\n",
    "\n",
    "Within the code:\n",
    "```\n",
    "    if dataset_type == 'onset':\n",
    "        typeshape = ONSET_INPUT_SHAPE\n",
    "        batch_size = 256\n",
    "        \n",
    "        if input_type == 'spectrogram':\n",
    "            n_freqs = [36,3,3]\n",
    "            n_times = [3,3,20]\n",
    "        elif input_type == 'melspectrogram':\n",
    "            n_freqs = [20,3,3]\n",
    "            n_times = [3,3,10]\n",
    "        else:\n",
    "            print(\"ERROR: Input type must be either spectrogram or melspectrogram!\")\n",
    "    elif dataset_type == 'segment':\n",
    "        typeshape = SEGMENT_INPUT_SHAPE\n",
    "        batch_size = 128\n",
    "        \n",
    "        if input_type == 'spectrogram':\n",
    "            n_freqs = [15,3,3]\n",
    "            n_times = [3,3,20]\n",
    "        elif input_type == 'melspectrogram':\n",
    "            n_freqs = [45,3,3]\n",
    "            n_times = [3,3,10]\n",
    "        else:\n",
    "            print(\"ERROR: Input type must be either spectrogram or melspectrogram!\")        \n",
    "    else:\n",
    "        print(\"ERROR: Dataset type must be either onset or segment!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf_cnnkernelmulti_tracks = pd.DataFrame()\n",
    "for dataset_type,input_type in zip(['onset','onset','segment','segment'],\n",
    "                                   ['spectrogram','melspectrogram','spectrogram','melspectrogram']):\n",
    "    csv_name = 'sub{}_cnnkernelmulti_{}.csv'.format(dataset_type, input_type)\n",
    "    csv_path = os.path.join(DIR_SAVE_MODEL, csv_name)\n",
    "    subdf_cnnkernelmulti_track = pd.read_csv(csv_path)\n",
    "\n",
    "    subdf_cnnkernelmulti_tracks = pd.concat([subdf_cnnkernelmulti_tracks, subdf_cnnkernelmulti_track])\n",
    "\n",
    "onset_input = subdf_cnnkernelmulti_tracks.loc[subdf_cnnkernelmulti_tracks['dataset_type']=='onset']\n",
    "onset_spectrogram = onset_input.loc[onset_input['input_type']=='spectrogram']\n",
    "onset_melspectrogram = onset_input.loc[onset_input['input_type']=='melspectrogram']\n",
    "\n",
    "segment_input = subdf_cnnkernelmulti_tracks.loc[subdf_cnnkernelmulti_tracks['dataset_type']=='segment']\n",
    "segment_spectrogram = segment_input.loc[onset_input['input_type']=='spectrogram']\n",
    "segment_melspectrogram = segment_input.loc[onset_input['input_type']=='melspectrogram']\n",
    "\n",
    "onsetspec_auc_multi = onset_spectrogram.subdf_cnnkernel_auc[0]\n",
    "onsetspec_auc_multisig = 0\n",
    "if onsetspec_auc_multi>onsetspec_auc_max: onsetspec_auc_multisig = 1\n",
    "    \n",
    "onsetmel_auc_multi = onset_melspectrogram.subdf_cnnkernel_auc[0]\n",
    "onsetmel_auc_multisig = 0\n",
    "if onsetmel_auc_multi>onsetmel_auc_max: onsetmel_auc_multisig = 1\n",
    "\n",
    "segspec_auc_multi = segment_spectrogram.subdf_cnnkernel_auc[0]\n",
    "segspec_auc_multisig = 0\n",
    "if segspec_auc_multi>segspec_auc_max: segspec_auc_multisig = 1\n",
    "    \n",
    "segmel_auc_multi = segment_melspectrogram.subdf_cnnkernel_auc[0]\n",
    "segmel_auc_multisig = 0\n",
    "if segmel_auc_multi>segmel_auc_max: segmel_auc_multisig = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subdf_cnnkernel_acc</th>\n",
       "      <th>subdf_cnnkernel_auc</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>input_type</th>\n",
       "      <th>n_freq</th>\n",
       "      <th>n_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.983731</td>\n",
       "      <td>0.998281</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subdf_cnnkernel_acc  subdf_cnnkernel_auc dataset_type  \\\n",
       "0           0             0.983731             0.998281      segment   \n",
       "\n",
       "       input_type  n_freq  n_time  \n",
       "0  melspectrogram      45      10  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_melspectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subdf_cnnkernel_acc</th>\n",
       "      <th>subdf_cnnkernel_auc</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>input_type</th>\n",
       "      <th>n_layer</th>\n",
       "      <th>n_channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.976240</td>\n",
       "      <td>0.996352</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.951273</td>\n",
       "      <td>0.986978</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.974146</td>\n",
       "      <td>0.995974</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.970844</td>\n",
       "      <td>0.994754</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.943621</td>\n",
       "      <td>0.984885</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.955219</td>\n",
       "      <td>0.989027</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.938869</td>\n",
       "      <td>0.980417</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.878141</td>\n",
       "      <td>0.948604</td>\n",
       "      <td>segment</td>\n",
       "      <td>melspectrogram</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subdf_cnnkernel_acc  subdf_cnnkernel_auc dataset_type  \\\n",
       "0           0             0.976240             0.996352      segment   \n",
       "1           1             0.951273             0.986978      segment   \n",
       "2           2             0.974146             0.995974      segment   \n",
       "3           3             0.970844             0.994754      segment   \n",
       "4           4             0.943621             0.984885      segment   \n",
       "5           5             0.955219             0.989027      segment   \n",
       "6           6             0.938869             0.980417      segment   \n",
       "7           7             0.878141             0.948604      segment   \n",
       "\n",
       "       input_type  n_layer  n_channel  \n",
       "0  melspectrogram        4          4  \n",
       "1  melspectrogram        4          1  \n",
       "2  melspectrogram        3          7  \n",
       "3  melspectrogram        3          4  \n",
       "4  melspectrogram        3          1  \n",
       "5  melspectrogram        2          7  \n",
       "6  melspectrogram        2          4  \n",
       "7  melspectrogram        2          1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_name = 'subdf_cnn_segmel_lc.csv'\n",
    "csv_path = os.path.join(DIR_SAVE_MODEL, csv_name)\n",
    "subdf_cnnsegmel_lc = pd.read_csv(csv_path)\n",
    "subdf_cnnsegmel_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best auc of onset excerpts uses mel spectrogram as input, kernel is 3x10.\n",
    "\n",
    "The best auc of segment excerpts uses mel spectrogram as input, kernel is multiple, 45x3+3x3+3x10.\n",
    "\n",
    "---\n",
    "\n",
    "We try the onset-mel cnn-3x10 with two more convolutional layers: \n",
    "```\n",
    "python subdf_cnn3x10_onsetmel_l.py\n",
    "```\n",
    "\n",
    "We try the seg-mel cnn-multi with less layers and less channels:\n",
    "```\n",
    "python subdf_cnn_segmel_lc.py\n",
    "```\n",
    "\n",
    "BUT none of them performs better!\n",
    "\n",
    "---\n",
    "\n",
    "Test with LeakyRelu activations:\n",
    "\n",
    "```\n",
    "python subdf_cnn_act.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = 'subdf_cnn_act.csv'\n",
    "csv_path = os.path.join(DIR_SAVE_MODEL, csv_name)\n",
    "subdf_cnnact_track = pd.read_csv(csv_path)\n",
    "\n",
    "onset_input = subdf_cnnact_track.loc[subdf_cnnact_track['dataset_type']=='onset']\n",
    "onset_melspectrogram = onset_input.loc[onset_input['input_type']=='melspectrogram']\n",
    "onsetmel_auc_LeakyReLU = onset_melspectrogram.subdf_cnnkernel_auc.values[0]\n",
    "onsetmel_auc_LeakyReLUsig = 0\n",
    "if onsetmel_auc_LeakyReLU>onsetmel_auc_max: onsetmel_auc_LeakyReLUsig = 1\n",
    "    \n",
    "segment_input = subdf_cnnact_track.loc[subdf_cnnact_track['dataset_type']=='segment']\n",
    "segment_melspectrogram = segment_input.loc[segment_input['input_type']=='melspectrogram']\n",
    "segmel_auc_LeakyReLU = segment_melspectrogram.subdf_cnnkernel_auc.values[0]\n",
    "segmel_auc_LeakyReLUsig = 0\n",
    "if segmel_auc_LeakyReLU>segmel_auc_max: segmel_auc_LeakyReLUsig = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   kernel effect on onset: n_freq, n_time,   auc   , sig, 3x3mean \n",
      "------------------------------------------------------------------\n",
      "    spectrogram 3x3kernel:   3   ,   3   , 0.975214, n/a, 0.967773\n",
      "    spectrogram freq axis:   36  ,   3   , 0.977411,  1 , 0.967773\n",
      "    spectrogram time axis:   3   ,   20  , 0.981743,  1 , 0.967773\n",
      "    spectrogram BOTH axis: multi , multi , 0.980067,  1 , 0.967773\n",
      "mel spectrogram 3x3kernel:   3   ,   3   , 0.979812, n/a, 0.976562\n",
      "mel spectrogram freq axis:   20  ,   3   , 0.975790,  0 , 0.976562\n",
      "mel spectrogram time axis:   3   ,   10  , 0.982690,  1 , 0.976562 *\n",
      "mel spectrogram BOTH axis: multi , multi , 0.975477,  0 , 0.976562\n",
      "mel spectrogram LeakyReLU:   3   ,   10  , 0.979376,  0 , 0.976562\n",
      "------------------------------------------------------------------\n",
      " kernel effect on segment: n_freq, n_time,   auc   , sig, 3x3mean \n",
      "------------------------------------------------------------------\n",
      "    spectrogram 3x3kernel:   3   ,   3   , 0.997626, n/a, 0.992508\n",
      "    spectrogram freq axis:   15  ,   3   , 0.995389,  0 , 0.992508\n",
      "    spectrogram time axis:   3   ,   20  , 0.998020,  1 , 0.992508\n",
      "    spectrogram BOTH axis: multi , multi , 0.997979,  1 , 0.992508\n",
      "mel spectrogram 3x3kernel:   3   ,   3   , 0.998074, n/a, 0.996258\n",
      "mel spectrogram freq axis:   45  ,   3   , 0.996849,  0 , 0.996258\n",
      "mel spectrogram time axis:   3   ,   10  , 0.997321,  0 , 0.996258\n",
      "mel spectrogram BOTH axis: multi , multi , 0.998281,  1 , 0.996258 *\n",
      "mel spectrogram LeakyReLU: multi , multi , 0.995766,  0 , 0.996258\n"
     ]
    }
   ],
   "source": [
    "print(\"   kernel effect on onset: {:^6}, {:^6}, {:^8}, {:^3}, {:^8}\".format('n_freq', 'n_time', 'auc', 'sig', '3x3mean'))\n",
    "print(\"-\"*66)\n",
    "print(\"    spectrogram 3x3kernel: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('3', '3', onsetspec_auc_max, 'n/a', onsetspec_auc_mean))\n",
    "print(\"    spectrogram freq axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format(onsetspec_nfreq, '3', onsetspec_auc_freqmax, onsetspec_auc_freqsig, onsetspec_auc_mean))\n",
    "print(\"    spectrogram time axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('3', onsetspec_ntime, onsetspec_auc_timemax, onsetspec_auc_timesig, onsetspec_auc_mean))\n",
    "print(\"    spectrogram BOTH axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('multi', 'multi', onsetspec_auc_multi, onsetspec_auc_multisig, onsetspec_auc_mean))\n",
    "print(\"mel spectrogram 3x3kernel: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('3', '3', onsetmel_auc_max, 'n/a', onsetmel_auc_mean))\n",
    "print(\"mel spectrogram freq axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format(onsetmel_nfreq, '3', onsetmel_auc_freqmax, onsetmel_auc_freqsig, onsetmel_auc_mean))\n",
    "print(\"mel spectrogram time axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f} *\".format('3', onsetmel_ntime, onsetmel_auc_timemax, onsetmel_auc_timesig, onsetmel_auc_mean))\n",
    "print(\"mel spectrogram BOTH axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('multi', 'multi', onsetmel_auc_multi, onsetmel_auc_multisig, onsetmel_auc_mean))\n",
    "print(\"mel spectrogram LeakyReLU: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('3', '10', onsetmel_auc_LeakyReLU, onsetmel_auc_LeakyReLUsig, onsetmel_auc_mean))\n",
    "\n",
    "print(\"-\"*66)\n",
    "print(\" kernel effect on segment: {:^6}, {:^6}, {:^8}, {:^3}, {:^8}\".format('n_freq', 'n_time', 'auc', 'sig', '3x3mean'))\n",
    "print(\"-\"*66)\n",
    "print(\"    spectrogram 3x3kernel: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('3', '3', segspec_auc_max, 'n/a', segspec_auc_mean))\n",
    "print(\"    spectrogram freq axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format(segspec_nfreq, '3', segspec_auc_freqmax, segspec_auc_freqsig, segspec_auc_mean))\n",
    "print(\"    spectrogram time axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('3', segspec_ntime, segspec_auc_timemax, segspec_auc_timesig, segspec_auc_mean))\n",
    "print(\"    spectrogram BOTH axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('multi', 'multi', segspec_auc_multi, segspec_auc_multisig, segspec_auc_mean))\n",
    "print(\"mel spectrogram 3x3kernel: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('3', '3', segmel_auc_max, 'n/a', segmel_auc_mean))\n",
    "print(\"mel spectrogram freq axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format(segmel_nfreq, '3', segmel_auc_freqmax, segmel_auc_freqsig, segmel_auc_mean))\n",
    "print(\"mel spectrogram time axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('3', segmel_ntime, segmel_auc_timemax, segmel_auc_timesig, segmel_auc_mean))\n",
    "print(\"mel spectrogram BOTH axis: {:^6}, {:^6}, {:6f}, {:^3}, {:6f} *\".format('multi', 'multi', segmel_auc_multi, segmel_auc_multisig, segmel_auc_mean))\n",
    "print(\"mel spectrogram LeakyReLU: {:^6}, {:^6}, {:6f}, {:^3}, {:6f}\".format('multi', 'multi', segmel_auc_LeakyReLU, segmel_auc_LeakyReLUsig, segmel_auc_mean))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test seg-mel cnn-multi with L2 and dropout:\n",
    "```\n",
    "python subdf_cnn_segmel_opt.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt effect on segment melspectrogram\n",
      "multi kernel:   auc   , opt      \n",
      "------------------------------------------------------------------\n",
      "              0.998281, n/a      \n",
      "              0.996856, l2       \n",
      "              0.996708, l2dropout\n"
     ]
    }
   ],
   "source": [
    "csv_name = 'subsegment_cnn_melspectrogram_opt.csv'.format(dataset_type, input_type)\n",
    "csv_path = os.path.join(DIR_SAVE_MODEL, csv_name)\n",
    "subdf_segmel_track = pd.read_csv(csv_path)\n",
    "    \n",
    "segmel_input = subdf_segmel_track.loc[subdf_segmel_track['opt_type']=='l2']\n",
    "segmel_auc_l2 = segmel_input.subdf_cnnkernel_auc.values[0]\n",
    "\n",
    "segmel_input = subdf_segmel_track.loc[subdf_segmel_track['opt_type']=='l2dropout']\n",
    "segmel_auc_l2dropout = segmel_input.subdf_cnnkernel_auc.values[0]\n",
    "\n",
    "print(\"opt effect on segment melspectrogram\")\n",
    "print(\"multi kernel: {:^8}, {:<9}\".format('auc', 'opt'))\n",
    "print(\"-\"*66)\n",
    "print(\"              {:6f}, {:<9}\".format(segmel_auc_multi,     'n/a'))\n",
    "print(\"              {:6f}, {:<9}\".format(segmel_auc_l2,        'l2'))\n",
    "print(\"              {:6f}, {:<9}\".format(segmel_auc_l2dropout, 'l2dropout'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
